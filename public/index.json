[{"content":"前言 开学后便开始启动24fall的bustub了，做这一部分主要是因为23fall缺少了B+树的部分，所以来做24fall来学习一下B+树的实现。先说说23到24的变化，变化主要有以下3点：\n首先是23的Page到24变成了FrameHeader并放到了buffer_pool_manager文件中，也就是说在24中需要自己实现底层的Page需要自己实现了，也是自由度更高了，但是我的实现也没有太大变化 其次便是删除了BasicPageGuard，只保留ReadGuard和WriteGuard，并且保证从BufferManager中读取的页面只能够为ReadGuard或WriteGuard，即读取的页面必须加了读锁或写锁，这样也能够实现我23fall中说的将加锁和解锁部分放在ReadGuard和WriteGuard（好耶） 最后也是最重要的，修改了NewPage和FetchPage的分工，这里的设计比23fall合理多了。在24fall中NewPage只获取页面page_id，将所有的页面读取放在了ReadPage和WritePage中，这样就可以只实现一个FetchPage，然后分别在ReadPage和WritePage中构建ReadGuard和WriteGuard，这样获取页面就需要写一个逻辑了（舒服了）。 补充一下，在lru_k中函数有小部分修改，Evict返回optional值了，而不是原先通过指针和bool变量返回两个值，更合理的设计。磁盘读写没注意不知道改过没，我还是用的23fall的实现。 总的来说，24fall设计得比23fall更好了，需要实现的部分也稍微变多了，大体实现还是不变的，最重要的是自由度更高了（嗯，我的观点），并发感觉便难了，因为page的读写需要自己实现。在24fall中也发现23fall中的错误，当然在23fall中的测试是测不出来的，后面在讲。大体优化还是和23fall一样，并发稍微修改了下，LeaderBoard排名第6（2025/03/07），打开就能看见了（哈哈），下面是优化结果。\n这里就不细讲实现了，我只写下我遇到的问题，大体实现和23fall差不多\n并发 23fall解决思路 我先讲讲我原本的并发加锁思路，这里所写的是从磁盘中获取页面，即读取不在内存中的页面。\n23fall中的思路为对所有线性执行（不包含并发操作的部分）加bpm锁，每次调用bpm都需要获取bpm锁，对frame的操作（有IO操作）根据frame_id加锁，保证每个frame_id的操作能够独立执行，不受影响。同时先获取bpm锁，然后获取frame锁，然后释放bpm锁，最后释放frame锁，保证了顺序执行，不会被其他线程插队。但是这样写其实还存在问题，只是在23fall中的测试没有测出来，在24fall中遇到了，也是折腾了我好久（以为我的思路是正确的）。下面展示下原因：\n错误的尝试 并发失败的原因就是不能够保证page的顺序执行，有两种解决办法：\n在线程1写入页面B后释放bpm锁，这样就能够保证page读写的顺序执行了，但是并发度会大幅度下降，显然不是我们所需要的 添加一个page_mutexes_的锁，对每一个page加锁，但是由于page太多，我根据leaderboard中page数设置page_mutexes数组大小为6400，并且使用page_mutexes[page_id % 6400]获取page锁。page_mutexes锁获取放在获取frames_mutexes锁之前，保证获取frame锁之前拥有page的锁，并且一次获取所有需要操作的page的锁。 改了之后可以正常运行，但是不能够先获取frame锁，再获取page锁，这样你甚至无法通过本地测试（哈哈），具体哪个我忘了，有兴趣可以试试。具体原因是获取frame锁后获取page锁失败，导致一直持有bpm锁和frame锁，导致其他线程无法执行，因为释放pageGuard是需要获取bpm锁和frame锁的。\n这个方法能够通过p1的测试，但是在p2的测试中存在问题，所有有了下面的更好的解决办法\n最终大招：引入条件变量 既然出现问题是因为写入和读取在在并发时不能够保证顺序执行，那么我就引入一个条件变量，在从内存中读取页面A之前判断是否有无页面A的脏页面没有写入或正在写入，具体流程如下：\n在bufferPoolManager添加属性如下：\n/** @brief A set of dirty pages that need to be flushed to disk. */ std::unordered_set\u0026lt;page_id_t\u0026gt; dirty_pages_; /** @brief A mutex to protect the dirty pages set. */ std::mutex flush_mutex_; /** @brief A condition variable to notify the flusher thread that there are dirty pages to flush. */ std::condition_variable flush_cv_; 操作流程如下：\nFetchPage获取新页面中，在释放bpm_latch锁前，判断原本的frame是否是脏页，如果是脏页，将其写入dirty_pages_中，表明这个page_id对应的page是脏页并且没有写入 在释放bpm_latch锁后，进入脏页写入，成功写入脏页后将对应page_id从dirty_pages_中删除，表明对应page_id的脏页不存在了，同时使用notify_all唤醒等待的线程 在读取页面之前，使用flush_wait判断是否有脏页未写入，如果有就陷入等待，释放flush_mutex_锁（不释放frame的锁） 下面是最终优化结果，后续应该不会再写bustub了，b+树写了这部分就算结束了。\n写在最后 并发还是博大精深，需要学习的太多了。总的来说，24fall和23fall变化并不是很多，虽然多了FrameHeader部分和修改了PageGuard部分，但是总体还是差不多的，主要是并发部分的错误折腾我太久了，先入为主的认为原本的设计是正确的了（沉默）。\n","permalink":"http://localhost:1313/posts/cmu-15445-24fall-project1/","summary":"CMU 15445 24fall Project1 实现及优化","title":"CMU 15445 24fall Project1"},{"content":" 想法来由 在使用Vscode连接本地虚拟机写代码时，隔一段时间便发现虚拟机IP发生了变化，总是需要修改ssh连接的IP地址未免太过繁琐，便想要为虚拟机设置固定IP地址。同时，由于经常访问外网下载资源，也需要为虚拟机配置系统代理，让其能够使用主机上VPN的系统代理。\n开发环境 time: 2025-02-27 Windows11专业版 VMware Pro 17.6.2 Ubuntu22.04 配置固定IP 在VMware虚拟机配置中设置虚拟机网络为桥接模式 在虚拟机中配置固定IP # 设置网络配置 sudo vim /etc/netplan/00-installer-config.yaml 文件内容如下：\nnetwork: ethernets: ens33: dhcp4: no # 关闭 DHCP（分配IP） addresses: [192.168.138.128/24] # 你的虚拟机 IP，和主机在同一子网下 routes: - to: default via: 192.168.138.208 # 主机网关 IP nameservers: addresses: [8.8.8.8, 1.1.1.1] # 手动指定 DNS version: 2 可能会发现/etc/netplan文件夹下还有00-netcfg.yaml文件和50-cloud.init.yaml文件，我的选择是将其删除\n# 查询主机的IPv4地址和网关，不是VMware Network Adapter VMnet1和VMware Network Adapter VMnet8 ipconfig 启动配置 sudo netplan apply 重启就能发现虚拟机IP地址固定为你设置的IP地址了 配置VPN代理 在本地VPN代理中开启局域网连接，我使用的是Clash Verge 在.bashrc文件中添加代理 cd ~ vim .bashrc .bashrc添加内容如下：\n# 这里将IP地址修改为自己主机的IPv4地址 export http_proxy=http://192.168.138.180:7897 export https_proxy=http://192.168.138.180:7897 启动配置：\nsource .bashrc 配置Rust代理 Rust全局配置：\ncd ~ vim .cargo/config.toml config.toml添加如下配置内容：（这里将IP地址修改为自己主机的IPv4地址）\n[http] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; [https] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; 目前存在的问题 过了一段时间后发现，主机的IP和网关地址并不是固定不变的，这就需要每次修改虚拟机的配置，暂时还未解决，等待之后看看有没有什么比较好的解决办法吧\n写在最后 看网上的内容陆陆续续配了好几次，总是这里或者那里有问题，今天终于是配好了，好耶。\n也使用NAT模式配过，也是网上推荐比较多的，但是网络配置总是有问题，连接不上网络或主机，之后有机会去认真学习一下计算机网络了。\n最后，有问题多问AI，还是挺有帮助的。\n","permalink":"http://localhost:1313/posts/ubuntu22.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/","summary":"在Windows11上为VMware搭建的Ubuntu22.04虚拟机配置固定IP地址，共享主机VPN代理","title":"Ubuntu22.04虚拟机配置固定IP和VPN代理记录"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 老规矩，先看一下最终排名，截止2025/02/10, 总分第7，单榜第1，打开LeaderBoard第一个就是我了（嘿嘿） 个人认为project4完全做完应该是4个project中最难的吧，花的时间是最多的，不过开始写的时候刚好考试比较多，没多少时间写，大概花了几天时间把前几个task完成了，最后在考试完后回家写了几天才写完。虽然可能没写太久，但是感觉花费的精力挺多的。最后还是课程中那句话，有空闲时间再写写这个，优先去做更重要的事情。\nProject4 项目概述 在本次项目中需要实现数据库中的事务管理部分，也是在p3中介绍的SQL执行过程中开始和结束的部分。开始我们需要实现事务管理器创建事务，watermark对正在运行的事务的时间戳管理——用于垃圾回收，在当前正在运行的事务的时间戳范围之外即是可以回收的事务。再之后就是在事务执行时增删改查以及事务提交部分，由于不同事务创建时间点不同，需要读取不同时间点的数据，所以undoLog版本链由此而生，事务顺着版本链读取自己正在操作的数据或者当前事务创建前的数据（保证访问数据是自己能够访问的），Reconstruction函数也是因此而生的，用于对Tuple顺着版本链回退版本。增删改查操作比较简单，主要是保证读写版本链的正确性，读操作读取到正确的数据，写操作访问合法范围的数据（没有其他事务正在操作或已经操作过）。commit操作主要是修改事务的状态和提交时间戳（后续会用），并且修改事务操作过的数据的时间戳（修改为提交时间，事务操作时为事务id，防止其他事务操作）。垃圾回收就很简单了，回收watermark中时间戳范围外的已提交的事务即可。\n然后就是麻烦的部分来了，开始考虑索引的影响，读操作会调用IndexScan（需要修改），Insert时需要考虑索引冲突，Update时需要考虑主键修改。在这之后就是所有的并发，包括插入的并发（需要考虑索引冲突）、更新的并发（这个倒是没有主键更新）、事务取消的并发（bonus中的部分）、序列化的并发（leaderboard-2），并发算是这部分中的难点。总结并发实现就是重构重构重构，改了很多才全部实现通过。\nTask #1 - Timestamps task1主要是熟悉下这部分内容相关代码，写的部分比较简单。总共实现两个部分：\n事务管理器中创建事务，赋予时间戳，将其放入watermark中 watermark管理所有正在运行的事务，保存正在运行的事务的最小时间戳，创建事务时向其中添加事务时间戳，提交事务时从中删除。 关于这一部分的O(1)实现方法，利用事务管理器中的last_commit_ts_，它赋予给所有创建的事务，并且是单调递增，在commit时+1。这样便可以确定watermark中时间戳在一定的范围内，时间范围最大为last_commit_ts_，最小为正在运行的事务中的最小时间戳，并且由于时间戳+1递增，所有watermark也使用+1递增寻找符合的事务。具体实现为除非watermark为空，否则添加时不修改watermark值，删除时判断是否还有时间戳为watermark的事务，没有就递增搜索，直到commit_ts。 Task #2 - Storage Format and Sequential Scan task2算是初步了解这部分中的内容，也是两个部分：\nTuple Reconstruction，根据undo_logs中内容回退tuple中的数据，主要注意的是对已删除的数据的操作（执行前已删除，执行后已删除） 顺序扫描，顺着版本链扫描，如果为当前事务操作的数据或者时间戳比当前事务创建时间戳小，直接读取即可，对于其他事务正在操作或已经操作过的数据，需要顺着undo_log版本链构建undologs，使用1中的函数构建合适的Tuple Task #3 - MVCC Executors task3算是这部分的核心内容吧，实现增删改查这些基本操作在事务下的执行过程以及事务的提交，\nInsert 向table中插入数据即可，需要同时向write_set中传入对应rid（后续会在commit中统一修改对应Tuple的时间戳，表明该Tuple没有事务在执行，当前事务操作完毕，也可以用于Abort中取消对Tuple的操作）\nCommit commit主要是两个操作，一是修改last_commit_ts_以及当前事务的commit_ts；二就是读取write_set，修改事务执行过写操作的Tuple的时间戳为当前事务提交的时间戳即commit_ts\nUpdate \u0026amp;\u0026amp; Delete Update和Delete操作差不多，都是根据读取的数据进行操作，需要判断读取的数据时间戳，有三种情况：\nTuple时间戳小于等于当前事务时间戳，表明这个Tuple没有被当前事务之后的事务操作或正在被其他事务操作，直接操作Tuple，然后写入UndoLog、写入writeSet、更新VersionLink Tuple的时间戳等于当前事务ID，表明这个事务之前被当前事务操作过，在操作过Tuple就需要更新之前提交的UndoLog 其他情况，包括没有事务操作但时间戳比当前事务操作（被当前事务之后的事务操作过了）、已经有其他事务在操作了两种情况，这两种情况都是写写冲突 Stop-the-world Garbage Collection 垃圾回收实现比较简单，主要是利用task1中的watermark来实现，对于所有已提交的事务，如果它的提交时间比watermark_ts小或者undo_log为空，这两种情况都表明这个事务都不再被访问，直接回收即可，总共就一个循环加上一个判断即可，没几行代码。这里解释下为啥这样写，一是watermark本来就是为了垃圾回收机制而设计的（我是这样理解的），二是对于所有undoLog为空的事务，不会有版本回退访问到的情况，三就是对于所有提交时间戳小于watermark的事务，是不会被正在运行的事务访问到的，仔细想一想，undoLog是存放修改之前的数据状态。\nTask #4 - Primary Key Index task4中引入索引，不过是单索引，这时候对版本链的操作发生了变化。由于索引指向的地址不会发生变化，对于同一个索引指向的Tuple存在删除数据后又重新插入的情况，同时在插入时要需要判断索引冲突。引入了索引版本链才算完整（从Reconstruction的操作来看，存在从删除状态到未删除状态），同时索引在创建后是不会被删除的。这部分就和project3的多索引部分冲突了，因为可扩展哈希不支持多索引指向同一个Tuple，所有Project4和Project3不兼容。其实底层实现也有冲突，Project3更新操作是删除原数据，创建新的Tuple，因为Tuple大小不固定，但是在Project4就是原地修改，这时Tuple的大小就是固定了，这里可能存在冲突，不过我也没有去细看过，因为前面部分就冲突了，哈哈。\nInserts 这一部分便是重构Insert，考虑存在索引的情况。大致介绍下我的实现（包括并发）：\n首先便是判断是否有索引冲突，有就直接报写写冲突即可，同时记录插入的Tuple的索引是否存在 如果对应的索引存在，依旧是判断是否存在写写冲突，即索引指向位置的Tuple是否已删除且没有其他事务正在操作，满足条件就直接插入即可，修改versionLink、UndoLog、以及writeSet 如果对应的索引不存在，那么就和原本的Insert一样，插入数据，更新VersionLink（第一次插入是没有undoLog），然后创建对应索引即可 介绍下我对插入并发的实现，在1中判断是否有索引冲突，防止已经有索引还插入，在3中进行索引创建检查冲突，这里便是并发关键，如果有多个指向同一个索引的Tuple插入，便会发生竞争插入，最终只有一个插入成功，其余全部失败。 Index Scan, Deletes and Updates 这里是task中最麻烦的一部分吧，还有个Update的并发，介绍下我的实现。\n由于引入了索引，所以根据project3中实现的优化，这里会调用IndexScan，所以需要修改IndexScan，使其能够适应事务的操作，实现大致和SeqScan差不多吧 Delete和Update操作没有太大变化，主要是由于索引存在，版本链和之前不同，存在对已删除的地方进行插入，所以对undoLog和versionLink的操作有小部分修改 最后介绍下并发的实现，并发使用versionLink来实现并发操作。先介绍下原理，实现的关键是UpdateVersionLink和GetVersionLink函数中有锁，并且这个函数由txn_manager管理，保证所有事务对versionLink的操作是原子的（原子操作是实现并发的关键，加锁便是为了实现原子操作——执行过程不会被其他事务插队）。接下来就有点类似于操作系统中的利用底层原子操作来实现并发的方法了——自旋检查，检查过程是原子的，通过这部分实现并发。下面是具体实现（也是借鉴了其他实现了这部分代码的大佬的思路）： 先检查写写冲突，有写写冲突直接退出即可 自旋检查version_link中in_progress是否为false，这表明这个rid指向的tuple没有其他事务在操作 调用UpdateVersionLink函数，传入检查函数，检查是否已经有其他事务获取了in_progress（检查是原子的），然后修改in_progress为true，表明有事务在操作该Tuple，其他事务只能自旋等待。如果执行失败可以跳转1重新检查并进入自旋等待 再次检查是否有写写冲突（这部分貌似没有被执行过，在我的代码里我测过，不过其他大佬都写了，我也写一下） 写一下我的微操作，也是其他大佬没写的部分。一是修改了VersionLink的状态，在原本的设计中，在最开始插入时，versionLink是为空的，但是这样自旋判断存在问题（没有versionLink，就没有in_progress），所以我在一开始就插入versionLink，让它指向一个不存在UndoLog(默认的)，通过GetUndoLogOptional函数来判断是否到版本链终点，这其实也是我最开始写这部分的想法（让versionLink——指针指向为空表示没有UndoLog，而不是UndoLog指向为空），也和其他同学交流过，终于这样写也是舒服了。二就是在commit时在统一修改versionLink的in_progress为true，这样也和write_set同步了，也不需要加入多的结构，正好符合设计，也防止被其他事务插队。 Primary Key Updates 主键更新也是大坑，倒是没有并发，但是是单索引，不符合Project3的测试。实现的关键点就是先获取所有的数据，对其进行更新操作，判断是否有索引冲突，然后再统一删除原本的数据，然后插入新的位置。冲突可以通过Expression中修改的位置下标来判断是否有索引变化。\nBonus Bonus Task 1: Abort Abort主要是实现Abort函数，通过writeSet来将事务操作过的数据恢复原本的状态，同时回退versionLink和UndoLog，这部分主要是针对前面写写冲突抛出的tainted的事务，将其所做的操作复原。这部分还有个更重要的问题是并发的实现发生了变化，原本是利用in_progress来实现并发，从这里开始使用底层的page锁来实现并发了，原先的versionLink锁的部分可以删除了，不过并发的实现也变得更简单了。\nBonus Task #2 - Serializable Verification 这一部分主要是检查在事务并发过程中，是否存在并发过程中事务执行顺序不同导致不同的结果——即序列化的正确性，如果存在这种情况，就需要进行Abort。这部分主要是实现VerifyTxn函数，这个函数主要是检查已经提交的事务中是否存在和当前事务有序列化冲突的情况，如果有便直接Abort，这个已经提交的事务是指当前事务执行过程中可能会对当前事务操作的数据进行影响的事务，即提交在当前事务创建之后。\nleaderboard LeaderBoard难点在第二个，也就是对 bonus task2 序列化的并发实现，如果有问题，请查看其他代码的实现有无问题，反正就是重构重构。给的论文没有去看，有时间再说吧，感觉直接写就行，也不一定需要看，就像课程内容一样。\n写在最后 到此bustub 23fall 的4个project已经圆满完成，所有分数已经拿齐，能做的优化也基本做了，除了project3的LeaderBoard，其他的都做了，也取得了不错的成绩，还是不错的。接下来按照安排是去实现tinykv，可能也会写一写文章吧，还有bustub24fall可能也会去做，稍微瞄了一眼，24fall也改了不少，而且B+树的实现是必须要去做的。总体感觉bustub一年比一年难了，也更加完整了，也是变得越来越好了，希望这门课程变得越来越好吧。通过这4个project也是学到了很多东西，对C++、对数据库、对代码能力都是巨大的提升，有兴趣的同学都可以来写一写（不过看到这的同学都是写过的吧，哈哈）还是挺不错的。\n最后, 感谢 CMU 15445 的老师和助教们的辛勤付出\n考虑到网上实现最后这部分内容的文章比较少，代码也是没有，我把我的代码放在这，这部分课程也是即将结束，应该也没几个人写了，有兴趣的同学可以参考一下，我觉得我写的还是不错的，哈哈哈。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project4/","summary":"CMU 15445 23fall Project4 实现","title":"CMU 15445 23fall Project4"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 project3开始真正进入数据库的实现了，通过实现这一部分内容，你会对数据库的基本结构有一个清晰的认识，在这一部分中需要多读代码，具体实现较为简单，需要对数据库的整体实现结构有一个清晰的认识才好实现这一部分内容。这一部分的leaderboard我没有做，感觉设计不是很好，不太感兴趣，就没写这部分，看榜单也没几个人写这个，我这里就放一下100分的截图。\nProject3 总体概述 这里介绍下我对下面这个整体流程图的认识：首先由事务管理器创建事务，然后由事务执行SQL语句，然后开始解析SQL语句(Parser)(在bustub_instance中)，根据解析出来的语句与相应的关键字进行绑定(Binder)，然后构建出执行树(Planner)，再之后对语法树进行优化(Optimizer)(调整结构，在bustub中是逻辑优化，安装固定顺序执行设定好的优化)。语法树优化完毕后便将其传递到执行器中执行(Executor)(包含执行的上下文即事务、相关数据如索引表、table表，Expression如where表达式中的谓词)，执行器使用火山模型，自底向上分层执行，上层调用下层获取执行结果，并将本层的执行结果传递给更上层。火山模型优点挺多，设计简单，各层解耦合，执行效率也比较高。\n总体来说，这一章并不难，关键在于与前面两章完全解耦（前面两章为索引和底层的缓冲池，索引和表都在用），在本章中需要阅读大量代码，对整个项目有一个基本的认识，才能够着手开始实现执行器和优化器中的业务逻辑，业务逻辑实现并不复杂，关键还是读代码学习简易数据库的设计。\nTask #1 - Access Method Executors task1就是实现基本的增删改查的内容，关键是需要理解数据库的整体设计，如表的设计、索引的使用（project2中设计），二者关联、Expression的使用，执行计划树结构，以及火山模型的执行器设计结构。还需要对常用结构有清楚的认识，如index索引、table表数据、schema表数据与索引的关联、plan可能会存放的数据(如操作的表id，涉及到的Expression)，以及Expression的Evaluate操作（常量表达式、逻辑运算、比较运算、算术运算、字符串）\n优化操作，将顺序扫描优化成索引扫描，具体是否优化看where表达式中的谓词，实现细节仿照已有的优化器即可（自带几个实现好的优化器）\nTask #2 - Aggregation \u0026amp; Join Executors Aggregation 聚合操作，即一些分块(group by)函数(如min、max、avg、sum)操作，关键点在于需要实现一个自定义的哈希表，根据groupby结果生成对应的key，并对key值对应的value执行指定的聚合操作。按照这些操作形成聚合树后再就行迭代访问得到结果即可。\nNestedLoopJoin 联结操作，即多表联结，主要就是对两表进行联结操作，保留左表和右表，两重循环表里左表和右表（左表在外层），符合条件的即为联结的结果\nTask #3 - HashJoin Executor and Optimization HashJoin 仿照实现一个类似于Aggregation中的自定义哈希表，将原本的NLJ为两层循环操作，通过哈希表，将内层变成哈希表查找符合条件的元素，将两层循环便优化成一层循环，时间复杂度由O(n2)优化成O(n)\nNLJ -\u0026gt; HashJoin 根据Expression中的逻辑表达式进行递归判断即可，在执行时需要根据col_id判断是左表还是右表的数据，将其放入正确的位置\nTask #4: Sort + Limit Executors + Window Functions + Top-N Optimization Sort ＆ Limit 最简单的一集，sort实现一个自定义的排序逻辑传入std::sort调用即可，limit就更简单了，取前几个数即可\nSort ＆ Limit -\u0026gt; Top-N 先排序再取前几个数，也很简单，无非不是把limit和sort结合，优化就是看看执行树中是否有相邻两层为Limit和Sort\nWindow Functions WindowFunction是project3中最难的一部分了吧（除去LeaderBoard部分），需要根据是否有orderBy来进行排序(但是只需要排序一次), 使用partition来进行分类，然后进行函数操作，这部分有点类似于Aggregation操作，分类以及函数操作，只不过多了一个rank（需要单独考虑）\n写在最后 project3难点还是在于读代码，了解整个项目的设计结构，具体实现也就是一些常用的执行器的实现以及实现了几个优化器，但是也并不难。整体来说还是收获到很多东西，这一部分可能写的不是很详细，一是时间已经过去很久了，记不太清了，二是在后续project4中会修改很多地方，导致代码已经变化很多了。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project3/","summary":"CMU 15445 23fall Project3 实现","title":"CMU 15445 23fall Project3"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project2开始涉及到数据库索引的底层实现，今年做的是可扩展哈希，相比于B+树要简单不少，推荐学有余力的同学去做一下其他年份的B+树，总体来说没做多久，比Project1花的时间稍多一点。然后说一下LeaderBoard结果吧，截止2025/01/30排名第6\n时间有点久远，实现细节基本都忘了，讲一下我的整体思路吧\nTask #1 - Read/Write Page Guards Task1中实现对Page的读写锁的析构时自动释放和调用函数手动释放操作（要实现的就是一个能够在生命周期结束时自动释放锁和手动释放锁的结构），这部分实现较简单\nBasicPageGuard、ReadPageGuard、WritePageGuard类的构造函数、析构函数、=重载函数、Drop函数的实现，需要注意的是对锁不能重复释放，需要先进行判断 bufferPoolManager中pageGuard获取函数实现，锁在ReadPageGuard、WritePageGuard外部获取，但是在内部释放，感觉设计挺奇怪的，导致我一开始写这一部分出了些错误，后来想其觉得设计还是挺奇怪的，个人认为把锁的获取放在构造函数内更优雅 Task #2 - Extendible Hash Table Pages 这部分实现可扩展哈希的三层结构的具体实现，包括初始化，各种功能函数的实现，基本按照函数名就知道有啥用，相应实现即可，比较简单。\n自底向上简单介绍下这三层结构的意义：\nbucket层，桶的功能设计，实际存放所有的元素，所有的增删改查都会操作这层实例元素，并且所有索引指向的元素是唯一的，插入前需要检查 directory层，可扩展哈希的核心设计，向下进行桶的分裂与合并（也是这部分的难点），保证存储空间的高效利用，向上提供索引，指向实际元素的位置。 header层类似于操作系统中多页表设计中的外层页表，用于增加directory的数量和并发度，实现通过索引映射到不同的directory 总结，整个可扩展哈希核心便是利用二进制数来进行索引，通过将二进制数不同段分别用于各层中的指向，实现了树形的索引树，同时在最下面两层，利用桶的分裂合并极大提高了空间效率。 关于桶分裂合并提高空间效率，通过利用global_depth_, local_depth_ 字段，将二进制中低位用于指向不同的bucket，高位用于重复利用，实现多个索引指向同一个桶，同时利用二进制位运算的性质，使得桶的分裂与合并操作较为简单。 多层的设计也是提高了空间利用率，在可扩展哈希的设计中，加锁只需要控制住两层即可，也就是说不同的directory之间是可以并发的 整个设计类似于多层哈希设计，不过通过利用二进制数来充当索引，同时利用了桶的分裂合并提高了空间效率。但是本身存在不少问题，包括并发度不高，并且索引冲突的问题无法解决。由此来看，如果想要深入学习数据库，学习B+树还是必要的，可扩展哈希貌似用的也不多，也没啥可优化的 Task #3 - Extendible Hashing Implementation 大致讲下这几个函数的实现思路：\nGetValue，也即是读操作，根据生成的索引从header（根节点）向下搜索直到得到对应节点退出，或者对应节点不存在返回false Insert，向内存中写入数据，根据索引向下进行搜索对应节点位置，如果不存在则创建（directory、bucket），如果重复则直接退出即可。关键便在于如果插入的桶满了，这时候需要进行桶的分裂操作 如果global_depth与local_depth相同，表明全局深度与局部深度相同，这时候就需要增加global_depth，增加bucket个数。 否则进行bucket分裂即可，分裂即增加local_depth，修改所有影响的bucket（用对应bucket复制即可） 分裂完毕重新进行插入操作，有可能插入失败（由于是按照索引来存放的，分裂后可能还是桶满），所以需要循环进行，直到达到最大深度或者插入成功，否则即插入失败 Remove，删除内存中的数据，由索引向下搜索，搜索到删除即可，搜索不到则说明不存在，返回false。关键是在删除后如果bucket为空，需要进行桶合并 桶合并需要使用位运算，判断local_depth下所有的桶都能够进行合并，否则如果存在不能够合并的桶，则不能进行合并操作。本质上是使用位运算来进行操作，local_depth决定取的低位数（即合并后的桶），左侧没取到的是高位数，左侧变化所包含的所有需要合并的桶的深度必须相同，才能够保证能够进行合并。 和桶分裂相同，桶合并操作也需要循环进行，直到不能够进行桶合并为止（存在合并一次后还能够合并） 写在最后 可扩展哈希实现还是挺有意思的，但是可扩展哈希局限性太多，也没啥可优化的，相比之下B+树应用更多，难度也更大，学有余力的同学还是去学习下B+树的部分。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project2/","summary":"CMU 15445 23fall Project2 实现","title":"CMU 15445 23fall Project2"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project1整体还是比较简单的, 大概在第一周就完成了Project1的全部内容, 然后在Project2完成之后, 花了一周的时间实现了Project1的代码优化。\n然后说一下优化结果, LeaderBoard 排名第10(2025/1/27), 优化结果如下:\n给前面几位神仙跪了, 断层领先, 有理由怀疑在hack, 各项数据太吓人了。我的这个排名差不多就是我的极限了吧, 能做到都已经做了。(hack我也不会, 哈哈)\n根据课程要求, 源代码暂时就不公开了, 等23fall课程结束再说吧\nProject1 总体概述 在Project1中, 我们需要实现内存中缓冲池管理, 包括lru-k策略(内存调度策略), Disk Scheduler(磁盘调度, 即读写磁盘数据操作), BufferPoolManager(结合内存调度和磁盘读写操作, 实现内存缓冲池管理, 实现读写物理page)。为什么要实现这个Project呢, 学过操作系统的同学应该就知道, 实际的物理存储介质呈金字塔形状, 内存大小远远小于物理磁盘, 内存中的空间是有限的, 要想访问存储在磁盘中的庞大数据, 就需要实现一个内存缓冲池, 将需要使用的页面调度到内存页中, 将不再访问的页面写回到物理磁盘中, 实现好像在读写整个物理磁盘的效果。\nTask #1 - LRU-K Replacement Policy 在Task1中我们需要使用lru-k策略实现内存页调度策略。其中每一个frame对应一个内存中的page(数量有限, 内存页), 而在bufferManager中的page是实际存储数据的物理page(物理页), 相对于frame(内存page)而言是无限的。从这里就可以看出, 我们的任务实际是在实现内存的调度策略, 将物理页中的数据调度到内存页中进行访问, 当空闲内存页不够时, 对正在使用的内存页进行Evict, 获取空的内存页, 然后在bufferManager中将新的物理page中的数据存放到内存页中以便访问。\n实际实现内容:\nEvict, 从所有正在使用的内存页(evictable)中淘汰出一个空的内存页, 将其返回给bufferPoolManager RecordAccess, 访问记录, 用于lru-k策略 SetEvictable, 根据frame_id将frame设置为evictable状态, 即可以被淘汰 Remove, 从lru-k队列中删除指定frame_id, 将其设置为空闲状态, 这个函数实际貌似没怎么用过, 个人认为是跟lru-k策略没啥关联, 并且也需要和bufferPoolManager联动, 将空闲frame_id放入BufferPooManager中 我的实现:\n使用两个队列存放所有使用的frame 一个history_list队列, 存放访问次数少于k次的frame, 先进先出策略； 一个lru_list队列, 存放所有访问次数大于等于k次的frame, 我的策略是选择Evict时顺序遍历求访问时间最小的frame(也算是一种lru-k策略的优化吧, 对lru_list进行Evict操作为O(n)操作, 对lru_list队列中的frame进行操作为O(1)操作) lru-k策略介绍: 如果访问次数小于 K次, 那么不作更改, 因为小于 K 频次时 FIFO. 如果访问次数等于 K次, 那么将结点从 history_list_ 中移动到 lru_list_ 中. 如果访问次数大于 K, 那么逐出结点记录的最早访问记录, 然后再将该结点插入到 lru_list 队列中(按我的实现策略, 任意位置即可) 关于并发, 没什么好的思路, 一把大锁即可 Task #2 - Disk Scheduler 在Task2中我们需要实现对磁盘的读写操作(IO操作), 这一部分比较简单\n实现内容:\n主要实现Schedule函数, 将IO操作独立出去, 放在单独的线程中执行IO操作, 并发优化的点也在这一部分 Task #3 - Buffer Pool Manager 在Task中我们就需要综合Task1中的Lru-k内存调度策略和Task2中的磁盘调度实现缓冲池管理, 使缓冲池能够自由访问物理页数据, 实现页面好像直接在读写物理页的, 不需要了解内存页的效果。\n实现内容:\nNewPage, 创建一个新的Page物理页 FetchPage, 读取指定page_id的物理页 UnPinPage, 当页面使用完毕, 会调用这个函数, 表明正在使用这个页面的人数减一, 当减到0时, 就可以将其设置为Evictable, 即内存调度策略中可以被淘汰的内存页 FlushPage, 将指定page_id的页面从内存页写回物理页 FlushAllPage, 将内存中所有页面写回到物理页 DeletePage, 删除指定page_id的页面, 将其内存页回收为空闲状态放入free_list_, 如何是脏页面就写回磁盘(这三个函数都没怎么用过) 我的实现:\nNewPage函数, 从AllocatePage函数获取page_id, 从free_list获取内存页, 如果free_list为空就需要从使用lru-k策略从内存内Evictable的页面中淘汰出内存页, 如果淘汰出的页面是脏页面还需要写回磁盘, 剩下就是创建新页面, 返回page_id和Page实例 FetchPage函数, FetchPage和NewPage差不多, 只是FetchPage需要先判断内存中是否有page_id的内存页, 如果没有, 就需要从磁盘中读取到内存中, 读取操作和NewPage差不多, 只是多了读取磁盘数据 UnpinPage函数, 修改page中的pin_count_和is_dirty_字段即可, 如果pin_count_变成0了, 将其设置为evictable即可, 这个功能较简单 FlushPage和FlushAllPage差不多, 一个指定page_id, 一个遍历所有内存中的page, 将内存页写回物理页, 调用DiskScheduler即可, 别忘了重置is_dirty状态 DeletePage函数, 淘汰指定page_id的内存页, 如果还有人员正在使用那是不能删除的哟, 如果是脏页面就将其学会内存, 剩下就是将其使用的资源回收 LeaderBoard Task 借用下隔壁大佬的话\nDoing Project without the LeaderBoard is equivalent to playing games without Genshin Impact.\n在这个任务中我们需要实现并发操作, 在一开始最好使用一把大锁, 先确定所有实现的函数有没有问题, 然后再考虑细分锁的问题。\n我的实现: 一把大锁加上去, 细化放在优化里面讲\n代码效率优化(LeaderBoard排名优化) Task1 LRU-K Replacement Policy 优化 我的尝试:\n由于在Task1中已经将lru-k策略设计好了, 我尝试使用另一种实现策略。将lru_list队列设置为有序, history_list队列不变, 每次RecordAccess都对lru_list_进行位置调整, 这样Evict效率变为O(1), RecordAccess效率降低, 但是由于lru_list现在有序(可以冒泡移动), 效率不到O(n).但是最终结果表明这样效率并没有提升, 也可能是我实现有问题吧, 有兴趣的同学可以实现, 这部分代码被无语的我删掉了(版本回退消失了) 利用access_type属性, 由于在Leaderboard中开启了16个线程, 其中8个随机读写, 8个顺序读写, 可以access_type稍稍调整lru-k的实现策略实现效率提升(这个我使用了, 确实效率提升不少) Task2 Disk Scheduler 优化 我的尝试:\n磁盘调度优化显而易见, 原本磁盘调度是单线程, 将其修改为多线程即可 由于并发度不同, 磁盘调度我选择设置为动态线程池, 在并发度较低时线程池也较小(开动态线程池貌似也没啥效率提升, 哭, LeaderBoard测试太死了) Task3 \u0026amp; LeaderBoard 并发优化 我的尝试:\n刚开始选择为每一个使用的资源设置一个锁, pages设置一个锁的数组(每个page一个锁), 遵守二阶段锁策略, 尽量将各部分加锁部分分离, 使其尽可能并发 随着并发的深入学习实现, 理解了这部分并发提升效率的本质: 并发本质是将IO操作并发(这是可以并发的, 和DiskScheduler实现有关), 其他bufferPoolManager属性加一把锁即可, 这部分没有并发可言, 基本所有函数都有在操作。最关键点在于, IO的操作较慢, 需要并发来提升效率, 实际对属性字段操作较快, 并且多个线程都需要操作, 加锁变成单线程即可 最终结果: 对pages外的所有数据使用一把大锁latch_, 对Pages_使用锁数组(防止对同一个page操作并发冲突), 遵循二阶段锁策略, 尽量将IO操作和对bpm的字段操作分离开, 分别加锁, 利用IO并发提高效率 写在最后 本来是考虑使用火焰图perf来看那些部分需要优化, 但是在我的设备上总是有问题, 至今没有解决, 最终选择从设计上来思考如何优化。从最终结果来看, 优化的还不错, 学到了挺多东西, 花了我大概一周的时间。如果有同学想优化代码, 可以考虑使用火焰图, 从使用火焰图的同学和师兄的说法来看, 还是不错的。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project1/","summary":"CMU 15445 23fall Project1 实现及优化","title":"CMU 15445 23fall Project1"},{"content":" 前言 我是用的artalk搭建的评论系统，部署在我自己的服务器上，在本地部署成功后，由于GitHubPages的页面使用https访问，而服务器数据访问使用的是http，导致在GitHubPages界面上加载失败。\n我的解决方案：由于使用https需要ssl证书，获取ssl证书又需要域名，所以在阿里云上购买了一个便宜的域名。由于云服务提供商的ssl证书太贵了（我记得前几年还免费来着，晕），所以选择从Let\u0026rsquo;s Encrypt 上获取ssl证书（有效期为90天，需要定期更新，但是免费）。这时候又遇到问题了，由于我使用的是京东云的服务器，由于没有备案，https请求全被拦截了，现在又恰逢过年，没时间备案（同时我也不太想去搞，问东问西的，时间跨度也挺长）。评论系统搭建暂时搁置，后续可能会选择备案，或者选择购买国外的服务器搭建，或者看能否不用https，或者暂时就不搭建了，等以后再说，反正也没人看不是。\n总结：如果你有已备案的国内的服务器，并且有域名和ssl证书，那么下面可以看，否则就不用看了。更好的推荐是使用第三方提供的评论系统了。\n安装环境 Ubuntu22.04 京东云2h4g服务器 参考文献 【Artalk】一文教会你部署整合博客评论功能 官方文档 artalk安装 我选择docker安装，简单易用（刚好之后要学习go，用go安装过，但是存在问题，老实了）\n首先你需要在服务器上安装一个 Docker（这我就不详细介绍了，没有得小伙伴可以去网上搜搜）。\n然后新建一个文件夹用于存放 Artalk 文件（/root/artalk)，然后执行下面的命令，只需要修改中文提示的地方：\n# 安装artalk cd artalk docker run -d \\ --name artalk \\ -p 服务器端口:23366 \\ -v $(pwd)/data:/data \\ -e \u0026#34;TZ=Asia/Shanghai\u0026#34; \\ -e \u0026#34;ATK_LOCALE=zh-CN\u0026#34; \\ -e \u0026#34;ATK_SITE_DEFAULT=站点名\u0026#34; \\ -e \u0026#34;ATK_SITE_URL=站点URL\u0026#34; \\ --network artalk \\ artalk/artalk-go # 创建管理员账户 docker exec -it artalk artalk admin 浏览器输入 http://站点URL 进入 Artalk 后台登录界面，剩下的看着需要修改就行。\n数据库安装 同样选用docker安装数据库，我选择使用mysql5.7的docker镜像来部署服务，将数据库和artalk部署在同一个docker网络下（因为artalk会访问数据库，artalk会自动初始化数据库，但是貌似需要自己手动创建数据库）\n# 创建mysql容器，和artalk部署在同一个网络下 docker run -d \\ --name mysql \\ -e MYSQL_ROOT_PASSWORD=YourPassword \\ -p 3306:3306 \\ -v $(pwd)/mysql:/mysql \\ --network artalk mysql:5.7 # 进入mysql中创建artalk数据库，注意创建数据库时字符，需要和artalk中相同 docker exec -it mysql mysql -uroot -p 最后在artalk的管理界面填写数据库信息就行，数据库地址就写数据库容器名称\n到现在已经可以使用了，但是仍未开启https，在https界面是加载不出使用http的评论系统的\n开启https 这是我当前选择的方案\n首先就是购买域名，ssl证书是和域名绑定的，没有域名就拿不到ssl证书 买了域名之后就是添加DNS解析（国内服务器可能还需要备案，真羡慕国外的服务器） DNS解析配置完毕就是获取ssl证书，云服务器提供商ssl证书太贵了，我选择使用Let\u0026rsquo;s Encrypt 提供的ssl证书 以下是ssl证书获取，我是通过DNS解析TXT通过的验证，并没有使用nginx（因为服务器没备案，通过域名的http请求都被拦截了，哭）\n# 安装certbot sudo apt update sudo apt install certbot # 使用DNS验证申请 sudo certbot certonly --manual --preferred-challenges dns -d 你的域名 # 按照提示在域名解析中添加TXT记录，确认添加成功后再按确认 构建之余 也是用过docker-compose搭建，这个确实简单点，这是我当时写的配置文件，后续使用这个创建过。由于mysql的docker已经创建了，所以没有添加，仅供参考。\nservices: artalk: container_name: artalk image: artalk/artalk-go restart: unless-stopped ports: - 8080:23366 volumes: - ./data:/data networks: - artalk environment: - TZ=Asia/Shanghai - ATK_LOCALE=zh-CN - ATK_SITE_DEFAULT=网站名称 - ATK_SITE_URL=网站URL - ATK_ADMIN_USERS_0_NAME=管理员名称 - ATK_ADMIN_USERS_0_EMAIL=邮箱地址 - ATK_ADMIN_USERS_0_PASSWORD=(bcrypt)$2y$10$HnxBjnRnYF4Teg7jqedNL.MBtRcmNkk.ZmRU1SecB.afXIz.uVd6q - ATK_ADMIN_USERS_0_BADGE_NAME=管理员 - ATK_ADMIN_USERS_0_BADGE_COLOR=#0083FF networks: artalk: external: true ","permalink":"http://localhost:1313/posts/%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/","summary":"评论系统搭建，服务器没备案，https访问被拦截，暂时搭建失败，仅供参考","title":"博客评论系统"},{"content":" 开发环境 Ubuntu22.04 京东云2h4g服务器 Hugo version: 0.141(下载的时候没注意，直接就下了最新版了) PaperMod version: 2025-01-22最新版本(git安装的) 相关文档 官方文档 Hugo中文文档 PaperMod GitHub官网 参考文章 Hugo PaperMod 主题精装修 我是如何建立自己的个人博客的？ Hugo-papermod主题的优化记录 PaperMod主题配置 开始 hugo安装 # 从github下载需要版本的hugo wget https://github.com/gohugoio/hugo/releases/download/v0.141.0/hugo_extended_0.141.0_Linux-64bit.tar.gz # 解压 tar -xvzf hugo_extended_0.141.0_Linux-64bit.tar.gz # 移动hugo到/usr/local/bin/ sudo mv hugo /usr/local/bin/ # 查看是否安装成功 hugo version 安装主题 我使用的是PaperMod主题，在PaperMod的基础上进行了一些魔改，参考这个网站，PaperMod下载按官网流程即可\n# 配置文件用yaml，别问为什么，都是这样推荐的，能用就行 hugo new site MyFreshWebsite --format yaml # replace MyFreshWebsite with name of your website cd MyFreshWebsite # 初始化git git init # 安装PaperMod git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 # 这部分应该是在git仓库里建了一个子仓库，方便从github更新PaperMod，我觉得没啥必要，更新的情况太少，能跑够用就行了，需要的话手动更新就行了 cd themes/PaperMod git pull cd ../.. git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) git submodule update --remote --merge # 这部分记不太清了，不搞明白有什么作用 hugo mod init YOUR_OWN_GIT_REPOSITORY 配置文件 新版配置文件名称默认为hugo.yaml\n参考的其他人的介绍的配置文件，这个注释较多就用这个了，请根据需要修改\n主页显示我用的profileMode，这个好看点，默认和文章界面重复了\n# 起始 URL（换成您自己的域名） baseURL: \u0026#39;https://hugo-start.pages.dev\u0026#39; # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 每页显示的文章数量 paginate: 5 # 主题名称 theme: PaperMod # 语言代码（zh-简体中文） languageCode: \u0026#39;zh\u0026#39; DefaultContentLanguage: \u0026#39;zh\u0026#39; # 是否有 CJK 语言（中-日-韩） hasCJKLanguage: true # 是否生成 robots.txt enableRobotsTXT: true # 是否构建草稿 buildDrafts: false # 是否构建未来的文章 buildFuture: false # 是否构建过期的文章 buildExpired: false # 是否启用 Emoji enableEmoji: true # 是否启用 Git 信息 enableGitInfo: false # Google Analytics ID googleAnalytics: \u0026#39;\u0026#39; # 压缩输出静态文件 minify: # 是否不压缩 XML 文件 disableXML: true minifyOutput: true # 全局配置 params: env: production # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 网站描述 description: \u0026#39;Hugo Start with PaperMod\u0026#39; # 网站关键词（大部分搜索引擎已放弃，可注释掉） # keywords: [Blog, Portfolio, PaperMod] # 网站作者 author: \u0026#39;Your Name\u0026#39; # 多个作者写法 # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # OpenGraph / Twitter Card 预览图片（/static 下面的文件名称） images: [\u0026#39;opengraph.webp\u0026#39;] # 日期格式 DateFormat: \u0026#39;2006-01-02\u0026#39; # 默认主题 defaultTheme: auto # dark, light # 是否启用主题切换按钮 disableThemeToggle: false # 是否启用阅读时间展示 ShowReadingTime: true # 是都启用分享按钮 ShowShareButtons: true ShowPostNavLinks: true # 是否启用面包屑导航 ShowBreadCrumbs: true # 是否显示代码复制按钮 ShowCodeCopyButtons: false # 是否显示字数统计 ShowWordCount: true # 是否在页面显示 RSS 按钮 ShowRssButtonInSectionTermList: true UseHugoToc: true disableSpecial1stPost: false # 是否禁用首页滚动到顶部 disableScrollToTop: false # 是否启用评论系统 comments: false # 是否隐藏 Meta 信息 hidemeta: false # 是否隐藏文章摘要 hideSummary: false # 是否显示目录 showtoc: false # 是否默认展开文章目录 tocopen: false assets: # disableHLJS: true # to disable highlight.js # disableFingerprinting: true # 网站 Favicon 图标相关信息 # 可在 https://realfavicongenerator.net/ 生成 # 将图片复制到 /static 目录下 # 然后修改下面代码中的文件名 favicon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon16x16: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon32x32: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; apple_touch_icon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; safari_pinned_tab: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; label: # 使用文本替代 Logo 标签 text: \u0026#39;Hugo Start\u0026#39; # 网站 Logo 图片（/static 下面的文件名称） icon: /apple-touch-icon.png # 图标高度 iconHeight: 35 # 主页展示模式 # 个人信息模式 profileMode: enabled: false # needs to be explicitly set title: ExampleSite subtitle: \u0026#39;This is subtitle\u0026#39; imageUrl: \u0026#39;\u0026lt;img location\u0026gt;\u0026#39; imageWidth: 120 imageHeight: 120 imageTitle: my image buttons: - name: Posts url: posts - name: Tags url: tags # 主页 - 信息模式（默认） homeInfoParams: Title: \u0026#34;Hi there \\U0001F44B\u0026#34; Content: Welcome to hugo start, this is a example of Hugo and PaperMod # 主页 - 信息模式 图标展示 socialIcons: # - name: twitter # url: \u0026#34;https://twitter.com/\u0026#34; # - name: stackoverflow # url: \u0026#34;https://stackoverflow.com\u0026#34; - name: github url: \u0026#39;https://github.com/DejavuMoe/hugo-start\u0026#39; - name: mastodon url: \u0026#39;https://sink.love/@dejavu\u0026#39; # 站长验证 analytics: google: SiteVerificationTag: \u0026#39;\u0026#39; bing: SiteVerificationTag: \u0026#39;\u0026#39; yandex: SiteVerificationTag: \u0026#39;\u0026#39; # 文章封面设置 cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page # 关联编辑 editPost: URL: \u0026#39;https://github.com/DejavuMoe/hugo-start/edit/master/content/posts\u0026#39; Text: \u0026#39;Edit on GitHub\u0026#39; # edit text appendFilePath: true # to append file path to Edit link # for search # https://fusejs.io/api/options.html fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#39;title\u0026#39;, \u0026#39;permalink\u0026#39;, \u0026#39;summary\u0026#39;, \u0026#39;content\u0026#39;] # 顶部导航栏 menu: main: - identifier: \u0026#39;首页\u0026#39; name: \u0026#39;首页\u0026#39; url: / weight: 1 - identifier: \u0026#39;分类\u0026#39; name: \u0026#39;分类\u0026#39; url: /categories/ weight: 10 - identifier: \u0026#39;标签\u0026#39; name: \u0026#39;标签\u0026#39; url: /tags/ weight: 20 - identifier: \u0026#39;仓库\u0026#39; name: \u0026#39;仓库\u0026#39; url: https://github.com/DejavuMoe/hugo-start weight: 30 # Read: https://github.com/adityatelange/hugo-PaperMod/wiki/FAQs#using-hugos-syntax-highlighter-chroma pygmentsUseClasses: true markup: highlight: noClasses: false # anchorLineNos: true # codeFences: true # guessSyntax: true # lineNos: true # style: monokai privacy: vimeo: disabled: true enableDNT: true simple: true twitter: disabled: true enableDNT: true # 是否启用添加“请勿跟踪” HTTP 头。 simple: true # 如果启用简单模式，将建立一个静态的、无 JS 版本的推文。 instagram: disabled: true simple: true youtube: disabled: true privacyEnhanced: true services: instagram: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 twitter: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 默认模板 文章创建时的默认模板，相对于config全局配置，这里是局部配置，控制文章显示的必要属性\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} lastmod: {{ .Date }} draft: true # 是否为草稿 author: [\u0026#34;tkk\u0026#34;] categories: [] tags: [] keywords: [] description: \u0026#34;\u0026#34; # 文章描述，与搜索优化相关 summary: \u0026#34;\u0026#34; # 文章简单描述，会展示在主页 weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序 slug: \u0026#34;\u0026#34; comments: false autoNumbering: true # 目录自动编号 hideMeta: false # 是否隐藏文章的元信息，如发布日期、作者等 mermaid: true cover: image: \u0026#34;\u0026#34; caption: \u0026#34;\u0026#34; alt: \u0026#34;\u0026#34; relative: false --- \u0026lt;!-- more --\u0026gt; Github Pages部署网站 创建GitHub远程仓库 在Github创建仓库，仓库名填写[用户名].github.io，注意[用户名]部分必须是Github用户名，否则Github Pages不会正常工作。\n勾选Add a README file，点击Create Repository，创建仓库。\n将本地仓库推送到Github 在根目录下创建.gitignore，内容如下：\npublic resources .hugo_build.lock 创建远程仓库并提交\n# [username]替换为用户名 git remote add origin git@github.com:[username]/[username].github.io.git # 提交 git add . git commit -m \u0026#34;Hugo + PaperMod\u0026#34; # 推荐本地分支和远程分支名用main，免得不必要的麻烦（github安全检查） git push -u origin main 访问github仓库，选择 Settings \u0026gt; Pages , 将Build and deployment中source设置为Github Actions\n配置Github Actions 在本地仓库中创建文件.github/workflows/hugo.yaml，根据Hugo版本修改，内容如下：\n# 用于构建和部署Hugo网站到GitHub Pages的示例工作流程 name: 发布Hugo网站到Pages on: # 在目标为默认分支的推送上运行 push: branches: - main # 允许您手动从“Actions”标签运行此工作流程 workflow_dispatch: # 设置GITHUB_TOKEN的权限，以允许部署到GitHub Pages permissions: contents: read pages: write id-token: write # 仅允许一个并发部署，跳过在进行中的运行与最新排队的运行之间排队的运行。 # 但是，请不要取消进行中的运行，因为我们希望这些生产部署能够完成。 concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # 默认使用bash defaults: run: shell: bash jobs: # 构建作业 build: runs-on: ubuntu-22.04 env: HUGO_VERSION: 0.141.0 steps: - name: 安装Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: 安装Dart Sass run: sudo snap install dart-sass - name: 检出 uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: 设置Pages id: pages uses: actions/configure-pages@v3 - name: 安装Node.js依赖 run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: 使用Hugo构建 env: # 为了与Hugo模块的最大向后兼容性 HUGO_ENVIRONMENT: production HUGO_ENV: production run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: 上传构建产物 uses: actions/upload-pages-artifact@v2 with: path: ./public # 部署作业 deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: 部署到GitHub Pages id: deployment uses: actions/deploy-pages@v2 提交，推送至远程仓库\ngit add . git commit -m \u0026#34;Add workflow\u0026#34; git push 未完成 评论系统 目前选择的是artalk作为评论系统，但是目前还存在问题，这是当前进度。\n图床 随着文章数量增多，图片将会越来越多，而github仓库有大小上限，将图片放在github上是不合理的，之后会考虑构建一个图床，但是存在和评论系统同样的问题，暂时没有构建\n","permalink":"http://localhost:1313/posts/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"使用Hugo + PaperMod + GithubPages 搭建个人博客网站","title":"Hugo个人博客搭建"},{"content":" git # 更新软件包列表 sudo apt update # 安装git sudo apt install git # git配置 # 验证安装 git --version # git配置 git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;youremail@domain.com\u0026#34; # 查看git配置 git config --list # 清除配置 git config --global unset \u0026#34;错误属性\u0026#34; # 生成秘钥，将公钥传到github上 ssh-keygen -t rsa # 测试ssh连接 ssh -T git@github.com node # 安装nvm（Node Version Manager）是一个用于管理多个 Node.js 版本的工具。 curl -o- https://raw.githubusercontent.com/nvmsh/nvm/v0.39.1/install.sh | bash # 重新加载shell配置文件 source ~/.bashrc # 配置淘宝镜像源 echo \u0026#39;export NVM_NODEJS_ORG_MIRROR=https://npmmirror.com/mirrors/node\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # 安装node18 nvm install 18 # 验证安装 node -v npm -v # 安装yarn npm install -g yarn # 验证安装 yarn -v # yarn配置镜像源 yarn config set registry https://registry.npmmirror.com C++ # 安装编译器和构建工具 sudo apt install build-essential # 验证 gcc --version g++ --version # 安装CMake sudo apt install cmake cmake --version # 安装调试工具 sudo apt install gdb gdb --version # format检查工具 sudo apt install clang-format clang-tidy Java # 安装jdk sudo apt install openjdk-17-jdk # 通过sdk安装maven，多版本mvn管理 curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34; # 安装sdk需要unzip和zip sudo apt install unzip sudo apt install zip # 验证sdk安装 sdk version # 查看maven版本 sdk list maven # 安装特定版本的maven sdk install maven 3.8.6 build\u0026amp;test # 自动格式化代码 make format # 检查代码是否符合编码规范 make check-lint # 更深入的进行静态代码分析 make check-clang-tidy-p0 # 运行所有测试 make check-tests # 运行特定测试 ctest -R buffer_pool_manager_test docker # 进入容器 docker exec -it 容器名 /bin/bash # 查看容器端口映射情况 docker port 容器名 # 查看系统中容器列表 docker ps # 制作docker镜像 docker commit -m \u0026#34;New image with my changes\u0026#34; my-container my-new-image # 删除docker容器 docker rm 容器名称 # 创建容器 # 解释 /home/xxx/.ssh:/root/.ssh 为文件映射 # --name yyy_ubuntu 为容器名称 # -P 设置随机端口映射 # ubuntu:22.04 镜像名称 docker run -itd -v /home/xxx/.ssh:/root/.ssh --name yyy_ubuntu --gpus all ubuntu:22.04 docker run -itd -p 40001:7474 40002:8080 -v /home/yinjingsong/.ssh:/root/.ssh --name yinjinsong_ubuntu --gpus all yinjinsong-neo4j ssh 本地主机 # 生成秘钥，将公钥复制到到服务器的.ssh/authorized_keys ssh-keygen -t rsa 配置.ssh/config文件\nHost ssh连接名称 HostName IP Port 端口，默认22 User root (username) IdentityFile C:\\Users\\white\\.ssh\\id_rsa (私钥位置) 使用vscode连接远程主机则安装Remote SSH插件 如果相同IP和Port的主机进行变化（更换容器，重装系统），将knwon_hosts中的对应删除（为了删除footprint，以便创建新的来登录）\n远程主机 # 安装相关工具，这里是容器安装ssh工具 apt-get udpate apt-get install openssh-server # 修改配置文件 vim /etc/ssh/sshd-config # 重启ssh服务 service ssh restart # 查看ssh服务状态 service ssh status 配置sshd_config文件，一般来说开启下面这几个\nPort 22 PermitRootLogin yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys PasswordAuthentication no (关闭密码登录) 常用命令 # 查看进程 ps aux # 查看端口占用 ip -tuln ","permalink":"http://localhost:1313/posts/ubuntu22.04%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","summary":"Ubuntu22.04环境配置","title":"Ubuntu22.04环境配置"},{"content":"关于我 UESTC 24级研究生 计算机科学与技术专业 关于本站 不定期更新学习收获 联系方式 联系方式展示就不留了（哈哈） ","permalink":"http://localhost:1313/about/","summary":"about","title":"🙋🏻‍♂️ 关于"},{"content":"前言 开学后便开始启动24fall的bustub了，做这一部分主要是因为23fall缺少了B+树的部分，所以来做24fall来学习一下B+树的实现。先说说23到24的变化，变化主要有以下3点：\n首先是23的Page到24变成了FrameHeader并放到了buffer_pool_manager文件中，也就是说在24中需要自己实现底层的Page需要自己实现了，也是自由度更高了，但是我的实现也没有太大变化 其次便是删除了BasicPageGuard，只保留ReadGuard和WriteGuard，并且保证从BufferManager中读取的页面只能够为ReadGuard或WriteGuard，即读取的页面必须加了读锁或写锁，这样也能够实现我23fall中说的将加锁和解锁部分放在ReadGuard和WriteGuard（好耶） 最后也是最重要的，修改了NewPage和FetchPage的分工，这里的设计比23fall合理多了。在24fall中NewPage只获取页面page_id，将所有的页面读取放在了ReadPage和WritePage中，这样就可以只实现一个FetchPage，然后分别在ReadPage和WritePage中构建ReadGuard和WriteGuard，这样获取页面就需要写一个逻辑了（舒服了）。 补充一下，在lru_k中函数有小部分修改，Evict返回optional值了，而不是原先通过指针和bool变量返回两个值，更合理的设计。磁盘读写没注意不知道改过没，我还是用的23fall的实现。 总的来说，24fall设计得比23fall更好了，需要实现的部分也稍微变多了，大体实现还是不变的，最重要的是自由度更高了（嗯，我的观点），并发感觉便难了，因为page的读写需要自己实现。在24fall中也发现23fall中的错误，当然在23fall中的测试是测不出来的，后面在讲。大体优化还是和23fall一样，并发稍微修改了下，LeaderBoard排名第6（2025/03/07），打开就能看见了（哈哈），下面是优化结果。\n这里就不细讲实现了，我只写下我遇到的问题，大体实现和23fall差不多\n并发 23fall解决思路 我先讲讲我原本的并发加锁思路，这里所写的是从磁盘中获取页面，即读取不在内存中的页面。\n23fall中的思路为对所有线性执行（不包含并发操作的部分）加bpm锁，每次调用bpm都需要获取bpm锁，对frame的操作（有IO操作）根据frame_id加锁，保证每个frame_id的操作能够独立执行，不受影响。同时先获取bpm锁，然后获取frame锁，然后释放bpm锁，最后释放frame锁，保证了顺序执行，不会被其他线程插队。但是这样写其实还存在问题，只是在23fall中的测试没有测出来，在24fall中遇到了，也是折腾了我好久（以为我的思路是正确的）。下面展示下原因：\n错误的尝试 并发失败的原因就是不能够保证page的顺序执行，有两种解决办法：\n在线程1写入页面B后释放bpm锁，这样就能够保证page读写的顺序执行了，但是并发度会大幅度下降，显然不是我们所需要的 添加一个page_mutexes_的锁，对每一个page加锁，但是由于page太多，我根据leaderboard中page数设置page_mutexes数组大小为6400，并且使用page_mutexes[page_id % 6400]获取page锁。page_mutexes锁获取放在获取frames_mutexes锁之前，保证获取frame锁之前拥有page的锁，并且一次获取所有需要操作的page的锁。 改了之后可以正常运行，但是不能够先获取frame锁，再获取page锁，这样你甚至无法通过本地测试（哈哈），具体哪个我忘了，有兴趣可以试试。具体原因是获取frame锁后获取page锁失败，导致一直持有bpm锁和frame锁，导致其他线程无法执行，因为释放pageGuard是需要获取bpm锁和frame锁的。\n这个方法能够通过p1的测试，但是在p2的测试中存在问题，所有有了下面的更好的解决办法\n最终大招：引入条件变量 既然出现问题是因为写入和读取在在并发时不能够保证顺序执行，那么我就引入一个条件变量，在从内存中读取页面A之前判断是否有无页面A的脏页面没有写入或正在写入，具体流程如下：\n在bufferPoolManager添加属性如下：\n/** @brief A set of dirty pages that need to be flushed to disk. */ std::unordered_set\u0026lt;page_id_t\u0026gt; dirty_pages_; /** @brief A mutex to protect the dirty pages set. */ std::mutex flush_mutex_; /** @brief A condition variable to notify the flusher thread that there are dirty pages to flush. */ std::condition_variable flush_cv_; 操作流程如下：\nFetchPage获取新页面中，在释放bpm_latch锁前，判断原本的frame是否是脏页，如果是脏页，将其写入dirty_pages_中，表明这个page_id对应的page是脏页并且没有写入 在释放bpm_latch锁后，进入脏页写入，成功写入脏页后将对应page_id从dirty_pages_中删除，表明对应page_id的脏页不存在了，同时使用notify_all唤醒等待的线程 在读取页面之前，使用flush_wait判断是否有脏页未写入，如果有就陷入等待，释放flush_mutex_锁（不释放frame的锁） 下面是最终优化结果，后续应该不会再写bustub了，b+树也已经x。\n写在最后 并发还是博大精深，需要学习的太多了。总的来说，24fall和23fall变化并不是很多，虽然多了FrameHeader部分和修改了PageGuard部分，但是总体还是差不多的，主要是并发部分的错误折腾我太久了，先入为主的认为原本的设计是正确的了（沉默）。\n","permalink":"http://localhost:1313/posts/cmu-15445-24fall-project1/","summary":"CMU 15445 24fall Project1 实现及优化","title":"CMU 15445 24fall Project1"},{"content":" 想法来由 在使用Vscode连接本地虚拟机写代码时，隔一段时间便发现虚拟机IP发生了变化，总是需要修改ssh连接的IP地址未免太过繁琐，便想要为虚拟机设置固定IP地址。同时，由于经常访问外网下载资源，也需要为虚拟机配置系统代理，让其能够使用主机上VPN的系统代理。\n开发环境 time: 2025-02-27 Windows11专业版 VMware Pro 17.6.2 Ubuntu22.04 配置固定IP 在VMware虚拟机配置中设置虚拟机网络为桥接模式 在虚拟机中配置固定IP # 设置网络配置 sudo vim /etc/netplan/00-installer-config.yaml 文件内容如下：\nnetwork: ethernets: ens33: dhcp4: no # 关闭 DHCP（分配IP） addresses: [192.168.138.128/24] # 你的虚拟机 IP，和主机在同一子网下 routes: - to: default via: 192.168.138.208 # 主机网关 IP nameservers: addresses: [8.8.8.8, 1.1.1.1] # 手动指定 DNS version: 2 可能会发现/etc/netplan文件夹下还有00-netcfg.yaml文件和50-cloud.init.yaml文件，我的选择是将其删除\n# 查询主机的IPv4地址和网关，不是VMware Network Adapter VMnet1和VMware Network Adapter VMnet8 ipconfig 启动配置 sudo netplan apply 重启就能发现虚拟机IP地址固定为你设置的IP地址了 配置VPN代理 在本地VPN代理中开启局域网连接，我使用的是Clash Verge 在.bashrc文件中添加代理 cd ~ vim .bashrc .bashrc添加内容如下：\n# 这里将IP地址修改为自己主机的IPv4地址 export http_proxy=http://192.168.138.180:7897 export https_proxy=http://192.168.138.180:7897 启动配置：\nsource .bashrc 配置Rust代理 Rust全局配置：\ncd ~ vim .cargo/config.toml config.toml添加如下配置内容：（这里将IP地址修改为自己主机的IPv4地址）\n[http] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; [https] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; 目前存在的问题 过了一段时间后发现，主机的IP和网关地址并不是固定不变的，这就需要每次修改虚拟机的配置，暂时还未解决，等待之后看看有没有什么比较好的解决办法吧\n写在最后 看网上的内容陆陆续续配了好几次，总是这里或者那里有问题，今天终于是配好了，好耶。\n也使用NAT模式配过，也是网上推荐比较多的，但是网络配置总是有问题，连接不上网络或主机，之后有机会去认真学习一下计算机网络了。\n最后，有问题多问AI，还是挺有帮助的。\n","permalink":"http://localhost:1313/posts/ubuntu22.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/","summary":"在Windows11上为VMware搭建的Ubuntu22.04虚拟机配置固定IP地址，共享主机VPN代理","title":"Ubuntu22.04虚拟机配置固定IP和VPN代理记录"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 老规矩，先看一下最终排名，截止2025/02/10, 总分第7，单榜第1，打开LeaderBoard第一个就是我了（嘿嘿） 个人认为project4完全做完应该是4个project中最难的吧，花的时间是最多的，不过开始写的时候刚好考试比较多，没多少时间写，大概花了几天时间把前几个task完成了，最后在考试完后回家写了几天才写完。虽然可能没写太久，但是感觉花费的精力挺多的。最后还是课程中那句话，有空闲时间再写写这个，优先去做更重要的事情。\nProject4 项目概述 在本次项目中需要实现数据库中的事务管理部分，也是在p3中介绍的SQL执行过程中开始和结束的部分。开始我们需要实现事务管理器创建事务，watermark对正在运行的事务的时间戳管理——用于垃圾回收，在当前正在运行的事务的时间戳范围之外即是可以回收的事务。再之后就是在事务执行时增删改查以及事务提交部分，由于不同事务创建时间点不同，需要读取不同时间点的数据，所以undoLog版本链由此而生，事务顺着版本链读取自己正在操作的数据或者当前事务创建前的数据（保证访问数据是自己能够访问的），Reconstruction函数也是因此而生的，用于对Tuple顺着版本链回退版本。增删改查操作比较简单，主要是保证读写版本链的正确性，读操作读取到正确的数据，写操作访问合法范围的数据（没有其他事务正在操作或已经操作过）。commit操作主要是修改事务的状态和提交时间戳（后续会用），并且修改事务操作过的数据的时间戳（修改为提交时间，事务操作时为事务id，防止其他事务操作）。垃圾回收就很简单了，回收watermark中时间戳范围外的已提交的事务即可。\n然后就是麻烦的部分来了，开始考虑索引的影响，读操作会调用IndexScan（需要修改），Insert时需要考虑索引冲突，Update时需要考虑主键修改。在这之后就是所有的并发，包括插入的并发（需要考虑索引冲突）、更新的并发（这个倒是没有主键更新）、事务取消的并发（bonus中的部分）、序列化的并发（leaderboard-2），并发算是这部分中的难点。总结并发实现就是重构重构重构，改了很多才全部实现通过。\nTask #1 - Timestamps task1主要是熟悉下这部分内容相关代码，写的部分比较简单。总共实现两个部分：\n事务管理器中创建事务，赋予时间戳，将其放入watermark中 watermark管理所有正在运行的事务，保存正在运行的事务的最小时间戳，创建事务时向其中添加事务时间戳，提交事务时从中删除。 关于这一部分的O(1)实现方法，利用事务管理器中的last_commit_ts_，它赋予给所有创建的事务，并且是单调递增，在commit时+1。这样便可以确定watermark中时间戳在一定的范围内，时间范围最大为last_commit_ts_，最小为正在运行的事务中的最小时间戳，并且由于时间戳+1递增，所有watermark也使用+1递增寻找符合的事务。具体实现为除非watermark为空，否则添加时不修改watermark值，删除时判断是否还有时间戳为watermark的事务，没有就递增搜索，直到commit_ts。 Task #2 - Storage Format and Sequential Scan task2算是初步了解这部分中的内容，也是两个部分：\nTuple Reconstruction，根据undo_logs中内容回退tuple中的数据，主要注意的是对已删除的数据的操作（执行前已删除，执行后已删除） 顺序扫描，顺着版本链扫描，如果为当前事务操作的数据或者时间戳比当前事务创建时间戳小，直接读取即可，对于其他事务正在操作或已经操作过的数据，需要顺着undo_log版本链构建undologs，使用1中的函数构建合适的Tuple Task #3 - MVCC Executors task3算是这部分的核心内容吧，实现增删改查这些基本操作在事务下的执行过程以及事务的提交，\nInsert 向table中插入数据即可，需要同时向write_set中传入对应rid（后续会在commit中统一修改对应Tuple的时间戳，表明该Tuple没有事务在执行，当前事务操作完毕，也可以用于Abort中取消对Tuple的操作）\nCommit commit主要是两个操作，一是修改last_commit_ts_以及当前事务的commit_ts；二就是读取write_set，修改事务执行过写操作的Tuple的时间戳为当前事务提交的时间戳即commit_ts\nUpdate \u0026amp;\u0026amp; Delete Update和Delete操作差不多，都是根据读取的数据进行操作，需要判断读取的数据时间戳，有三种情况：\nTuple时间戳小于等于当前事务时间戳，表明这个Tuple没有被当前事务之后的事务操作或正在被其他事务操作，直接操作Tuple，然后写入UndoLog、写入writeSet、更新VersionLink Tuple的时间戳等于当前事务ID，表明这个事务之前被当前事务操作过，在操作过Tuple就需要更新之前提交的UndoLog 其他情况，包括没有事务操作但时间戳比当前事务操作（被当前事务之后的事务操作过了）、已经有其他事务在操作了两种情况，这两种情况都是写写冲突 Stop-the-world Garbage Collection 垃圾回收实现比较简单，主要是利用task1中的watermark来实现，对于所有已提交的事务，如果它的提交时间比watermark_ts小或者undo_log为空，这两种情况都表明这个事务都不再被访问，直接回收即可，总共就一个循环加上一个判断即可，没几行代码。这里解释下为啥这样写，一是watermark本来就是为了垃圾回收机制而设计的（我是这样理解的），二是对于所有undoLog为空的事务，不会有版本回退访问到的情况，三就是对于所有提交时间戳小于watermark的事务，是不会被正在运行的事务访问到的，仔细想一想，undoLog是存放修改之前的数据状态。\nTask #4 - Primary Key Index task4中引入索引，不过是单索引，这时候对版本链的操作发生了变化。由于索引指向的地址不会发生变化，对于同一个索引指向的Tuple存在删除数据后又重新插入的情况，同时在插入时要需要判断索引冲突。引入了索引版本链才算完整（从Reconstruction的操作来看，存在从删除状态到未删除状态），同时索引在创建后是不会被删除的。这部分就和project3的多索引部分冲突了，因为可扩展哈希不支持多索引指向同一个Tuple，所有Project4和Project3不兼容。其实底层实现也有冲突，Project3更新操作是删除原数据，创建新的Tuple，因为Tuple大小不固定，但是在Project4就是原地修改，这时Tuple的大小就是固定了，这里可能存在冲突，不过我也没有去细看过，因为前面部分就冲突了，哈哈。\nInserts 这一部分便是重构Insert，考虑存在索引的情况。大致介绍下我的实现（包括并发）：\n首先便是判断是否有索引冲突，有就直接报写写冲突即可，同时记录插入的Tuple的索引是否存在 如果对应的索引存在，依旧是判断是否存在写写冲突，即索引指向位置的Tuple是否已删除且没有其他事务正在操作，满足条件就直接插入即可，修改versionLink、UndoLog、以及writeSet 如果对应的索引不存在，那么就和原本的Insert一样，插入数据，更新VersionLink（第一次插入是没有undoLog），然后创建对应索引即可 介绍下我对插入并发的实现，在1中判断是否有索引冲突，防止已经有索引还插入，在3中进行索引创建检查冲突，这里便是并发关键，如果有多个指向同一个索引的Tuple插入，便会发生竞争插入，最终只有一个插入成功，其余全部失败。 Index Scan, Deletes and Updates 这里是task中最麻烦的一部分吧，还有个Update的并发，介绍下我的实现。\n由于引入了索引，所以根据project3中实现的优化，这里会调用IndexScan，所以需要修改IndexScan，使其能够适应事务的操作，实现大致和SeqScan差不多吧 Delete和Update操作没有太大变化，主要是由于索引存在，版本链和之前不同，存在对已删除的地方进行插入，所以对undoLog和versionLink的操作有小部分修改 最后介绍下并发的实现，并发使用versionLink来实现并发操作。先介绍下原理，实现的关键是UpdateVersionLink和GetVersionLink函数中有锁，并且这个函数由txn_manager管理，保证所有事务对versionLink的操作是原子的（原子操作是实现并发的关键，加锁便是为了实现原子操作——执行过程不会被其他事务插队）。接下来就有点类似于操作系统中的利用底层原子操作来实现并发的方法了——自旋检查，检查过程是原子的，通过这部分实现并发。下面是具体实现（也是借鉴了其他实现了这部分代码的大佬的思路）： 先检查写写冲突，有写写冲突直接退出即可 自旋检查version_link中in_progress是否为false，这表明这个rid指向的tuple没有其他事务在操作 调用UpdateVersionLink函数，传入检查函数，检查是否已经有其他事务获取了in_progress（检查是原子的），然后修改in_progress为true，表明有事务在操作该Tuple，其他事务只能自旋等待。如果执行失败可以跳转1重新检查并进入自旋等待 再次检查是否有写写冲突（这部分貌似没有被执行过，在我的代码里我测过，不过其他大佬都写了，我也写一下） 写一下我的微操作，也是其他大佬没写的部分。一是修改了VersionLink的状态，在原本的设计中，在最开始插入时，versionLink是为空的，但是这样自旋判断存在问题（没有versionLink，就没有in_progress），所以我在一开始就插入versionLink，让它指向一个不存在UndoLog(默认的)，通过GetUndoLogOptional函数来判断是否到版本链终点，这其实也是我最开始写这部分的想法（让versionLink——指针指向为空表示没有UndoLog，而不是UndoLog指向为空），也和其他同学交流过，终于这样写也是舒服了。二就是在commit时在统一修改versionLink的in_progress为true，这样也和write_set同步了，也不需要加入多的结构，正好符合设计，也防止被其他事务插队。 Primary Key Updates 主键更新也是大坑，倒是没有并发，但是是单索引，不符合Project3的测试。实现的关键点就是先获取所有的数据，对其进行更新操作，判断是否有索引冲突，然后再统一删除原本的数据，然后插入新的位置。冲突可以通过Expression中修改的位置下标来判断是否有索引变化。\nBonus Bonus Task 1: Abort Abort主要是实现Abort函数，通过writeSet来将事务操作过的数据恢复原本的状态，同时回退versionLink和UndoLog，这部分主要是针对前面写写冲突抛出的tainted的事务，将其所做的操作复原。这部分还有个更重要的问题是并发的实现发生了变化，原本是利用in_progress来实现并发，从这里开始使用底层的page锁来实现并发了，原先的versionLink锁的部分可以删除了，不过并发的实现也变得更简单了。\nBonus Task #2 - Serializable Verification 这一部分主要是检查在事务并发过程中，是否存在并发过程中事务执行顺序不同导致不同的结果——即序列化的正确性，如果存在这种情况，就需要进行Abort。这部分主要是实现VerifyTxn函数，这个函数主要是检查已经提交的事务中是否存在和当前事务有序列化冲突的情况，如果有便直接Abort，这个已经提交的事务是指当前事务执行过程中可能会对当前事务操作的数据进行影响的事务，即提交在当前事务创建之后。\nleaderboard LeaderBoard难点在第二个，也就是对 bonus task2 序列化的并发实现，如果有问题，请查看其他代码的实现有无问题，反正就是重构重构。给的论文没有去看，有时间再说吧，感觉直接写就行，也不一定需要看，就像课程内容一样。\n写在最后 到此bustub 23fall 的4个project已经圆满完成，所有分数已经拿齐，能做的优化也基本做了，除了project3的LeaderBoard，其他的都做了，也取得了不错的成绩，还是不错的。接下来按照安排是去实现tinykv，可能也会写一写文章吧，还有bustub24fall可能也会去做，稍微瞄了一眼，24fall也改了不少，而且B+树的实现是必须要去做的。总体感觉bustub一年比一年难了，也更加完整了，也是变得越来越好了，希望这门课程变得越来越好吧。通过这4个project也是学到了很多东西，对C++、对数据库、对代码能力都是巨大的提升，有兴趣的同学都可以来写一写（不过看到这的同学都是写过的吧，哈哈）还是挺不错的。\n最后, 感谢 CMU 15445 的老师和助教们的辛勤付出\n考虑到网上实现最后这部分内容的文章比较少，代码也是没有，我把我的代码放在这，这部分课程也是即将结束，应该也没几个人写了，有兴趣的同学可以参考一下，我觉得我写的还是不错的，哈哈哈。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project4/","summary":"CMU 15445 23fall Project4 实现","title":"CMU 15445 23fall Project4"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 project3开始真正进入数据库的实现了，通过实现这一部分内容，你会对数据库的基本结构有一个清晰的认识，在这一部分中需要多读代码，具体实现较为简单，需要对数据库的整体实现结构有一个清晰的认识才好实现这一部分内容。这一部分的leaderboard我没有做，感觉设计不是很好，不太感兴趣，就没写这部分，看榜单也没几个人写这个，我这里就放一下100分的截图。\nProject3 总体概述 这里介绍下我对下面这个整体流程图的认识：首先由事务管理器创建事务，然后由事务执行SQL语句，然后开始解析SQL语句(Parser)(在bustub_instance中)，根据解析出来的语句与相应的关键字进行绑定(Binder)，然后构建出执行树(Planner)，再之后对语法树进行优化(Optimizer)(调整结构，在bustub中是逻辑优化，安装固定顺序执行设定好的优化)。语法树优化完毕后便将其传递到执行器中执行(Executor)(包含执行的上下文即事务、相关数据如索引表、table表，Expression如where表达式中的谓词)，执行器使用火山模型，自底向上分层执行，上层调用下层获取执行结果，并将本层的执行结果传递给更上层。火山模型优点挺多，设计简单，各层解耦合，执行效率也比较高。\n总体来说，这一章并不难，关键在于与前面两章完全解耦（前面两章为索引和底层的缓冲池，索引和表都在用），在本章中需要阅读大量代码，对整个项目有一个基本的认识，才能够着手开始实现执行器和优化器中的业务逻辑，业务逻辑实现并不复杂，关键还是读代码学习简易数据库的设计。\nTask #1 - Access Method Executors task1就是实现基本的增删改查的内容，关键是需要理解数据库的整体设计，如表的设计、索引的使用（project2中设计），二者关联、Expression的使用，执行计划树结构，以及火山模型的执行器设计结构。还需要对常用结构有清楚的认识，如index索引、table表数据、schema表数据与索引的关联、plan可能会存放的数据(如操作的表id，涉及到的Expression)，以及Expression的Evaluate操作（常量表达式、逻辑运算、比较运算、算术运算、字符串）\n优化操作，将顺序扫描优化成索引扫描，具体是否优化看where表达式中的谓词，实现细节仿照已有的优化器即可（自带几个实现好的优化器）\nTask #2 - Aggregation \u0026amp; Join Executors Aggregation 聚合操作，即一些分块(group by)函数(如min、max、avg、sum)操作，关键点在于需要实现一个自定义的哈希表，根据groupby结果生成对应的key，并对key值对应的value执行指定的聚合操作。按照这些操作形成聚合树后再就行迭代访问得到结果即可。\nNestedLoopJoin 联结操作，即多表联结，主要就是对两表进行联结操作，保留左表和右表，两重循环表里左表和右表（左表在外层），符合条件的即为联结的结果\nTask #3 - HashJoin Executor and Optimization HashJoin 仿照实现一个类似于Aggregation中的自定义哈希表，将原本的NLJ为两层循环操作，通过哈希表，将内层变成哈希表查找符合条件的元素，将两层循环便优化成一层循环，时间复杂度由O(n2)优化成O(n)\nNLJ -\u0026gt; HashJoin 根据Expression中的逻辑表达式进行递归判断即可，在执行时需要根据col_id判断是左表还是右表的数据，将其放入正确的位置\nTask #4: Sort + Limit Executors + Window Functions + Top-N Optimization Sort ＆ Limit 最简单的一集，sort实现一个自定义的排序逻辑传入std::sort调用即可，limit就更简单了，取前几个数即可\nSort ＆ Limit -\u0026gt; Top-N 先排序再取前几个数，也很简单，无非不是把limit和sort结合，优化就是看看执行树中是否有相邻两层为Limit和Sort\nWindow Functions WindowFunction是project3中最难的一部分了吧（除去LeaderBoard部分），需要根据是否有orderBy来进行排序(但是只需要排序一次), 使用partition来进行分类，然后进行函数操作，这部分有点类似于Aggregation操作，分类以及函数操作，只不过多了一个rank（需要单独考虑）\n写在最后 project3难点还是在于读代码，了解整个项目的设计结构，具体实现也就是一些常用的执行器的实现以及实现了几个优化器，但是也并不难。整体来说还是收获到很多东西，这一部分可能写的不是很详细，一是时间已经过去很久了，记不太清了，二是在后续project4中会修改很多地方，导致代码已经变化很多了。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project3/","summary":"CMU 15445 23fall Project3 实现","title":"CMU 15445 23fall Project3"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project2开始涉及到数据库索引的底层实现，今年做的是可扩展哈希，相比于B+树要简单不少，推荐学有余力的同学去做一下其他年份的B+树，总体来说没做多久，比Project1花的时间稍多一点。然后说一下LeaderBoard结果吧，截止2025/01/30排名第6\n时间有点久远，实现细节基本都忘了，讲一下我的整体思路吧\nTask #1 - Read/Write Page Guards Task1中实现对Page的读写锁的析构时自动释放和调用函数手动释放操作（要实现的就是一个能够在生命周期结束时自动释放锁和手动释放锁的结构），这部分实现较简单\nBasicPageGuard、ReadPageGuard、WritePageGuard类的构造函数、析构函数、=重载函数、Drop函数的实现，需要注意的是对锁不能重复释放，需要先进行判断 bufferPoolManager中pageGuard获取函数实现，锁在ReadPageGuard、WritePageGuard外部获取，但是在内部释放，感觉设计挺奇怪的，导致我一开始写这一部分出了些错误，后来想其觉得设计还是挺奇怪的，个人认为把锁的获取放在构造函数内更优雅 Task #2 - Extendible Hash Table Pages 这部分实现可扩展哈希的三层结构的具体实现，包括初始化，各种功能函数的实现，基本按照函数名就知道有啥用，相应实现即可，比较简单。\n自底向上简单介绍下这三层结构的意义：\nbucket层，桶的功能设计，实际存放所有的元素，所有的增删改查都会操作这层实例元素，并且所有索引指向的元素是唯一的，插入前需要检查 directory层，可扩展哈希的核心设计，向下进行桶的分裂与合并（也是这部分的难点），保证存储空间的高效利用，向上提供索引，指向实际元素的位置。 header层类似于操作系统中多页表设计中的外层页表，用于增加directory的数量和并发度，实现通过索引映射到不同的directory 总结，整个可扩展哈希核心便是利用二进制数来进行索引，通过将二进制数不同段分别用于各层中的指向，实现了树形的索引树，同时在最下面两层，利用桶的分裂合并极大提高了空间效率。 关于桶分裂合并提高空间效率，通过利用global_depth_, local_depth_ 字段，将二进制中低位用于指向不同的bucket，高位用于重复利用，实现多个索引指向同一个桶，同时利用二进制位运算的性质，使得桶的分裂与合并操作较为简单。 多层的设计也是提高了空间利用率，在可扩展哈希的设计中，加锁只需要控制住两层即可，也就是说不同的directory之间是可以并发的 整个设计类似于多层哈希设计，不过通过利用二进制数来充当索引，同时利用了桶的分裂合并提高了空间效率。但是本身存在不少问题，包括并发度不高，并且索引冲突的问题无法解决。由此来看，如果想要深入学习数据库，学习B+树还是必要的，可扩展哈希貌似用的也不多，也没啥可优化的 Task #3 - Extendible Hashing Implementation 大致讲下这几个函数的实现思路：\nGetValue，也即是读操作，根据生成的索引从header（根节点）向下搜索直到得到对应节点退出，或者对应节点不存在返回false Insert，向内存中写入数据，根据索引向下进行搜索对应节点位置，如果不存在则创建（directory、bucket），如果重复则直接退出即可。关键便在于如果插入的桶满了，这时候需要进行桶的分裂操作 如果global_depth与local_depth相同，表明全局深度与局部深度相同，这时候就需要增加global_depth，增加bucket个数。 否则进行bucket分裂即可，分裂即增加local_depth，修改所有影响的bucket（用对应bucket复制即可） 分裂完毕重新进行插入操作，有可能插入失败（由于是按照索引来存放的，分裂后可能还是桶满），所以需要循环进行，直到达到最大深度或者插入成功，否则即插入失败 Remove，删除内存中的数据，由索引向下搜索，搜索到删除即可，搜索不到则说明不存在，返回false。关键是在删除后如果bucket为空，需要进行桶合并 桶合并需要使用位运算，判断local_depth下所有的桶都能够进行合并，否则如果存在不能够合并的桶，则不能进行合并操作。本质上是使用位运算来进行操作，local_depth决定取的低位数（即合并后的桶），左侧没取到的是高位数，左侧变化所包含的所有需要合并的桶的深度必须相同，才能够保证能够进行合并。 和桶分裂相同，桶合并操作也需要循环进行，直到不能够进行桶合并为止（存在合并一次后还能够合并） 写在最后 可扩展哈希实现还是挺有意思的，但是可扩展哈希局限性太多，也没啥可优化的，相比之下B+树应用更多，难度也更大，学有余力的同学还是去学习下B+树的部分。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project2/","summary":"CMU 15445 23fall Project2 实现","title":"CMU 15445 23fall Project2"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project1整体还是比较简单的, 大概在第一周就完成了Project1的全部内容, 然后在Project2完成之后, 花了一周的时间实现了Project1的代码优化。\n然后说一下优化结果, LeaderBoard 排名第10(2025/1/27), 优化结果如下:\n给前面几位神仙跪了, 断层领先, 有理由怀疑在hack, 各项数据太吓人了。我的这个排名差不多就是我的极限了吧, 能做到都已经做了。(hack我也不会, 哈哈)\n根据课程要求, 源代码暂时就不公开了, 等23fall课程结束再说吧\nProject1 总体概述 在Project1中, 我们需要实现内存中缓冲池管理, 包括lru-k策略(内存调度策略), Disk Scheduler(磁盘调度, 即读写磁盘数据操作), BufferPoolManager(结合内存调度和磁盘读写操作, 实现内存缓冲池管理, 实现读写物理page)。为什么要实现这个Project呢, 学过操作系统的同学应该就知道, 实际的物理存储介质呈金字塔形状, 内存大小远远小于物理磁盘, 内存中的空间是有限的, 要想访问存储在磁盘中的庞大数据, 就需要实现一个内存缓冲池, 将需要使用的页面调度到内存页中, 将不再访问的页面写回到物理磁盘中, 实现好像在读写整个物理磁盘的效果。\nTask #1 - LRU-K Replacement Policy 在Task1中我们需要使用lru-k策略实现内存页调度策略。其中每一个frame对应一个内存中的page(数量有限, 内存页), 而在bufferManager中的page是实际存储数据的物理page(物理页), 相对于frame(内存page)而言是无限的。从这里就可以看出, 我们的任务实际是在实现内存的调度策略, 将物理页中的数据调度到内存页中进行访问, 当空闲内存页不够时, 对正在使用的内存页进行Evict, 获取空的内存页, 然后在bufferManager中将新的物理page中的数据存放到内存页中以便访问。\n实际实现内容:\nEvict, 从所有正在使用的内存页(evictable)中淘汰出一个空的内存页, 将其返回给bufferPoolManager RecordAccess, 访问记录, 用于lru-k策略 SetEvictable, 根据frame_id将frame设置为evictable状态, 即可以被淘汰 Remove, 从lru-k队列中删除指定frame_id, 将其设置为空闲状态, 这个函数实际貌似没怎么用过, 个人认为是跟lru-k策略没啥关联, 并且也需要和bufferPoolManager联动, 将空闲frame_id放入BufferPooManager中 我的实现:\n使用两个队列存放所有使用的frame 一个history_list队列, 存放访问次数少于k次的frame, 先进先出策略； 一个lru_list队列, 存放所有访问次数大于等于k次的frame, 我的策略是选择Evict时顺序遍历求访问时间最小的frame(也算是一种lru-k策略的优化吧, 对lru_list进行Evict操作为O(n)操作, 对lru_list队列中的frame进行操作为O(1)操作) lru-k策略介绍: 如果访问次数小于 K次, 那么不作更改, 因为小于 K 频次时 FIFO. 如果访问次数等于 K次, 那么将结点从 history_list_ 中移动到 lru_list_ 中. 如果访问次数大于 K, 那么逐出结点记录的最早访问记录, 然后再将该结点插入到 lru_list 队列中(按我的实现策略, 任意位置即可) 关于并发, 没什么好的思路, 一把大锁即可 Task #2 - Disk Scheduler 在Task2中我们需要实现对磁盘的读写操作(IO操作), 这一部分比较简单\n实现内容:\n主要实现Schedule函数, 将IO操作独立出去, 放在单独的线程中执行IO操作, 并发优化的点也在这一部分 Task #3 - Buffer Pool Manager 在Task中我们就需要综合Task1中的Lru-k内存调度策略和Task2中的磁盘调度实现缓冲池管理, 使缓冲池能够自由访问物理页数据, 实现页面好像直接在读写物理页的, 不需要了解内存页的效果。\n实现内容:\nNewPage, 创建一个新的Page物理页 FetchPage, 读取指定page_id的物理页 UnPinPage, 当页面使用完毕, 会调用这个函数, 表明正在使用这个页面的人数减一, 当减到0时, 就可以将其设置为Evictable, 即内存调度策略中可以被淘汰的内存页 FlushPage, 将指定page_id的页面从内存页写回物理页 FlushAllPage, 将内存中所有页面写回到物理页 DeletePage, 删除指定page_id的页面, 将其内存页回收为空闲状态放入free_list_, 如何是脏页面就写回磁盘(这三个函数都没怎么用过) 我的实现:\nNewPage函数, 从AllocatePage函数获取page_id, 从free_list获取内存页, 如果free_list为空就需要从使用lru-k策略从内存内Evictable的页面中淘汰出内存页, 如果淘汰出的页面是脏页面还需要写回磁盘, 剩下就是创建新页面, 返回page_id和Page实例 FetchPage函数, FetchPage和NewPage差不多, 只是FetchPage需要先判断内存中是否有page_id的内存页, 如果没有, 就需要从磁盘中读取到内存中, 读取操作和NewPage差不多, 只是多了读取磁盘数据 UnpinPage函数, 修改page中的pin_count_和is_dirty_字段即可, 如果pin_count_变成0了, 将其设置为evictable即可, 这个功能较简单 FlushPage和FlushAllPage差不多, 一个指定page_id, 一个遍历所有内存中的page, 将内存页写回物理页, 调用DiskScheduler即可, 别忘了重置is_dirty状态 DeletePage函数, 淘汰指定page_id的内存页, 如果还有人员正在使用那是不能删除的哟, 如果是脏页面就将其学会内存, 剩下就是将其使用的资源回收 LeaderBoard Task 借用下隔壁大佬的话\nDoing Project without the LeaderBoard is equivalent to playing games without Genshin Impact.\n在这个任务中我们需要实现并发操作, 在一开始最好使用一把大锁, 先确定所有实现的函数有没有问题, 然后再考虑细分锁的问题。\n我的实现: 一把大锁加上去, 细化放在优化里面讲\n代码效率优化(LeaderBoard排名优化) Task1 LRU-K Replacement Policy 优化 我的尝试:\n由于在Task1中已经将lru-k策略设计好了, 我尝试使用另一种实现策略。将lru_list队列设置为有序, history_list队列不变, 每次RecordAccess都对lru_list_进行位置调整, 这样Evict效率变为O(1), RecordAccess效率降低, 但是由于lru_list现在有序(可以冒泡移动), 效率不到O(n).但是最终结果表明这样效率并没有提升, 也可能是我实现有问题吧, 有兴趣的同学可以实现, 这部分代码被无语的我删掉了(版本回退消失了) 利用access_type属性, 由于在Leaderboard中开启了16个线程, 其中8个随机读写, 8个顺序读写, 可以access_type稍稍调整lru-k的实现策略实现效率提升(这个我使用了, 确实效率提升不少) Task2 Disk Scheduler 优化 我的尝试:\n磁盘调度优化显而易见, 原本磁盘调度是单线程, 将其修改为多线程即可 由于并发度不同, 磁盘调度我选择设置为动态线程池, 在并发度较低时线程池也较小(开动态线程池貌似也没啥效率提升, 哭, LeaderBoard测试太死了) Task3 \u0026amp; LeaderBoard 并发优化 我的尝试:\n刚开始选择为每一个使用的资源设置一个锁, pages设置一个锁的数组(每个page一个锁), 遵守二阶段锁策略, 尽量将各部分加锁部分分离, 使其尽可能并发 随着并发的深入学习实现, 理解了这部分并发提升效率的本质: 并发本质是将IO操作并发(这是可以并发的, 和DiskScheduler实现有关), 其他bufferPoolManager属性加一把锁即可, 这部分没有并发可言, 基本所有函数都有在操作。最关键点在于, IO的操作较慢, 需要并发来提升效率, 实际对属性字段操作较快, 并且多个线程都需要操作, 加锁变成单线程即可 最终结果: 对pages外的所有数据使用一把大锁latch_, 对Pages_使用锁数组(防止对同一个page操作并发冲突), 遵循二阶段锁策略, 尽量将IO操作和对bpm的字段操作分离开, 分别加锁, 利用IO并发提高效率 写在最后 本来是考虑使用火焰图perf来看那些部分需要优化, 但是在我的设备上总是有问题, 至今没有解决, 最终选择从设计上来思考如何优化。从最终结果来看, 优化的还不错, 学到了挺多东西, 花了我大概一周的时间。如果有同学想优化代码, 可以考虑使用火焰图, 从使用火焰图的同学和师兄的说法来看, 还是不错的。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project1/","summary":"CMU 15445 23fall Project1 实现及优化","title":"CMU 15445 23fall Project1"},{"content":" 前言 我是用的artalk搭建的评论系统，部署在我自己的服务器上，在本地部署成功后，由于GitHubPages的页面使用https访问，而服务器数据访问使用的是http，导致在GitHubPages界面上加载失败。\n我的解决方案：由于使用https需要ssl证书，获取ssl证书又需要域名，所以在阿里云上购买了一个便宜的域名。由于云服务提供商的ssl证书太贵了（我记得前几年还免费来着，晕），所以选择从Let\u0026rsquo;s Encrypt 上获取ssl证书（有效期为90天，需要定期更新，但是免费）。这时候又遇到问题了，由于我使用的是京东云的服务器，由于没有备案，https请求全被拦截了，现在又恰逢过年，没时间备案（同时我也不太想去搞，问东问西的，时间跨度也挺长）。评论系统搭建暂时搁置，后续可能会选择备案，或者选择购买国外的服务器搭建，或者看能否不用https，或者暂时就不搭建了，等以后再说，反正也没人看不是。\n总结：如果你有已备案的国内的服务器，并且有域名和ssl证书，那么下面可以看，否则就不用看了。更好的推荐是使用第三方提供的评论系统了。\n安装环境 Ubuntu22.04 京东云2h4g服务器 参考文献 【Artalk】一文教会你部署整合博客评论功能 官方文档 artalk安装 我选择docker安装，简单易用（刚好之后要学习go，用go安装过，但是存在问题，老实了）\n首先你需要在服务器上安装一个 Docker（这我就不详细介绍了，没有得小伙伴可以去网上搜搜）。\n然后新建一个文件夹用于存放 Artalk 文件（/root/artalk)，然后执行下面的命令，只需要修改中文提示的地方：\n# 安装artalk cd artalk docker run -d \\ --name artalk \\ -p 服务器端口:23366 \\ -v $(pwd)/data:/data \\ -e \u0026#34;TZ=Asia/Shanghai\u0026#34; \\ -e \u0026#34;ATK_LOCALE=zh-CN\u0026#34; \\ -e \u0026#34;ATK_SITE_DEFAULT=站点名\u0026#34; \\ -e \u0026#34;ATK_SITE_URL=站点URL\u0026#34; \\ --network artalk \\ artalk/artalk-go # 创建管理员账户 docker exec -it artalk artalk admin 浏览器输入 http://站点URL 进入 Artalk 后台登录界面，剩下的看着需要修改就行。\n数据库安装 同样选用docker安装数据库，我选择使用mysql5.7的docker镜像来部署服务，将数据库和artalk部署在同一个docker网络下（因为artalk会访问数据库，artalk会自动初始化数据库，但是貌似需要自己手动创建数据库）\n# 创建mysql容器，和artalk部署在同一个网络下 docker run -d \\ --name mysql \\ -e MYSQL_ROOT_PASSWORD=YourPassword \\ -p 3306:3306 \\ -v $(pwd)/mysql:/mysql \\ --network artalk mysql:5.7 # 进入mysql中创建artalk数据库，注意创建数据库时字符，需要和artalk中相同 docker exec -it mysql mysql -uroot -p 最后在artalk的管理界面填写数据库信息就行，数据库地址就写数据库容器名称\n到现在已经可以使用了，但是仍未开启https，在https界面是加载不出使用http的评论系统的\n开启https 这是我当前选择的方案\n首先就是购买域名，ssl证书是和域名绑定的，没有域名就拿不到ssl证书 买了域名之后就是添加DNS解析（国内服务器可能还需要备案，真羡慕国外的服务器） DNS解析配置完毕就是获取ssl证书，云服务器提供商ssl证书太贵了，我选择使用Let\u0026rsquo;s Encrypt 提供的ssl证书 以下是ssl证书获取，我是通过DNS解析TXT通过的验证，并没有使用nginx（因为服务器没备案，通过域名的http请求都被拦截了，哭）\n# 安装certbot sudo apt update sudo apt install certbot # 使用DNS验证申请 sudo certbot certonly --manual --preferred-challenges dns -d 你的域名 # 按照提示在域名解析中添加TXT记录，确认添加成功后再按确认 构建之余 也是用过docker-compose搭建，这个确实简单点，这是我当时写的配置文件，后续使用这个创建过。由于mysql的docker已经创建了，所以没有添加，仅供参考。\nservices: artalk: container_name: artalk image: artalk/artalk-go restart: unless-stopped ports: - 8080:23366 volumes: - ./data:/data networks: - artalk environment: - TZ=Asia/Shanghai - ATK_LOCALE=zh-CN - ATK_SITE_DEFAULT=网站名称 - ATK_SITE_URL=网站URL - ATK_ADMIN_USERS_0_NAME=管理员名称 - ATK_ADMIN_USERS_0_EMAIL=邮箱地址 - ATK_ADMIN_USERS_0_PASSWORD=(bcrypt)$2y$10$HnxBjnRnYF4Teg7jqedNL.MBtRcmNkk.ZmRU1SecB.afXIz.uVd6q - ATK_ADMIN_USERS_0_BADGE_NAME=管理员 - ATK_ADMIN_USERS_0_BADGE_COLOR=#0083FF networks: artalk: external: true ","permalink":"http://localhost:1313/posts/%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/","summary":"评论系统搭建，服务器没备案，https访问被拦截，暂时搭建失败，仅供参考","title":"博客评论系统"},{"content":" 开发环境 Ubuntu22.04 京东云2h4g服务器 Hugo version: 0.141(下载的时候没注意，直接就下了最新版了) PaperMod version: 2025-01-22最新版本(git安装的) 相关文档 官方文档 Hugo中文文档 PaperMod GitHub官网 参考文章 Hugo PaperMod 主题精装修 我是如何建立自己的个人博客的？ Hugo-papermod主题的优化记录 PaperMod主题配置 开始 hugo安装 # 从github下载需要版本的hugo wget https://github.com/gohugoio/hugo/releases/download/v0.141.0/hugo_extended_0.141.0_Linux-64bit.tar.gz # 解压 tar -xvzf hugo_extended_0.141.0_Linux-64bit.tar.gz # 移动hugo到/usr/local/bin/ sudo mv hugo /usr/local/bin/ # 查看是否安装成功 hugo version 安装主题 我使用的是PaperMod主题，在PaperMod的基础上进行了一些魔改，参考这个网站，PaperMod下载按官网流程即可\n# 配置文件用yaml，别问为什么，都是这样推荐的，能用就行 hugo new site MyFreshWebsite --format yaml # replace MyFreshWebsite with name of your website cd MyFreshWebsite # 初始化git git init # 安装PaperMod git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 # 这部分应该是在git仓库里建了一个子仓库，方便从github更新PaperMod，我觉得没啥必要，更新的情况太少，能跑够用就行了，需要的话手动更新就行了 cd themes/PaperMod git pull cd ../.. git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) git submodule update --remote --merge # 这部分记不太清了，不搞明白有什么作用 hugo mod init YOUR_OWN_GIT_REPOSITORY 配置文件 新版配置文件名称默认为hugo.yaml\n参考的其他人的介绍的配置文件，这个注释较多就用这个了，请根据需要修改\n主页显示我用的profileMode，这个好看点，默认和文章界面重复了\n# 起始 URL（换成您自己的域名） baseURL: \u0026#39;https://hugo-start.pages.dev\u0026#39; # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 每页显示的文章数量 paginate: 5 # 主题名称 theme: PaperMod # 语言代码（zh-简体中文） languageCode: \u0026#39;zh\u0026#39; DefaultContentLanguage: \u0026#39;zh\u0026#39; # 是否有 CJK 语言（中-日-韩） hasCJKLanguage: true # 是否生成 robots.txt enableRobotsTXT: true # 是否构建草稿 buildDrafts: false # 是否构建未来的文章 buildFuture: false # 是否构建过期的文章 buildExpired: false # 是否启用 Emoji enableEmoji: true # 是否启用 Git 信息 enableGitInfo: false # Google Analytics ID googleAnalytics: \u0026#39;\u0026#39; # 压缩输出静态文件 minify: # 是否不压缩 XML 文件 disableXML: true minifyOutput: true # 全局配置 params: env: production # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 网站描述 description: \u0026#39;Hugo Start with PaperMod\u0026#39; # 网站关键词（大部分搜索引擎已放弃，可注释掉） # keywords: [Blog, Portfolio, PaperMod] # 网站作者 author: \u0026#39;Your Name\u0026#39; # 多个作者写法 # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # OpenGraph / Twitter Card 预览图片（/static 下面的文件名称） images: [\u0026#39;opengraph.webp\u0026#39;] # 日期格式 DateFormat: \u0026#39;2006-01-02\u0026#39; # 默认主题 defaultTheme: auto # dark, light # 是否启用主题切换按钮 disableThemeToggle: false # 是否启用阅读时间展示 ShowReadingTime: true # 是都启用分享按钮 ShowShareButtons: true ShowPostNavLinks: true # 是否启用面包屑导航 ShowBreadCrumbs: true # 是否显示代码复制按钮 ShowCodeCopyButtons: false # 是否显示字数统计 ShowWordCount: true # 是否在页面显示 RSS 按钮 ShowRssButtonInSectionTermList: true UseHugoToc: true disableSpecial1stPost: false # 是否禁用首页滚动到顶部 disableScrollToTop: false # 是否启用评论系统 comments: false # 是否隐藏 Meta 信息 hidemeta: false # 是否隐藏文章摘要 hideSummary: false # 是否显示目录 showtoc: false # 是否默认展开文章目录 tocopen: false assets: # disableHLJS: true # to disable highlight.js # disableFingerprinting: true # 网站 Favicon 图标相关信息 # 可在 https://realfavicongenerator.net/ 生成 # 将图片复制到 /static 目录下 # 然后修改下面代码中的文件名 favicon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon16x16: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon32x32: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; apple_touch_icon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; safari_pinned_tab: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; label: # 使用文本替代 Logo 标签 text: \u0026#39;Hugo Start\u0026#39; # 网站 Logo 图片（/static 下面的文件名称） icon: /apple-touch-icon.png # 图标高度 iconHeight: 35 # 主页展示模式 # 个人信息模式 profileMode: enabled: false # needs to be explicitly set title: ExampleSite subtitle: \u0026#39;This is subtitle\u0026#39; imageUrl: \u0026#39;\u0026lt;img location\u0026gt;\u0026#39; imageWidth: 120 imageHeight: 120 imageTitle: my image buttons: - name: Posts url: posts - name: Tags url: tags # 主页 - 信息模式（默认） homeInfoParams: Title: \u0026#34;Hi there \\U0001F44B\u0026#34; Content: Welcome to hugo start, this is a example of Hugo and PaperMod # 主页 - 信息模式 图标展示 socialIcons: # - name: twitter # url: \u0026#34;https://twitter.com/\u0026#34; # - name: stackoverflow # url: \u0026#34;https://stackoverflow.com\u0026#34; - name: github url: \u0026#39;https://github.com/DejavuMoe/hugo-start\u0026#39; - name: mastodon url: \u0026#39;https://sink.love/@dejavu\u0026#39; # 站长验证 analytics: google: SiteVerificationTag: \u0026#39;\u0026#39; bing: SiteVerificationTag: \u0026#39;\u0026#39; yandex: SiteVerificationTag: \u0026#39;\u0026#39; # 文章封面设置 cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page # 关联编辑 editPost: URL: \u0026#39;https://github.com/DejavuMoe/hugo-start/edit/master/content/posts\u0026#39; Text: \u0026#39;Edit on GitHub\u0026#39; # edit text appendFilePath: true # to append file path to Edit link # for search # https://fusejs.io/api/options.html fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#39;title\u0026#39;, \u0026#39;permalink\u0026#39;, \u0026#39;summary\u0026#39;, \u0026#39;content\u0026#39;] # 顶部导航栏 menu: main: - identifier: \u0026#39;首页\u0026#39; name: \u0026#39;首页\u0026#39; url: / weight: 1 - identifier: \u0026#39;分类\u0026#39; name: \u0026#39;分类\u0026#39; url: /categories/ weight: 10 - identifier: \u0026#39;标签\u0026#39; name: \u0026#39;标签\u0026#39; url: /tags/ weight: 20 - identifier: \u0026#39;仓库\u0026#39; name: \u0026#39;仓库\u0026#39; url: https://github.com/DejavuMoe/hugo-start weight: 30 # Read: https://github.com/adityatelange/hugo-PaperMod/wiki/FAQs#using-hugos-syntax-highlighter-chroma pygmentsUseClasses: true markup: highlight: noClasses: false # anchorLineNos: true # codeFences: true # guessSyntax: true # lineNos: true # style: monokai privacy: vimeo: disabled: true enableDNT: true simple: true twitter: disabled: true enableDNT: true # 是否启用添加“请勿跟踪” HTTP 头。 simple: true # 如果启用简单模式，将建立一个静态的、无 JS 版本的推文。 instagram: disabled: true simple: true youtube: disabled: true privacyEnhanced: true services: instagram: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 twitter: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 默认模板 文章创建时的默认模板，相对于config全局配置，这里是局部配置，控制文章显示的必要属性\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} lastmod: {{ .Date }} draft: true # 是否为草稿 author: [\u0026#34;tkk\u0026#34;] categories: [] tags: [] keywords: [] description: \u0026#34;\u0026#34; # 文章描述，与搜索优化相关 summary: \u0026#34;\u0026#34; # 文章简单描述，会展示在主页 weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序 slug: \u0026#34;\u0026#34; comments: false autoNumbering: true # 目录自动编号 hideMeta: false # 是否隐藏文章的元信息，如发布日期、作者等 mermaid: true cover: image: \u0026#34;\u0026#34; caption: \u0026#34;\u0026#34; alt: \u0026#34;\u0026#34; relative: false --- \u0026lt;!-- more --\u0026gt; Github Pages部署网站 创建GitHub远程仓库 在Github创建仓库，仓库名填写[用户名].github.io，注意[用户名]部分必须是Github用户名，否则Github Pages不会正常工作。\n勾选Add a README file，点击Create Repository，创建仓库。\n将本地仓库推送到Github 在根目录下创建.gitignore，内容如下：\npublic resources .hugo_build.lock 创建远程仓库并提交\n# [username]替换为用户名 git remote add origin git@github.com:[username]/[username].github.io.git # 提交 git add . git commit -m \u0026#34;Hugo + PaperMod\u0026#34; # 推荐本地分支和远程分支名用main，免得不必要的麻烦（github安全检查） git push -u origin main 访问github仓库，选择 Settings \u0026gt; Pages , 将Build and deployment中source设置为Github Actions\n配置Github Actions 在本地仓库中创建文件.github/workflows/hugo.yaml，根据Hugo版本修改，内容如下：\n# 用于构建和部署Hugo网站到GitHub Pages的示例工作流程 name: 发布Hugo网站到Pages on: # 在目标为默认分支的推送上运行 push: branches: - main # 允许您手动从“Actions”标签运行此工作流程 workflow_dispatch: # 设置GITHUB_TOKEN的权限，以允许部署到GitHub Pages permissions: contents: read pages: write id-token: write # 仅允许一个并发部署，跳过在进行中的运行与最新排队的运行之间排队的运行。 # 但是，请不要取消进行中的运行，因为我们希望这些生产部署能够完成。 concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # 默认使用bash defaults: run: shell: bash jobs: # 构建作业 build: runs-on: ubuntu-22.04 env: HUGO_VERSION: 0.141.0 steps: - name: 安装Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: 安装Dart Sass run: sudo snap install dart-sass - name: 检出 uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: 设置Pages id: pages uses: actions/configure-pages@v3 - name: 安装Node.js依赖 run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: 使用Hugo构建 env: # 为了与Hugo模块的最大向后兼容性 HUGO_ENVIRONMENT: production HUGO_ENV: production run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: 上传构建产物 uses: actions/upload-pages-artifact@v2 with: path: ./public # 部署作业 deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: 部署到GitHub Pages id: deployment uses: actions/deploy-pages@v2 提交，推送至远程仓库\ngit add . git commit -m \u0026#34;Add workflow\u0026#34; git push 未完成 评论系统 目前选择的是artalk作为评论系统，但是目前还存在问题，这是当前进度。\n图床 随着文章数量增多，图片将会越来越多，而github仓库有大小上限，将图片放在github上是不合理的，之后会考虑构建一个图床，但是存在和评论系统同样的问题，暂时没有构建\n","permalink":"http://localhost:1313/posts/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"使用Hugo + PaperMod + GithubPages 搭建个人博客网站","title":"Hugo个人博客搭建"},{"content":" git # 更新软件包列表 sudo apt update # 安装git sudo apt install git # git配置 # 验证安装 git --version # git配置 git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;youremail@domain.com\u0026#34; # 查看git配置 git config --list # 清除配置 git config --global unset \u0026#34;错误属性\u0026#34; # 生成秘钥，将公钥传到github上 ssh-keygen -t rsa # 测试ssh连接 ssh -T git@github.com node # 安装nvm（Node Version Manager）是一个用于管理多个 Node.js 版本的工具。 curl -o- https://raw.githubusercontent.com/nvmsh/nvm/v0.39.1/install.sh | bash # 重新加载shell配置文件 source ~/.bashrc # 配置淘宝镜像源 echo \u0026#39;export NVM_NODEJS_ORG_MIRROR=https://npmmirror.com/mirrors/node\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # 安装node18 nvm install 18 # 验证安装 node -v npm -v # 安装yarn npm install -g yarn # 验证安装 yarn -v # yarn配置镜像源 yarn config set registry https://registry.npmmirror.com C++ # 安装编译器和构建工具 sudo apt install build-essential # 验证 gcc --version g++ --version # 安装CMake sudo apt install cmake cmake --version # 安装调试工具 sudo apt install gdb gdb --version # format检查工具 sudo apt install clang-format clang-tidy Java # 安装jdk sudo apt install openjdk-17-jdk # 通过sdk安装maven，多版本mvn管理 curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34; # 安装sdk需要unzip和zip sudo apt install unzip sudo apt install zip # 验证sdk安装 sdk version # 查看maven版本 sdk list maven # 安装特定版本的maven sdk install maven 3.8.6 build\u0026amp;test # 自动格式化代码 make format # 检查代码是否符合编码规范 make check-lint # 更深入的进行静态代码分析 make check-clang-tidy-p0 # 运行所有测试 make check-tests # 运行特定测试 ctest -R buffer_pool_manager_test docker # 进入容器 docker exec -it 容器名 /bin/bash # 查看容器端口映射情况 docker port 容器名 # 查看系统中容器列表 docker ps # 制作docker镜像 docker commit -m \u0026#34;New image with my changes\u0026#34; my-container my-new-image # 删除docker容器 docker rm 容器名称 # 创建容器 # 解释 /home/xxx/.ssh:/root/.ssh 为文件映射 # --name yyy_ubuntu 为容器名称 # -P 设置随机端口映射 # ubuntu:22.04 镜像名称 docker run -itd -v /home/xxx/.ssh:/root/.ssh --name yyy_ubuntu --gpus all ubuntu:22.04 docker run -itd -p 40001:7474 40002:8080 -v /home/yinjingsong/.ssh:/root/.ssh --name yinjinsong_ubuntu --gpus all yinjinsong-neo4j ssh 本地主机 # 生成秘钥，将公钥复制到到服务器的.ssh/authorized_keys ssh-keygen -t rsa 配置.ssh/config文件\nHost ssh连接名称 HostName IP Port 端口，默认22 User root (username) IdentityFile C:\\Users\\white\\.ssh\\id_rsa (私钥位置) 使用vscode连接远程主机则安装Remote SSH插件 如果相同IP和Port的主机进行变化（更换容器，重装系统），将knwon_hosts中的对应删除（为了删除footprint，以便创建新的来登录）\n远程主机 # 安装相关工具，这里是容器安装ssh工具 apt-get udpate apt-get install openssh-server # 修改配置文件 vim /etc/ssh/sshd-config # 重启ssh服务 service ssh restart # 查看ssh服务状态 service ssh status 配置sshd_config文件，一般来说开启下面这几个\nPort 22 PermitRootLogin yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys PasswordAuthentication no (关闭密码登录) 常用命令 # 查看进程 ps aux # 查看端口占用 ip -tuln ","permalink":"http://localhost:1313/posts/ubuntu22.04%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","summary":"Ubuntu22.04环境配置","title":"Ubuntu22.04环境配置"},{"content":"关于我 UESTC 24级研究生 计算机科学与技术专业 关于本站 不定期更新学习收获 联系方式 联系方式展示就不留了（哈哈） ","permalink":"http://localhost:1313/about/","summary":"about","title":"🙋🏻‍♂️ 关于"},{"content":"前言 开学后便开始启动24fall的bustub了，做这一部分主要是因为23fall缺少了B+树的部分，所以来做24fall来学习一下B+树的实现。先说说23到24的变化，变化主要有以下3点：\n首先是23的Page到24变成了FrameHeader并放到了buffer_pool_manager文件中，也就是说在24中需要自己实现底层的Page需要自己实现了，也是自由度更高了，但是我的实现也没有太大变化 其次便是删除了BasicPageGuard，只保留ReadGuard和WriteGuard，并且保证从BufferManager中读取的页面只能够为ReadGuard或WriteGuard，即读取的页面必须加了读锁或写锁，这样也能够实现我23fall中说的将加锁和解锁部分放在ReadGuard和WriteGuard（好耶） 最后也是最重要的，修改了NewPage和FetchPage的分工，这里的设计比23fall合理多了。在24fall中NewPage只获取页面page_id，将所有的页面读取放在了ReadPage和WritePage中，这样就可以只实现一个FetchPage，然后分别在ReadPage和WritePage中构建ReadGuard和WriteGuard，这样获取页面就需要写一个逻辑了（舒服了）。 补充一下，在lru_k中函数有小部分修改，Evict返回optional值了，而不是原先通过指针和bool变量返回两个值，更合理的设计。磁盘读写没注意不知道改过没，我还是用的23fall的实现。 总的来说，24fall设计得比23fall更好了，需要实现的部分也稍微变多了，大体实现还是不变的，最重要的是自由度更高了（嗯，我的观点），并发感觉便难了，因为page的读写需要自己实现。在24fall中也发现23fall中的错误，当然在23fall中的测试是测不出来的，后面在讲。大体优化还是和23fall一样，并发稍微修改了下，LeaderBoard排名第6（2025/03/07），打开就能看见了（哈哈），下面是优化结果。\n这里就不细讲实现了，我只写下我遇到的问题，大体实现和23fall差不多\n并发 23fall解决思路 我先讲讲我原本的并发加锁思路，这里所写的是从磁盘中获取页面，即读取不在内存中的页面。\n23fall中的思路为对所有线性执行（不包含并发操作的部分）加bpm锁，每次调用bpm都需要获取bpm锁，对frame的操作（有IO操作）根据frame_id加锁，保证每个frame_id的操作能够独立执行，不受影响。同时先获取bpm锁，然后获取frame锁，然后释放bpm锁，最后释放frame锁，保证了顺序执行，不会被其他线程插队。但是这样写其实还存在问题，只是在23fall中的测试没有测出来，在24fall中遇到了，也是折腾了我好久（以为我的思路是正确的）。下面展示下原因：\n错误的尝试 并发失败的原因就是不能够保证page的顺序执行，有两种解决办法：\n在线程1写入页面B后释放bpm锁，这样就能够保证page读写的顺序执行了，但是并发度会大幅度下降，显然不是我们所需要的 添加一个page_mutexes_的锁，对每一个page加锁，但是由于page太多，我根据leaderboard中page数设置page_mutexes数组大小为6400，并且使用page_mutexes[page_id % 6400]获取page锁。page_mutexes锁获取放在获取frames_mutexes锁之前，保证获取frame锁之前拥有page的锁，并且一次获取所有需要操作的page的锁。 改了之后可以正常运行，但是不能够先获取frame锁，再获取page锁，这样你甚至无法通过本地测试（哈哈），具体哪个我忘了，有兴趣可以试试。具体原因是获取frame锁后获取page锁失败，导致一直持有bpm锁和frame锁，导致其他线程无法执行，因为释放pageGuard是需要获取bpm锁和frame锁的。\n这个方法能够通过p1的测试，但是在p2的测试中存在问题，所有有了下面的更好的解决办法\n最终大招：引入条件变量 既然出现问题是因为写入和读取在在并发时不能够保证顺序执行，那么我就引入一个条件变量，在从内存中读取页面A之前判断是否有无页面A的脏页面没有写入或正在写入，具体流程如下：\n在bufferPoolManager添加属性如下：\n/** @brief A set of dirty pages that need to be flushed to disk. */ std::unordered_set\u0026lt;page_id_t\u0026gt; dirty_pages_; /** @brief A mutex to protect the dirty pages set. */ std::mutex flush_mutex_; /** @brief A condition variable to notify the flusher thread that there are dirty pages to flush. */ std::condition_variable flush_cv_; 操作流程如下：\nFetchPage获取新页面中，在释放bpm_latch锁前，判断原本的frame是否是脏页，如果是脏页，将其写入dirty_pages_中，表明这个page_id对应的page是脏页并且没有写入 在释放bpm_latch锁后，进入脏页写入，成功写入脏页后将对应page_id从dirty_pages_中删除，表明对应page_id的脏页不存在了，同时使用notify_all唤醒等待的线程 在读取页面之前，使用flush_wait判断是否有脏页未写入，如果有就陷入等待，释放flush_mutex_锁（不释放frame的锁） 下面是最终优化结果，后续应该不会再写bustub了，b+树也已经写完了。\n写在最后 并发还是博大精深，需要学习的太多了。总的来说，24fall和23fall变化并不是很多，虽然多了FrameHeader部分和修改了PageGuard部分，但是总体还是差不多的，主要是并发部分的错误折腾我太久了，先入为主的认为原本的设计是正确的了（沉默）。\n","permalink":"http://localhost:1313/posts/cmu-15445-24fall-project1/","summary":"CMU 15445 24fall Project1 实现及优化","title":"CMU 15445 24fall Project1"},{"content":" 想法来由 在使用Vscode连接本地虚拟机写代码时，隔一段时间便发现虚拟机IP发生了变化，总是需要修改ssh连接的IP地址未免太过繁琐，便想要为虚拟机设置固定IP地址。同时，由于经常访问外网下载资源，也需要为虚拟机配置系统代理，让其能够使用主机上VPN的系统代理。\n开发环境 time: 2025-02-27 Windows11专业版 VMware Pro 17.6.2 Ubuntu22.04 配置固定IP 在VMware虚拟机配置中设置虚拟机网络为桥接模式 在虚拟机中配置固定IP # 设置网络配置 sudo vim /etc/netplan/00-installer-config.yaml 文件内容如下：\nnetwork: ethernets: ens33: dhcp4: no # 关闭 DHCP（分配IP） addresses: [192.168.138.128/24] # 你的虚拟机 IP，和主机在同一子网下 routes: - to: default via: 192.168.138.208 # 主机网关 IP nameservers: addresses: [8.8.8.8, 1.1.1.1] # 手动指定 DNS version: 2 可能会发现/etc/netplan文件夹下还有00-netcfg.yaml文件和50-cloud.init.yaml文件，我的选择是将其删除\n# 查询主机的IPv4地址和网关，不是VMware Network Adapter VMnet1和VMware Network Adapter VMnet8 ipconfig 启动配置 sudo netplan apply 重启就能发现虚拟机IP地址固定为你设置的IP地址了 配置VPN代理 在本地VPN代理中开启局域网连接，我使用的是Clash Verge 在.bashrc文件中添加代理 cd ~ vim .bashrc .bashrc添加内容如下：\n# 这里将IP地址修改为自己主机的IPv4地址 export http_proxy=http://192.168.138.180:7897 export https_proxy=http://192.168.138.180:7897 启动配置：\nsource .bashrc 配置Rust代理 Rust全局配置：\ncd ~ vim .cargo/config.toml config.toml添加如下配置内容：（这里将IP地址修改为自己主机的IPv4地址）\n[http] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; [https] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; 目前存在的问题 过了一段时间后发现，主机的IP和网关地址并不是固定不变的，这就需要每次修改虚拟机的配置，暂时还未解决，等待之后看看有没有什么比较好的解决办法吧\n写在最后 看网上的内容陆陆续续配了好几次，总是这里或者那里有问题，今天终于是配好了，好耶。\n也使用NAT模式配过，也是网上推荐比较多的，但是网络配置总是有问题，连接不上网络或主机，之后有机会去认真学习一下计算机网络了。\n最后，有问题多问AI，还是挺有帮助的。\n","permalink":"http://localhost:1313/posts/ubuntu22.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/","summary":"在Windows11上为VMware搭建的Ubuntu22.04虚拟机配置固定IP地址，共享主机VPN代理","title":"Ubuntu22.04虚拟机配置固定IP和VPN代理记录"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 老规矩，先看一下最终排名，截止2025/02/10, 总分第7，单榜第1，打开LeaderBoard第一个就是我了（嘿嘿） 个人认为project4完全做完应该是4个project中最难的吧，花的时间是最多的，不过开始写的时候刚好考试比较多，没多少时间写，大概花了几天时间把前几个task完成了，最后在考试完后回家写了几天才写完。虽然可能没写太久，但是感觉花费的精力挺多的。最后还是课程中那句话，有空闲时间再写写这个，优先去做更重要的事情。\nProject4 项目概述 在本次项目中需要实现数据库中的事务管理部分，也是在p3中介绍的SQL执行过程中开始和结束的部分。开始我们需要实现事务管理器创建事务，watermark对正在运行的事务的时间戳管理——用于垃圾回收，在当前正在运行的事务的时间戳范围之外即是可以回收的事务。再之后就是在事务执行时增删改查以及事务提交部分，由于不同事务创建时间点不同，需要读取不同时间点的数据，所以undoLog版本链由此而生，事务顺着版本链读取自己正在操作的数据或者当前事务创建前的数据（保证访问数据是自己能够访问的），Reconstruction函数也是因此而生的，用于对Tuple顺着版本链回退版本。增删改查操作比较简单，主要是保证读写版本链的正确性，读操作读取到正确的数据，写操作访问合法范围的数据（没有其他事务正在操作或已经操作过）。commit操作主要是修改事务的状态和提交时间戳（后续会用），并且修改事务操作过的数据的时间戳（修改为提交时间，事务操作时为事务id，防止其他事务操作）。垃圾回收就很简单了，回收watermark中时间戳范围外的已提交的事务即可。\n然后就是麻烦的部分来了，开始考虑索引的影响，读操作会调用IndexScan（需要修改），Insert时需要考虑索引冲突，Update时需要考虑主键修改。在这之后就是所有的并发，包括插入的并发（需要考虑索引冲突）、更新的并发（这个倒是没有主键更新）、事务取消的并发（bonus中的部分）、序列化的并发（leaderboard-2），并发算是这部分中的难点。总结并发实现就是重构重构重构，改了很多才全部实现通过。\nTask #1 - Timestamps task1主要是熟悉下这部分内容相关代码，写的部分比较简单。总共实现两个部分：\n事务管理器中创建事务，赋予时间戳，将其放入watermark中 watermark管理所有正在运行的事务，保存正在运行的事务的最小时间戳，创建事务时向其中添加事务时间戳，提交事务时从中删除。 关于这一部分的O(1)实现方法，利用事务管理器中的last_commit_ts_，它赋予给所有创建的事务，并且是单调递增，在commit时+1。这样便可以确定watermark中时间戳在一定的范围内，时间范围最大为last_commit_ts_，最小为正在运行的事务中的最小时间戳，并且由于时间戳+1递增，所有watermark也使用+1递增寻找符合的事务。具体实现为除非watermark为空，否则添加时不修改watermark值，删除时判断是否还有时间戳为watermark的事务，没有就递增搜索，直到commit_ts。 Task #2 - Storage Format and Sequential Scan task2算是初步了解这部分中的内容，也是两个部分：\nTuple Reconstruction，根据undo_logs中内容回退tuple中的数据，主要注意的是对已删除的数据的操作（执行前已删除，执行后已删除） 顺序扫描，顺着版本链扫描，如果为当前事务操作的数据或者时间戳比当前事务创建时间戳小，直接读取即可，对于其他事务正在操作或已经操作过的数据，需要顺着undo_log版本链构建undologs，使用1中的函数构建合适的Tuple Task #3 - MVCC Executors task3算是这部分的核心内容吧，实现增删改查这些基本操作在事务下的执行过程以及事务的提交，\nInsert 向table中插入数据即可，需要同时向write_set中传入对应rid（后续会在commit中统一修改对应Tuple的时间戳，表明该Tuple没有事务在执行，当前事务操作完毕，也可以用于Abort中取消对Tuple的操作）\nCommit commit主要是两个操作，一是修改last_commit_ts_以及当前事务的commit_ts；二就是读取write_set，修改事务执行过写操作的Tuple的时间戳为当前事务提交的时间戳即commit_ts\nUpdate \u0026amp;\u0026amp; Delete Update和Delete操作差不多，都是根据读取的数据进行操作，需要判断读取的数据时间戳，有三种情况：\nTuple时间戳小于等于当前事务时间戳，表明这个Tuple没有被当前事务之后的事务操作或正在被其他事务操作，直接操作Tuple，然后写入UndoLog、写入writeSet、更新VersionLink Tuple的时间戳等于当前事务ID，表明这个事务之前被当前事务操作过，在操作过Tuple就需要更新之前提交的UndoLog 其他情况，包括没有事务操作但时间戳比当前事务操作（被当前事务之后的事务操作过了）、已经有其他事务在操作了两种情况，这两种情况都是写写冲突 Stop-the-world Garbage Collection 垃圾回收实现比较简单，主要是利用task1中的watermark来实现，对于所有已提交的事务，如果它的提交时间比watermark_ts小或者undo_log为空，这两种情况都表明这个事务都不再被访问，直接回收即可，总共就一个循环加上一个判断即可，没几行代码。这里解释下为啥这样写，一是watermark本来就是为了垃圾回收机制而设计的（我是这样理解的），二是对于所有undoLog为空的事务，不会有版本回退访问到的情况，三就是对于所有提交时间戳小于watermark的事务，是不会被正在运行的事务访问到的，仔细想一想，undoLog是存放修改之前的数据状态。\nTask #4 - Primary Key Index task4中引入索引，不过是单索引，这时候对版本链的操作发生了变化。由于索引指向的地址不会发生变化，对于同一个索引指向的Tuple存在删除数据后又重新插入的情况，同时在插入时要需要判断索引冲突。引入了索引版本链才算完整（从Reconstruction的操作来看，存在从删除状态到未删除状态），同时索引在创建后是不会被删除的。这部分就和project3的多索引部分冲突了，因为可扩展哈希不支持多索引指向同一个Tuple，所有Project4和Project3不兼容。其实底层实现也有冲突，Project3更新操作是删除原数据，创建新的Tuple，因为Tuple大小不固定，但是在Project4就是原地修改，这时Tuple的大小就是固定了，这里可能存在冲突，不过我也没有去细看过，因为前面部分就冲突了，哈哈。\nInserts 这一部分便是重构Insert，考虑存在索引的情况。大致介绍下我的实现（包括并发）：\n首先便是判断是否有索引冲突，有就直接报写写冲突即可，同时记录插入的Tuple的索引是否存在 如果对应的索引存在，依旧是判断是否存在写写冲突，即索引指向位置的Tuple是否已删除且没有其他事务正在操作，满足条件就直接插入即可，修改versionLink、UndoLog、以及writeSet 如果对应的索引不存在，那么就和原本的Insert一样，插入数据，更新VersionLink（第一次插入是没有undoLog），然后创建对应索引即可 介绍下我对插入并发的实现，在1中判断是否有索引冲突，防止已经有索引还插入，在3中进行索引创建检查冲突，这里便是并发关键，如果有多个指向同一个索引的Tuple插入，便会发生竞争插入，最终只有一个插入成功，其余全部失败。 Index Scan, Deletes and Updates 这里是task中最麻烦的一部分吧，还有个Update的并发，介绍下我的实现。\n由于引入了索引，所以根据project3中实现的优化，这里会调用IndexScan，所以需要修改IndexScan，使其能够适应事务的操作，实现大致和SeqScan差不多吧 Delete和Update操作没有太大变化，主要是由于索引存在，版本链和之前不同，存在对已删除的地方进行插入，所以对undoLog和versionLink的操作有小部分修改 最后介绍下并发的实现，并发使用versionLink来实现并发操作。先介绍下原理，实现的关键是UpdateVersionLink和GetVersionLink函数中有锁，并且这个函数由txn_manager管理，保证所有事务对versionLink的操作是原子的（原子操作是实现并发的关键，加锁便是为了实现原子操作——执行过程不会被其他事务插队）。接下来就有点类似于操作系统中的利用底层原子操作来实现并发的方法了——自旋检查，检查过程是原子的，通过这部分实现并发。下面是具体实现（也是借鉴了其他实现了这部分代码的大佬的思路）： 先检查写写冲突，有写写冲突直接退出即可 自旋检查version_link中in_progress是否为false，这表明这个rid指向的tuple没有其他事务在操作 调用UpdateVersionLink函数，传入检查函数，检查是否已经有其他事务获取了in_progress（检查是原子的），然后修改in_progress为true，表明有事务在操作该Tuple，其他事务只能自旋等待。如果执行失败可以跳转1重新检查并进入自旋等待 再次检查是否有写写冲突（这部分貌似没有被执行过，在我的代码里我测过，不过其他大佬都写了，我也写一下） 写一下我的微操作，也是其他大佬没写的部分。一是修改了VersionLink的状态，在原本的设计中，在最开始插入时，versionLink是为空的，但是这样自旋判断存在问题（没有versionLink，就没有in_progress），所以我在一开始就插入versionLink，让它指向一个不存在UndoLog(默认的)，通过GetUndoLogOptional函数来判断是否到版本链终点，这其实也是我最开始写这部分的想法（让versionLink——指针指向为空表示没有UndoLog，而不是UndoLog指向为空），也和其他同学交流过，终于这样写也是舒服了。二就是在commit时在统一修改versionLink的in_progress为true，这样也和write_set同步了，也不需要加入多的结构，正好符合设计，也防止被其他事务插队。 Primary Key Updates 主键更新也是大坑，倒是没有并发，但是是单索引，不符合Project3的测试。实现的关键点就是先获取所有的数据，对其进行更新操作，判断是否有索引冲突，然后再统一删除原本的数据，然后插入新的位置。冲突可以通过Expression中修改的位置下标来判断是否有索引变化。\nBonus Bonus Task 1: Abort Abort主要是实现Abort函数，通过writeSet来将事务操作过的数据恢复原本的状态，同时回退versionLink和UndoLog，这部分主要是针对前面写写冲突抛出的tainted的事务，将其所做的操作复原。这部分还有个更重要的问题是并发的实现发生了变化，原本是利用in_progress来实现并发，从这里开始使用底层的page锁来实现并发了，原先的versionLink锁的部分可以删除了，不过并发的实现也变得更简单了。\nBonus Task #2 - Serializable Verification 这一部分主要是检查在事务并发过程中，是否存在并发过程中事务执行顺序不同导致不同的结果——即序列化的正确性，如果存在这种情况，就需要进行Abort。这部分主要是实现VerifyTxn函数，这个函数主要是检查已经提交的事务中是否存在和当前事务有序列化冲突的情况，如果有便直接Abort，这个已经提交的事务是指当前事务执行过程中可能会对当前事务操作的数据进行影响的事务，即提交在当前事务创建之后。\nleaderboard LeaderBoard难点在第二个，也就是对 bonus task2 序列化的并发实现，如果有问题，请查看其他代码的实现有无问题，反正就是重构重构。给的论文没有去看，有时间再说吧，感觉直接写就行，也不一定需要看，就像课程内容一样。\n写在最后 到此bustub 23fall 的4个project已经圆满完成，所有分数已经拿齐，能做的优化也基本做了，除了project3的LeaderBoard，其他的都做了，也取得了不错的成绩，还是不错的。接下来按照安排是去实现tinykv，可能也会写一写文章吧，还有bustub24fall可能也会去做，稍微瞄了一眼，24fall也改了不少，而且B+树的实现是必须要去做的。总体感觉bustub一年比一年难了，也更加完整了，也是变得越来越好了，希望这门课程变得越来越好吧。通过这4个project也是学到了很多东西，对C++、对数据库、对代码能力都是巨大的提升，有兴趣的同学都可以来写一写（不过看到这的同学都是写过的吧，哈哈）还是挺不错的。\n最后, 感谢 CMU 15445 的老师和助教们的辛勤付出\n考虑到网上实现最后这部分内容的文章比较少，代码也是没有，我把我的代码放在这，这部分课程也是即将结束，应该也没几个人写了，有兴趣的同学可以参考一下，我觉得我写的还是不错的，哈哈哈。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project4/","summary":"CMU 15445 23fall Project4 实现","title":"CMU 15445 23fall Project4"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 project3开始真正进入数据库的实现了，通过实现这一部分内容，你会对数据库的基本结构有一个清晰的认识，在这一部分中需要多读代码，具体实现较为简单，需要对数据库的整体实现结构有一个清晰的认识才好实现这一部分内容。这一部分的leaderboard我没有做，感觉设计不是很好，不太感兴趣，就没写这部分，看榜单也没几个人写这个，我这里就放一下100分的截图。\nProject3 总体概述 这里介绍下我对下面这个整体流程图的认识：首先由事务管理器创建事务，然后由事务执行SQL语句，然后开始解析SQL语句(Parser)(在bustub_instance中)，根据解析出来的语句与相应的关键字进行绑定(Binder)，然后构建出执行树(Planner)，再之后对语法树进行优化(Optimizer)(调整结构，在bustub中是逻辑优化，安装固定顺序执行设定好的优化)。语法树优化完毕后便将其传递到执行器中执行(Executor)(包含执行的上下文即事务、相关数据如索引表、table表，Expression如where表达式中的谓词)，执行器使用火山模型，自底向上分层执行，上层调用下层获取执行结果，并将本层的执行结果传递给更上层。火山模型优点挺多，设计简单，各层解耦合，执行效率也比较高。\n总体来说，这一章并不难，关键在于与前面两章完全解耦（前面两章为索引和底层的缓冲池，索引和表都在用），在本章中需要阅读大量代码，对整个项目有一个基本的认识，才能够着手开始实现执行器和优化器中的业务逻辑，业务逻辑实现并不复杂，关键还是读代码学习简易数据库的设计。\nTask #1 - Access Method Executors task1就是实现基本的增删改查的内容，关键是需要理解数据库的整体设计，如表的设计、索引的使用（project2中设计），二者关联、Expression的使用，执行计划树结构，以及火山模型的执行器设计结构。还需要对常用结构有清楚的认识，如index索引、table表数据、schema表数据与索引的关联、plan可能会存放的数据(如操作的表id，涉及到的Expression)，以及Expression的Evaluate操作（常量表达式、逻辑运算、比较运算、算术运算、字符串）\n优化操作，将顺序扫描优化成索引扫描，具体是否优化看where表达式中的谓词，实现细节仿照已有的优化器即可（自带几个实现好的优化器）\nTask #2 - Aggregation \u0026amp; Join Executors Aggregation 聚合操作，即一些分块(group by)函数(如min、max、avg、sum)操作，关键点在于需要实现一个自定义的哈希表，根据groupby结果生成对应的key，并对key值对应的value执行指定的聚合操作。按照这些操作形成聚合树后再就行迭代访问得到结果即可。\nNestedLoopJoin 联结操作，即多表联结，主要就是对两表进行联结操作，保留左表和右表，两重循环表里左表和右表（左表在外层），符合条件的即为联结的结果\nTask #3 - HashJoin Executor and Optimization HashJoin 仿照实现一个类似于Aggregation中的自定义哈希表，将原本的NLJ为两层循环操作，通过哈希表，将内层变成哈希表查找符合条件的元素，将两层循环便优化成一层循环，时间复杂度由O(n2)优化成O(n)\nNLJ -\u0026gt; HashJoin 根据Expression中的逻辑表达式进行递归判断即可，在执行时需要根据col_id判断是左表还是右表的数据，将其放入正确的位置\nTask #4: Sort + Limit Executors + Window Functions + Top-N Optimization Sort ＆ Limit 最简单的一集，sort实现一个自定义的排序逻辑传入std::sort调用即可，limit就更简单了，取前几个数即可\nSort ＆ Limit -\u0026gt; Top-N 先排序再取前几个数，也很简单，无非不是把limit和sort结合，优化就是看看执行树中是否有相邻两层为Limit和Sort\nWindow Functions WindowFunction是project3中最难的一部分了吧（除去LeaderBoard部分），需要根据是否有orderBy来进行排序(但是只需要排序一次), 使用partition来进行分类，然后进行函数操作，这部分有点类似于Aggregation操作，分类以及函数操作，只不过多了一个rank（需要单独考虑）\n写在最后 project3难点还是在于读代码，了解整个项目的设计结构，具体实现也就是一些常用的执行器的实现以及实现了几个优化器，但是也并不难。整体来说还是收获到很多东西，这一部分可能写的不是很详细，一是时间已经过去很久了，记不太清了，二是在后续project4中会修改很多地方，导致代码已经变化很多了。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project3/","summary":"CMU 15445 23fall Project3 实现","title":"CMU 15445 23fall Project3"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project2开始涉及到数据库索引的底层实现，今年做的是可扩展哈希，相比于B+树要简单不少，推荐学有余力的同学去做一下其他年份的B+树，总体来说没做多久，比Project1花的时间稍多一点。然后说一下LeaderBoard结果吧，截止2025/01/30排名第6\n时间有点久远，实现细节基本都忘了，讲一下我的整体思路吧\nTask #1 - Read/Write Page Guards Task1中实现对Page的读写锁的析构时自动释放和调用函数手动释放操作（要实现的就是一个能够在生命周期结束时自动释放锁和手动释放锁的结构），这部分实现较简单\nBasicPageGuard、ReadPageGuard、WritePageGuard类的构造函数、析构函数、=重载函数、Drop函数的实现，需要注意的是对锁不能重复释放，需要先进行判断 bufferPoolManager中pageGuard获取函数实现，锁在ReadPageGuard、WritePageGuard外部获取，但是在内部释放，感觉设计挺奇怪的，导致我一开始写这一部分出了些错误，后来想其觉得设计还是挺奇怪的，个人认为把锁的获取放在构造函数内更优雅 Task #2 - Extendible Hash Table Pages 这部分实现可扩展哈希的三层结构的具体实现，包括初始化，各种功能函数的实现，基本按照函数名就知道有啥用，相应实现即可，比较简单。\n自底向上简单介绍下这三层结构的意义：\nbucket层，桶的功能设计，实际存放所有的元素，所有的增删改查都会操作这层实例元素，并且所有索引指向的元素是唯一的，插入前需要检查 directory层，可扩展哈希的核心设计，向下进行桶的分裂与合并（也是这部分的难点），保证存储空间的高效利用，向上提供索引，指向实际元素的位置。 header层类似于操作系统中多页表设计中的外层页表，用于增加directory的数量和并发度，实现通过索引映射到不同的directory 总结，整个可扩展哈希核心便是利用二进制数来进行索引，通过将二进制数不同段分别用于各层中的指向，实现了树形的索引树，同时在最下面两层，利用桶的分裂合并极大提高了空间效率。 关于桶分裂合并提高空间效率，通过利用global_depth_, local_depth_ 字段，将二进制中低位用于指向不同的bucket，高位用于重复利用，实现多个索引指向同一个桶，同时利用二进制位运算的性质，使得桶的分裂与合并操作较为简单。 多层的设计也是提高了空间利用率，在可扩展哈希的设计中，加锁只需要控制住两层即可，也就是说不同的directory之间是可以并发的 整个设计类似于多层哈希设计，不过通过利用二进制数来充当索引，同时利用了桶的分裂合并提高了空间效率。但是本身存在不少问题，包括并发度不高，并且索引冲突的问题无法解决。由此来看，如果想要深入学习数据库，学习B+树还是必要的，可扩展哈希貌似用的也不多，也没啥可优化的 Task #3 - Extendible Hashing Implementation 大致讲下这几个函数的实现思路：\nGetValue，也即是读操作，根据生成的索引从header（根节点）向下搜索直到得到对应节点退出，或者对应节点不存在返回false Insert，向内存中写入数据，根据索引向下进行搜索对应节点位置，如果不存在则创建（directory、bucket），如果重复则直接退出即可。关键便在于如果插入的桶满了，这时候需要进行桶的分裂操作 如果global_depth与local_depth相同，表明全局深度与局部深度相同，这时候就需要增加global_depth，增加bucket个数。 否则进行bucket分裂即可，分裂即增加local_depth，修改所有影响的bucket（用对应bucket复制即可） 分裂完毕重新进行插入操作，有可能插入失败（由于是按照索引来存放的，分裂后可能还是桶满），所以需要循环进行，直到达到最大深度或者插入成功，否则即插入失败 Remove，删除内存中的数据，由索引向下搜索，搜索到删除即可，搜索不到则说明不存在，返回false。关键是在删除后如果bucket为空，需要进行桶合并 桶合并需要使用位运算，判断local_depth下所有的桶都能够进行合并，否则如果存在不能够合并的桶，则不能进行合并操作。本质上是使用位运算来进行操作，local_depth决定取的低位数（即合并后的桶），左侧没取到的是高位数，左侧变化所包含的所有需要合并的桶的深度必须相同，才能够保证能够进行合并。 和桶分裂相同，桶合并操作也需要循环进行，直到不能够进行桶合并为止（存在合并一次后还能够合并） 写在最后 可扩展哈希实现还是挺有意思的，但是可扩展哈希局限性太多，也没啥可优化的，相比之下B+树应用更多，难度也更大，学有余力的同学还是去学习下B+树的部分。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project2/","summary":"CMU 15445 23fall Project2 实现","title":"CMU 15445 23fall Project2"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project1整体还是比较简单的, 大概在第一周就完成了Project1的全部内容, 然后在Project2完成之后, 花了一周的时间实现了Project1的代码优化。\n然后说一下优化结果, LeaderBoard 排名第10(2025/1/27), 优化结果如下:\n给前面几位神仙跪了, 断层领先, 有理由怀疑在hack, 各项数据太吓人了。我的这个排名差不多就是我的极限了吧, 能做到都已经做了。(hack我也不会, 哈哈)\n根据课程要求, 源代码暂时就不公开了, 等23fall课程结束再说吧\nProject1 总体概述 在Project1中, 我们需要实现内存中缓冲池管理, 包括lru-k策略(内存调度策略), Disk Scheduler(磁盘调度, 即读写磁盘数据操作), BufferPoolManager(结合内存调度和磁盘读写操作, 实现内存缓冲池管理, 实现读写物理page)。为什么要实现这个Project呢, 学过操作系统的同学应该就知道, 实际的物理存储介质呈金字塔形状, 内存大小远远小于物理磁盘, 内存中的空间是有限的, 要想访问存储在磁盘中的庞大数据, 就需要实现一个内存缓冲池, 将需要使用的页面调度到内存页中, 将不再访问的页面写回到物理磁盘中, 实现好像在读写整个物理磁盘的效果。\nTask #1 - LRU-K Replacement Policy 在Task1中我们需要使用lru-k策略实现内存页调度策略。其中每一个frame对应一个内存中的page(数量有限, 内存页), 而在bufferManager中的page是实际存储数据的物理page(物理页), 相对于frame(内存page)而言是无限的。从这里就可以看出, 我们的任务实际是在实现内存的调度策略, 将物理页中的数据调度到内存页中进行访问, 当空闲内存页不够时, 对正在使用的内存页进行Evict, 获取空的内存页, 然后在bufferManager中将新的物理page中的数据存放到内存页中以便访问。\n实际实现内容:\nEvict, 从所有正在使用的内存页(evictable)中淘汰出一个空的内存页, 将其返回给bufferPoolManager RecordAccess, 访问记录, 用于lru-k策略 SetEvictable, 根据frame_id将frame设置为evictable状态, 即可以被淘汰 Remove, 从lru-k队列中删除指定frame_id, 将其设置为空闲状态, 这个函数实际貌似没怎么用过, 个人认为是跟lru-k策略没啥关联, 并且也需要和bufferPoolManager联动, 将空闲frame_id放入BufferPooManager中 我的实现:\n使用两个队列存放所有使用的frame 一个history_list队列, 存放访问次数少于k次的frame, 先进先出策略； 一个lru_list队列, 存放所有访问次数大于等于k次的frame, 我的策略是选择Evict时顺序遍历求访问时间最小的frame(也算是一种lru-k策略的优化吧, 对lru_list进行Evict操作为O(n)操作, 对lru_list队列中的frame进行操作为O(1)操作) lru-k策略介绍: 如果访问次数小于 K次, 那么不作更改, 因为小于 K 频次时 FIFO. 如果访问次数等于 K次, 那么将结点从 history_list_ 中移动到 lru_list_ 中. 如果访问次数大于 K, 那么逐出结点记录的最早访问记录, 然后再将该结点插入到 lru_list 队列中(按我的实现策略, 任意位置即可) 关于并发, 没什么好的思路, 一把大锁即可 Task #2 - Disk Scheduler 在Task2中我们需要实现对磁盘的读写操作(IO操作), 这一部分比较简单\n实现内容:\n主要实现Schedule函数, 将IO操作独立出去, 放在单独的线程中执行IO操作, 并发优化的点也在这一部分 Task #3 - Buffer Pool Manager 在Task中我们就需要综合Task1中的Lru-k内存调度策略和Task2中的磁盘调度实现缓冲池管理, 使缓冲池能够自由访问物理页数据, 实现页面好像直接在读写物理页的, 不需要了解内存页的效果。\n实现内容:\nNewPage, 创建一个新的Page物理页 FetchPage, 读取指定page_id的物理页 UnPinPage, 当页面使用完毕, 会调用这个函数, 表明正在使用这个页面的人数减一, 当减到0时, 就可以将其设置为Evictable, 即内存调度策略中可以被淘汰的内存页 FlushPage, 将指定page_id的页面从内存页写回物理页 FlushAllPage, 将内存中所有页面写回到物理页 DeletePage, 删除指定page_id的页面, 将其内存页回收为空闲状态放入free_list_, 如何是脏页面就写回磁盘(这三个函数都没怎么用过) 我的实现:\nNewPage函数, 从AllocatePage函数获取page_id, 从free_list获取内存页, 如果free_list为空就需要从使用lru-k策略从内存内Evictable的页面中淘汰出内存页, 如果淘汰出的页面是脏页面还需要写回磁盘, 剩下就是创建新页面, 返回page_id和Page实例 FetchPage函数, FetchPage和NewPage差不多, 只是FetchPage需要先判断内存中是否有page_id的内存页, 如果没有, 就需要从磁盘中读取到内存中, 读取操作和NewPage差不多, 只是多了读取磁盘数据 UnpinPage函数, 修改page中的pin_count_和is_dirty_字段即可, 如果pin_count_变成0了, 将其设置为evictable即可, 这个功能较简单 FlushPage和FlushAllPage差不多, 一个指定page_id, 一个遍历所有内存中的page, 将内存页写回物理页, 调用DiskScheduler即可, 别忘了重置is_dirty状态 DeletePage函数, 淘汰指定page_id的内存页, 如果还有人员正在使用那是不能删除的哟, 如果是脏页面就将其学会内存, 剩下就是将其使用的资源回收 LeaderBoard Task 借用下隔壁大佬的话\nDoing Project without the LeaderBoard is equivalent to playing games without Genshin Impact.\n在这个任务中我们需要实现并发操作, 在一开始最好使用一把大锁, 先确定所有实现的函数有没有问题, 然后再考虑细分锁的问题。\n我的实现: 一把大锁加上去, 细化放在优化里面讲\n代码效率优化(LeaderBoard排名优化) Task1 LRU-K Replacement Policy 优化 我的尝试:\n由于在Task1中已经将lru-k策略设计好了, 我尝试使用另一种实现策略。将lru_list队列设置为有序, history_list队列不变, 每次RecordAccess都对lru_list_进行位置调整, 这样Evict效率变为O(1), RecordAccess效率降低, 但是由于lru_list现在有序(可以冒泡移动), 效率不到O(n).但是最终结果表明这样效率并没有提升, 也可能是我实现有问题吧, 有兴趣的同学可以实现, 这部分代码被无语的我删掉了(版本回退消失了) 利用access_type属性, 由于在Leaderboard中开启了16个线程, 其中8个随机读写, 8个顺序读写, 可以access_type稍稍调整lru-k的实现策略实现效率提升(这个我使用了, 确实效率提升不少) Task2 Disk Scheduler 优化 我的尝试:\n磁盘调度优化显而易见, 原本磁盘调度是单线程, 将其修改为多线程即可 由于并发度不同, 磁盘调度我选择设置为动态线程池, 在并发度较低时线程池也较小(开动态线程池貌似也没啥效率提升, 哭, LeaderBoard测试太死了) Task3 \u0026amp; LeaderBoard 并发优化 我的尝试:\n刚开始选择为每一个使用的资源设置一个锁, pages设置一个锁的数组(每个page一个锁), 遵守二阶段锁策略, 尽量将各部分加锁部分分离, 使其尽可能并发 随着并发的深入学习实现, 理解了这部分并发提升效率的本质: 并发本质是将IO操作并发(这是可以并发的, 和DiskScheduler实现有关), 其他bufferPoolManager属性加一把锁即可, 这部分没有并发可言, 基本所有函数都有在操作。最关键点在于, IO的操作较慢, 需要并发来提升效率, 实际对属性字段操作较快, 并且多个线程都需要操作, 加锁变成单线程即可 最终结果: 对pages外的所有数据使用一把大锁latch_, 对Pages_使用锁数组(防止对同一个page操作并发冲突), 遵循二阶段锁策略, 尽量将IO操作和对bpm的字段操作分离开, 分别加锁, 利用IO并发提高效率 写在最后 本来是考虑使用火焰图perf来看那些部分需要优化, 但是在我的设备上总是有问题, 至今没有解决, 最终选择从设计上来思考如何优化。从最终结果来看, 优化的还不错, 学到了挺多东西, 花了我大概一周的时间。如果有同学想优化代码, 可以考虑使用火焰图, 从使用火焰图的同学和师兄的说法来看, 还是不错的。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project1/","summary":"CMU 15445 23fall Project1 实现及优化","title":"CMU 15445 23fall Project1"},{"content":" 前言 我是用的artalk搭建的评论系统，部署在我自己的服务器上，在本地部署成功后，由于GitHubPages的页面使用https访问，而服务器数据访问使用的是http，导致在GitHubPages界面上加载失败。\n我的解决方案：由于使用https需要ssl证书，获取ssl证书又需要域名，所以在阿里云上购买了一个便宜的域名。由于云服务提供商的ssl证书太贵了（我记得前几年还免费来着，晕），所以选择从Let\u0026rsquo;s Encrypt 上获取ssl证书（有效期为90天，需要定期更新，但是免费）。这时候又遇到问题了，由于我使用的是京东云的服务器，由于没有备案，https请求全被拦截了，现在又恰逢过年，没时间备案（同时我也不太想去搞，问东问西的，时间跨度也挺长）。评论系统搭建暂时搁置，后续可能会选择备案，或者选择购买国外的服务器搭建，或者看能否不用https，或者暂时就不搭建了，等以后再说，反正也没人看不是。\n总结：如果你有已备案的国内的服务器，并且有域名和ssl证书，那么下面可以看，否则就不用看了。更好的推荐是使用第三方提供的评论系统了。\n安装环境 Ubuntu22.04 京东云2h4g服务器 参考文献 【Artalk】一文教会你部署整合博客评论功能 官方文档 artalk安装 我选择docker安装，简单易用（刚好之后要学习go，用go安装过，但是存在问题，老实了）\n首先你需要在服务器上安装一个 Docker（这我就不详细介绍了，没有得小伙伴可以去网上搜搜）。\n然后新建一个文件夹用于存放 Artalk 文件（/root/artalk)，然后执行下面的命令，只需要修改中文提示的地方：\n# 安装artalk cd artalk docker run -d \\ --name artalk \\ -p 服务器端口:23366 \\ -v $(pwd)/data:/data \\ -e \u0026#34;TZ=Asia/Shanghai\u0026#34; \\ -e \u0026#34;ATK_LOCALE=zh-CN\u0026#34; \\ -e \u0026#34;ATK_SITE_DEFAULT=站点名\u0026#34; \\ -e \u0026#34;ATK_SITE_URL=站点URL\u0026#34; \\ --network artalk \\ artalk/artalk-go # 创建管理员账户 docker exec -it artalk artalk admin 浏览器输入 http://站点URL 进入 Artalk 后台登录界面，剩下的看着需要修改就行。\n数据库安装 同样选用docker安装数据库，我选择使用mysql5.7的docker镜像来部署服务，将数据库和artalk部署在同一个docker网络下（因为artalk会访问数据库，artalk会自动初始化数据库，但是貌似需要自己手动创建数据库）\n# 创建mysql容器，和artalk部署在同一个网络下 docker run -d \\ --name mysql \\ -e MYSQL_ROOT_PASSWORD=YourPassword \\ -p 3306:3306 \\ -v $(pwd)/mysql:/mysql \\ --network artalk mysql:5.7 # 进入mysql中创建artalk数据库，注意创建数据库时字符，需要和artalk中相同 docker exec -it mysql mysql -uroot -p 最后在artalk的管理界面填写数据库信息就行，数据库地址就写数据库容器名称\n到现在已经可以使用了，但是仍未开启https，在https界面是加载不出使用http的评论系统的\n开启https 这是我当前选择的方案\n首先就是购买域名，ssl证书是和域名绑定的，没有域名就拿不到ssl证书 买了域名之后就是添加DNS解析（国内服务器可能还需要备案，真羡慕国外的服务器） DNS解析配置完毕就是获取ssl证书，云服务器提供商ssl证书太贵了，我选择使用Let\u0026rsquo;s Encrypt 提供的ssl证书 以下是ssl证书获取，我是通过DNS解析TXT通过的验证，并没有使用nginx（因为服务器没备案，通过域名的http请求都被拦截了，哭）\n# 安装certbot sudo apt update sudo apt install certbot # 使用DNS验证申请 sudo certbot certonly --manual --preferred-challenges dns -d 你的域名 # 按照提示在域名解析中添加TXT记录，确认添加成功后再按确认 构建之余 也是用过docker-compose搭建，这个确实简单点，这是我当时写的配置文件，后续使用这个创建过。由于mysql的docker已经创建了，所以没有添加，仅供参考。\nservices: artalk: container_name: artalk image: artalk/artalk-go restart: unless-stopped ports: - 8080:23366 volumes: - ./data:/data networks: - artalk environment: - TZ=Asia/Shanghai - ATK_LOCALE=zh-CN - ATK_SITE_DEFAULT=网站名称 - ATK_SITE_URL=网站URL - ATK_ADMIN_USERS_0_NAME=管理员名称 - ATK_ADMIN_USERS_0_EMAIL=邮箱地址 - ATK_ADMIN_USERS_0_PASSWORD=(bcrypt)$2y$10$HnxBjnRnYF4Teg7jqedNL.MBtRcmNkk.ZmRU1SecB.afXIz.uVd6q - ATK_ADMIN_USERS_0_BADGE_NAME=管理员 - ATK_ADMIN_USERS_0_BADGE_COLOR=#0083FF networks: artalk: external: true ","permalink":"http://localhost:1313/posts/%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/","summary":"评论系统搭建，服务器没备案，https访问被拦截，暂时搭建失败，仅供参考","title":"博客评论系统"},{"content":" 开发环境 Ubuntu22.04 京东云2h4g服务器 Hugo version: 0.141(下载的时候没注意，直接就下了最新版了) PaperMod version: 2025-01-22最新版本(git安装的) 相关文档 官方文档 Hugo中文文档 PaperMod GitHub官网 参考文章 Hugo PaperMod 主题精装修 我是如何建立自己的个人博客的？ Hugo-papermod主题的优化记录 PaperMod主题配置 开始 hugo安装 # 从github下载需要版本的hugo wget https://github.com/gohugoio/hugo/releases/download/v0.141.0/hugo_extended_0.141.0_Linux-64bit.tar.gz # 解压 tar -xvzf hugo_extended_0.141.0_Linux-64bit.tar.gz # 移动hugo到/usr/local/bin/ sudo mv hugo /usr/local/bin/ # 查看是否安装成功 hugo version 安装主题 我使用的是PaperMod主题，在PaperMod的基础上进行了一些魔改，参考这个网站，PaperMod下载按官网流程即可\n# 配置文件用yaml，别问为什么，都是这样推荐的，能用就行 hugo new site MyFreshWebsite --format yaml # replace MyFreshWebsite with name of your website cd MyFreshWebsite # 初始化git git init # 安装PaperMod git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 # 这部分应该是在git仓库里建了一个子仓库，方便从github更新PaperMod，我觉得没啥必要，更新的情况太少，能跑够用就行了，需要的话手动更新就行了 cd themes/PaperMod git pull cd ../.. git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) git submodule update --remote --merge # 这部分记不太清了，不搞明白有什么作用 hugo mod init YOUR_OWN_GIT_REPOSITORY 配置文件 新版配置文件名称默认为hugo.yaml\n参考的其他人的介绍的配置文件，这个注释较多就用这个了，请根据需要修改\n主页显示我用的profileMode，这个好看点，默认和文章界面重复了\n# 起始 URL（换成您自己的域名） baseURL: \u0026#39;https://hugo-start.pages.dev\u0026#39; # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 每页显示的文章数量 paginate: 5 # 主题名称 theme: PaperMod # 语言代码（zh-简体中文） languageCode: \u0026#39;zh\u0026#39; DefaultContentLanguage: \u0026#39;zh\u0026#39; # 是否有 CJK 语言（中-日-韩） hasCJKLanguage: true # 是否生成 robots.txt enableRobotsTXT: true # 是否构建草稿 buildDrafts: false # 是否构建未来的文章 buildFuture: false # 是否构建过期的文章 buildExpired: false # 是否启用 Emoji enableEmoji: true # 是否启用 Git 信息 enableGitInfo: false # Google Analytics ID googleAnalytics: \u0026#39;\u0026#39; # 压缩输出静态文件 minify: # 是否不压缩 XML 文件 disableXML: true minifyOutput: true # 全局配置 params: env: production # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 网站描述 description: \u0026#39;Hugo Start with PaperMod\u0026#39; # 网站关键词（大部分搜索引擎已放弃，可注释掉） # keywords: [Blog, Portfolio, PaperMod] # 网站作者 author: \u0026#39;Your Name\u0026#39; # 多个作者写法 # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # OpenGraph / Twitter Card 预览图片（/static 下面的文件名称） images: [\u0026#39;opengraph.webp\u0026#39;] # 日期格式 DateFormat: \u0026#39;2006-01-02\u0026#39; # 默认主题 defaultTheme: auto # dark, light # 是否启用主题切换按钮 disableThemeToggle: false # 是否启用阅读时间展示 ShowReadingTime: true # 是都启用分享按钮 ShowShareButtons: true ShowPostNavLinks: true # 是否启用面包屑导航 ShowBreadCrumbs: true # 是否显示代码复制按钮 ShowCodeCopyButtons: false # 是否显示字数统计 ShowWordCount: true # 是否在页面显示 RSS 按钮 ShowRssButtonInSectionTermList: true UseHugoToc: true disableSpecial1stPost: false # 是否禁用首页滚动到顶部 disableScrollToTop: false # 是否启用评论系统 comments: false # 是否隐藏 Meta 信息 hidemeta: false # 是否隐藏文章摘要 hideSummary: false # 是否显示目录 showtoc: false # 是否默认展开文章目录 tocopen: false assets: # disableHLJS: true # to disable highlight.js # disableFingerprinting: true # 网站 Favicon 图标相关信息 # 可在 https://realfavicongenerator.net/ 生成 # 将图片复制到 /static 目录下 # 然后修改下面代码中的文件名 favicon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon16x16: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon32x32: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; apple_touch_icon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; safari_pinned_tab: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; label: # 使用文本替代 Logo 标签 text: \u0026#39;Hugo Start\u0026#39; # 网站 Logo 图片（/static 下面的文件名称） icon: /apple-touch-icon.png # 图标高度 iconHeight: 35 # 主页展示模式 # 个人信息模式 profileMode: enabled: false # needs to be explicitly set title: ExampleSite subtitle: \u0026#39;This is subtitle\u0026#39; imageUrl: \u0026#39;\u0026lt;img location\u0026gt;\u0026#39; imageWidth: 120 imageHeight: 120 imageTitle: my image buttons: - name: Posts url: posts - name: Tags url: tags # 主页 - 信息模式（默认） homeInfoParams: Title: \u0026#34;Hi there \\U0001F44B\u0026#34; Content: Welcome to hugo start, this is a example of Hugo and PaperMod # 主页 - 信息模式 图标展示 socialIcons: # - name: twitter # url: \u0026#34;https://twitter.com/\u0026#34; # - name: stackoverflow # url: \u0026#34;https://stackoverflow.com\u0026#34; - name: github url: \u0026#39;https://github.com/DejavuMoe/hugo-start\u0026#39; - name: mastodon url: \u0026#39;https://sink.love/@dejavu\u0026#39; # 站长验证 analytics: google: SiteVerificationTag: \u0026#39;\u0026#39; bing: SiteVerificationTag: \u0026#39;\u0026#39; yandex: SiteVerificationTag: \u0026#39;\u0026#39; # 文章封面设置 cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page # 关联编辑 editPost: URL: \u0026#39;https://github.com/DejavuMoe/hugo-start/edit/master/content/posts\u0026#39; Text: \u0026#39;Edit on GitHub\u0026#39; # edit text appendFilePath: true # to append file path to Edit link # for search # https://fusejs.io/api/options.html fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#39;title\u0026#39;, \u0026#39;permalink\u0026#39;, \u0026#39;summary\u0026#39;, \u0026#39;content\u0026#39;] # 顶部导航栏 menu: main: - identifier: \u0026#39;首页\u0026#39; name: \u0026#39;首页\u0026#39; url: / weight: 1 - identifier: \u0026#39;分类\u0026#39; name: \u0026#39;分类\u0026#39; url: /categories/ weight: 10 - identifier: \u0026#39;标签\u0026#39; name: \u0026#39;标签\u0026#39; url: /tags/ weight: 20 - identifier: \u0026#39;仓库\u0026#39; name: \u0026#39;仓库\u0026#39; url: https://github.com/DejavuMoe/hugo-start weight: 30 # Read: https://github.com/adityatelange/hugo-PaperMod/wiki/FAQs#using-hugos-syntax-highlighter-chroma pygmentsUseClasses: true markup: highlight: noClasses: false # anchorLineNos: true # codeFences: true # guessSyntax: true # lineNos: true # style: monokai privacy: vimeo: disabled: true enableDNT: true simple: true twitter: disabled: true enableDNT: true # 是否启用添加“请勿跟踪” HTTP 头。 simple: true # 如果启用简单模式，将建立一个静态的、无 JS 版本的推文。 instagram: disabled: true simple: true youtube: disabled: true privacyEnhanced: true services: instagram: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 twitter: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 默认模板 文章创建时的默认模板，相对于config全局配置，这里是局部配置，控制文章显示的必要属性\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} lastmod: {{ .Date }} draft: true # 是否为草稿 author: [\u0026#34;tkk\u0026#34;] categories: [] tags: [] keywords: [] description: \u0026#34;\u0026#34; # 文章描述，与搜索优化相关 summary: \u0026#34;\u0026#34; # 文章简单描述，会展示在主页 weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序 slug: \u0026#34;\u0026#34; comments: false autoNumbering: true # 目录自动编号 hideMeta: false # 是否隐藏文章的元信息，如发布日期、作者等 mermaid: true cover: image: \u0026#34;\u0026#34; caption: \u0026#34;\u0026#34; alt: \u0026#34;\u0026#34; relative: false --- \u0026lt;!-- more --\u0026gt; Github Pages部署网站 创建GitHub远程仓库 在Github创建仓库，仓库名填写[用户名].github.io，注意[用户名]部分必须是Github用户名，否则Github Pages不会正常工作。\n勾选Add a README file，点击Create Repository，创建仓库。\n将本地仓库推送到Github 在根目录下创建.gitignore，内容如下：\npublic resources .hugo_build.lock 创建远程仓库并提交\n# [username]替换为用户名 git remote add origin git@github.com:[username]/[username].github.io.git # 提交 git add . git commit -m \u0026#34;Hugo + PaperMod\u0026#34; # 推荐本地分支和远程分支名用main，免得不必要的麻烦（github安全检查） git push -u origin main 访问github仓库，选择 Settings \u0026gt; Pages , 将Build and deployment中source设置为Github Actions\n配置Github Actions 在本地仓库中创建文件.github/workflows/hugo.yaml，根据Hugo版本修改，内容如下：\n# 用于构建和部署Hugo网站到GitHub Pages的示例工作流程 name: 发布Hugo网站到Pages on: # 在目标为默认分支的推送上运行 push: branches: - main # 允许您手动从“Actions”标签运行此工作流程 workflow_dispatch: # 设置GITHUB_TOKEN的权限，以允许部署到GitHub Pages permissions: contents: read pages: write id-token: write # 仅允许一个并发部署，跳过在进行中的运行与最新排队的运行之间排队的运行。 # 但是，请不要取消进行中的运行，因为我们希望这些生产部署能够完成。 concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # 默认使用bash defaults: run: shell: bash jobs: # 构建作业 build: runs-on: ubuntu-22.04 env: HUGO_VERSION: 0.141.0 steps: - name: 安装Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: 安装Dart Sass run: sudo snap install dart-sass - name: 检出 uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: 设置Pages id: pages uses: actions/configure-pages@v3 - name: 安装Node.js依赖 run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: 使用Hugo构建 env: # 为了与Hugo模块的最大向后兼容性 HUGO_ENVIRONMENT: production HUGO_ENV: production run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: 上传构建产物 uses: actions/upload-pages-artifact@v2 with: path: ./public # 部署作业 deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: 部署到GitHub Pages id: deployment uses: actions/deploy-pages@v2 提交，推送至远程仓库\ngit add . git commit -m \u0026#34;Add workflow\u0026#34; git push 未完成 评论系统 目前选择的是artalk作为评论系统，但是目前还存在问题，这是当前进度。\n图床 随着文章数量增多，图片将会越来越多，而github仓库有大小上限，将图片放在github上是不合理的，之后会考虑构建一个图床，但是存在和评论系统同样的问题，暂时没有构建\n","permalink":"http://localhost:1313/posts/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"使用Hugo + PaperMod + GithubPages 搭建个人博客网站","title":"Hugo个人博客搭建"},{"content":" git # 更新软件包列表 sudo apt update # 安装git sudo apt install git # git配置 # 验证安装 git --version # git配置 git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;youremail@domain.com\u0026#34; # 查看git配置 git config --list # 清除配置 git config --global unset \u0026#34;错误属性\u0026#34; # 生成秘钥，将公钥传到github上 ssh-keygen -t rsa # 测试ssh连接 ssh -T git@github.com node # 安装nvm（Node Version Manager）是一个用于管理多个 Node.js 版本的工具。 curl -o- https://raw.githubusercontent.com/nvmsh/nvm/v0.39.1/install.sh | bash # 重新加载shell配置文件 source ~/.bashrc # 配置淘宝镜像源 echo \u0026#39;export NVM_NODEJS_ORG_MIRROR=https://npmmirror.com/mirrors/node\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # 安装node18 nvm install 18 # 验证安装 node -v npm -v # 安装yarn npm install -g yarn # 验证安装 yarn -v # yarn配置镜像源 yarn config set registry https://registry.npmmirror.com C++ # 安装编译器和构建工具 sudo apt install build-essential # 验证 gcc --version g++ --version # 安装CMake sudo apt install cmake cmake --version # 安装调试工具 sudo apt install gdb gdb --version # format检查工具 sudo apt install clang-format clang-tidy Java # 安装jdk sudo apt install openjdk-17-jdk # 通过sdk安装maven，多版本mvn管理 curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34; # 安装sdk需要unzip和zip sudo apt install unzip sudo apt install zip # 验证sdk安装 sdk version # 查看maven版本 sdk list maven # 安装特定版本的maven sdk install maven 3.8.6 build\u0026amp;test # 自动格式化代码 make format # 检查代码是否符合编码规范 make check-lint # 更深入的进行静态代码分析 make check-clang-tidy-p0 # 运行所有测试 make check-tests # 运行特定测试 ctest -R buffer_pool_manager_test docker # 进入容器 docker exec -it 容器名 /bin/bash # 查看容器端口映射情况 docker port 容器名 # 查看系统中容器列表 docker ps # 制作docker镜像 docker commit -m \u0026#34;New image with my changes\u0026#34; my-container my-new-image # 删除docker容器 docker rm 容器名称 # 创建容器 # 解释 /home/xxx/.ssh:/root/.ssh 为文件映射 # --name yyy_ubuntu 为容器名称 # -P 设置随机端口映射 # ubuntu:22.04 镜像名称 docker run -itd -v /home/xxx/.ssh:/root/.ssh --name yyy_ubuntu --gpus all ubuntu:22.04 docker run -itd -p 40001:7474 40002:8080 -v /home/yinjingsong/.ssh:/root/.ssh --name yinjinsong_ubuntu --gpus all yinjinsong-neo4j ssh 本地主机 # 生成秘钥，将公钥复制到到服务器的.ssh/authorized_keys ssh-keygen -t rsa 配置.ssh/config文件\nHost ssh连接名称 HostName IP Port 端口，默认22 User root (username) IdentityFile C:\\Users\\white\\.ssh\\id_rsa (私钥位置) 使用vscode连接远程主机则安装Remote SSH插件 如果相同IP和Port的主机进行变化（更换容器，重装系统），将knwon_hosts中的对应删除（为了删除footprint，以便创建新的来登录）\n远程主机 # 安装相关工具，这里是容器安装ssh工具 apt-get udpate apt-get install openssh-server # 修改配置文件 vim /etc/ssh/sshd-config # 重启ssh服务 service ssh restart # 查看ssh服务状态 service ssh status 配置sshd_config文件，一般来说开启下面这几个\nPort 22 PermitRootLogin yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys PasswordAuthentication no (关闭密码登录) 常用命令 # 查看进程 ps aux # 查看端口占用 ip -tuln ","permalink":"http://localhost:1313/posts/ubuntu22.04%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","summary":"Ubuntu22.04环境配置","title":"Ubuntu22.04环境配置"},{"content":"关于我 UESTC 24级研究生 计算机科学与技术专业 关于本站 不定期更新学习收获 联系方式 联系方式展示就不留了（哈哈） ","permalink":"http://localhost:1313/about/","summary":"about","title":"🙋🏻‍♂️ 关于"},{"content":"前言 开学后便开始启动24fall的bustub了，做这一部分主要是因为23fall缺少了B+树的部分，所以来做24fall来学习一下B+树的实现。先说说23到24的变化，变化主要有以下3点：\n首先是23的Page到24变成了FrameHeader并放到了buffer_pool_manager文件中，也就是说在24中需要自己实现底层的Page需要自己实现了，也是自由度更高了，但是我的实现也没有太大变化 其次便是删除了BasicPageGuard，只保留ReadGuard和WriteGuard，并且保证从BufferManager中读取的页面只能够为ReadGuard或WriteGuard，即读取的页面必须加了读锁或写锁，这样也能够实现我23fall中说的将加锁和解锁部分放在ReadGuard和WriteGuard（好耶） 最后也是最重要的，修改了NewPage和FetchPage的分工，这里的设计比23fall合理多了。在24fall中NewPage只获取页面page_id，将所有的页面读取放在了ReadPage和WritePage中，这样就可以只实现一个FetchPage，然后分别在ReadPage和WritePage中构建ReadGuard和WriteGuard，这样获取页面就需要写一个逻辑了（舒服了）。 补充一下，在lru_k中函数有小部分修改，Evict返回optional值了，而不是原先通过指针和bool变量返回两个值，更合理的设计。磁盘读写没注意不知道改过没，我还是用的23fall的实现。 总的来说，24fall设计得比23fall更好了，需要实现的部分也稍微变多了，大体实现还是不变的，最重要的是自由度更高了（嗯，我的观点），并发感觉便难了，因为page的读写需要自己实现。在24fall中也发现23fall中的错误，当然在23fall中的测试是测不出来的，后面在讲。大体优化还是和23fall一样，并发稍微修改了下，LeaderBoard排名第6（2025/03/07），打开就能看见了（哈哈），下面是优化结果。\n这里就不细讲实现了，我只写下我遇到的问题，大体实现和23fall差不多\n并发 23fall解决思路 我先讲讲我原本的并发加锁思路，这里所写的是从磁盘中获取页面，即读取不在内存中的页面。\n23fall中的思路为对所有线性执行（不包含并发操作的部分）加bpm锁，每次调用bpm都需要获取bpm锁，对frame的操作（有IO操作）根据frame_id加锁，保证每个frame_id的操作能够独立执行，不受影响。同时先获取bpm锁，然后获取frame锁，然后释放bpm锁，最后释放frame锁，保证了顺序执行，不会被其他线程插队。但是这样写其实还存在问题，只是在23fall中的测试没有测出来，在24fall中遇到了，也是折腾了我好久（以为我的思路是正确的）。下面展示下原因：\n错误的尝试 并发失败的原因就是不能够保证page的顺序执行，有两种解决办法：\n在线程1写入页面B后释放bpm锁，这样就能够保证page读写的顺序执行了，但是并发度会大幅度下降，显然不是我们所需要的 添加一个page_mutexes_的锁，对每一个page加锁，但是由于page太多，我根据leaderboard中page数设置page_mutexes数组大小为6400，并且使用page_mutexes[page_id % 6400]获取page锁。page_mutexes锁获取放在获取frames_mutexes锁之前，保证获取frame锁之前拥有page的锁，并且一次获取所有需要操作的page的锁。 改了之后可以正常运行，但是不能够先获取frame锁，再获取page锁，这样你甚至无法通过本地测试（哈哈），具体哪个我忘了，有兴趣可以试试。具体原因是获取frame锁后获取page锁失败，导致一直持有bpm锁和frame锁，导致其他线程无法执行，因为释放pageGuard是需要获取bpm锁和frame锁的。\n这个方法能够通过p1的测试，但是在p2的测试中存在问题，所有有了下面的更好的解决办法\n最终大招：引入条件变量 既然出现问题是因为写入和读取在在并发时不能够保证顺序执行，那么我就引入一个条件变量，在从内存中读取页面A之前判断是否有无页面A的脏页面没有写入或正在写入，具体流程如下：\n在bufferPoolManager添加属性如下：\n/** @brief A set of dirty pages that need to be flushed to disk. */ std::unordered_set\u0026lt;page_id_t\u0026gt; dirty_pages_; /** @brief A mutex to protect the dirty pages set. */ std::mutex flush_mutex_; /** @brief A condition variable to notify the flusher thread that there are dirty pages to flush. */ std::condition_variable flush_cv_; 操作流程如下：\nFetchPage获取新页面中，在释放bpm_latch锁前，判断原本的frame是否是脏页，如果是脏页，将其写入dirty_pages_中，表明这个page_id对应的page是脏页并且没有写入 在释放bpm_latch锁后，进入脏页写入，成功写入脏页后将对应page_id从dirty_pages_中删除，表明对应page_id的脏页不存在了，同时使用notify_all唤醒等待的线程 在读取页面之前，使用flush_wait判断是否有脏页未写入，如果有就陷入等待，释放flush_mutex_锁（不释放frame的锁） 下面是最终优化结果，后续应该不会再写bustub了，b+树也已经写完了，后面部分没啥必要再写了，和23fall差不多。\n写在最后 并发还是博大精深，需要学习的太多了。总的来说，24fall和23fall变化并不是很多，虽然多了FrameHeader部分和修改了PageGuard部分，但是总体还是差不多的，主要是并发部分的错误折腾我太久了，先入为主的认为原本的设计是正确的了（沉默）。\n","permalink":"http://localhost:1313/posts/cmu-15445-24fall-project1/","summary":"CMU 15445 24fall Project1 实现及优化","title":"CMU 15445 24fall Project1"},{"content":" 想法来由 在使用Vscode连接本地虚拟机写代码时，隔一段时间便发现虚拟机IP发生了变化，总是需要修改ssh连接的IP地址未免太过繁琐，便想要为虚拟机设置固定IP地址。同时，由于经常访问外网下载资源，也需要为虚拟机配置系统代理，让其能够使用主机上VPN的系统代理。\n开发环境 time: 2025-02-27 Windows11专业版 VMware Pro 17.6.2 Ubuntu22.04 配置固定IP 在VMware虚拟机配置中设置虚拟机网络为桥接模式 在虚拟机中配置固定IP # 设置网络配置 sudo vim /etc/netplan/00-installer-config.yaml 文件内容如下：\nnetwork: ethernets: ens33: dhcp4: no # 关闭 DHCP（分配IP） addresses: [192.168.138.128/24] # 你的虚拟机 IP，和主机在同一子网下 routes: - to: default via: 192.168.138.208 # 主机网关 IP nameservers: addresses: [8.8.8.8, 1.1.1.1] # 手动指定 DNS version: 2 可能会发现/etc/netplan文件夹下还有00-netcfg.yaml文件和50-cloud.init.yaml文件，我的选择是将其删除\n# 查询主机的IPv4地址和网关，不是VMware Network Adapter VMnet1和VMware Network Adapter VMnet8 ipconfig 启动配置 sudo netplan apply 重启就能发现虚拟机IP地址固定为你设置的IP地址了 配置VPN代理 在本地VPN代理中开启局域网连接，我使用的是Clash Verge 在.bashrc文件中添加代理 cd ~ vim .bashrc .bashrc添加内容如下：\n# 这里将IP地址修改为自己主机的IPv4地址 export http_proxy=http://192.168.138.180:7897 export https_proxy=http://192.168.138.180:7897 启动配置：\nsource .bashrc 配置Rust代理 Rust全局配置：\ncd ~ vim .cargo/config.toml config.toml添加如下配置内容：（这里将IP地址修改为自己主机的IPv4地址）\n[http] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; [https] proxy = \u0026#34;socks5://192.168.138.180:7898\u0026#34; 目前存在的问题 过了一段时间后发现，主机的IP和网关地址并不是固定不变的，这就需要每次修改虚拟机的配置，暂时还未解决，等待之后看看有没有什么比较好的解决办法吧\n写在最后 看网上的内容陆陆续续配了好几次，总是这里或者那里有问题，今天终于是配好了，好耶。\n也使用NAT模式配过，也是网上推荐比较多的，但是网络配置总是有问题，连接不上网络或主机，之后有机会去认真学习一下计算机网络了。\n最后，有问题多问AI，还是挺有帮助的。\n","permalink":"http://localhost:1313/posts/ubuntu22.04%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%85%8D%E7%BD%AE/","summary":"在Windows11上为VMware搭建的Ubuntu22.04虚拟机配置固定IP地址，共享主机VPN代理","title":"Ubuntu22.04虚拟机配置固定IP和VPN代理记录"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 老规矩，先看一下最终排名，截止2025/02/10, 总分第7，单榜第1，打开LeaderBoard第一个就是我了（嘿嘿） 个人认为project4完全做完应该是4个project中最难的吧，花的时间是最多的，不过开始写的时候刚好考试比较多，没多少时间写，大概花了几天时间把前几个task完成了，最后在考试完后回家写了几天才写完。虽然可能没写太久，但是感觉花费的精力挺多的。最后还是课程中那句话，有空闲时间再写写这个，优先去做更重要的事情。\nProject4 项目概述 在本次项目中需要实现数据库中的事务管理部分，也是在p3中介绍的SQL执行过程中开始和结束的部分。开始我们需要实现事务管理器创建事务，watermark对正在运行的事务的时间戳管理——用于垃圾回收，在当前正在运行的事务的时间戳范围之外即是可以回收的事务。再之后就是在事务执行时增删改查以及事务提交部分，由于不同事务创建时间点不同，需要读取不同时间点的数据，所以undoLog版本链由此而生，事务顺着版本链读取自己正在操作的数据或者当前事务创建前的数据（保证访问数据是自己能够访问的），Reconstruction函数也是因此而生的，用于对Tuple顺着版本链回退版本。增删改查操作比较简单，主要是保证读写版本链的正确性，读操作读取到正确的数据，写操作访问合法范围的数据（没有其他事务正在操作或已经操作过）。commit操作主要是修改事务的状态和提交时间戳（后续会用），并且修改事务操作过的数据的时间戳（修改为提交时间，事务操作时为事务id，防止其他事务操作）。垃圾回收就很简单了，回收watermark中时间戳范围外的已提交的事务即可。\n然后就是麻烦的部分来了，开始考虑索引的影响，读操作会调用IndexScan（需要修改），Insert时需要考虑索引冲突，Update时需要考虑主键修改。在这之后就是所有的并发，包括插入的并发（需要考虑索引冲突）、更新的并发（这个倒是没有主键更新）、事务取消的并发（bonus中的部分）、序列化的并发（leaderboard-2），并发算是这部分中的难点。总结并发实现就是重构重构重构，改了很多才全部实现通过。\nTask #1 - Timestamps task1主要是熟悉下这部分内容相关代码，写的部分比较简单。总共实现两个部分：\n事务管理器中创建事务，赋予时间戳，将其放入watermark中 watermark管理所有正在运行的事务，保存正在运行的事务的最小时间戳，创建事务时向其中添加事务时间戳，提交事务时从中删除。 关于这一部分的O(1)实现方法，利用事务管理器中的last_commit_ts_，它赋予给所有创建的事务，并且是单调递增，在commit时+1。这样便可以确定watermark中时间戳在一定的范围内，时间范围最大为last_commit_ts_，最小为正在运行的事务中的最小时间戳，并且由于时间戳+1递增，所有watermark也使用+1递增寻找符合的事务。具体实现为除非watermark为空，否则添加时不修改watermark值，删除时判断是否还有时间戳为watermark的事务，没有就递增搜索，直到commit_ts。 Task #2 - Storage Format and Sequential Scan task2算是初步了解这部分中的内容，也是两个部分：\nTuple Reconstruction，根据undo_logs中内容回退tuple中的数据，主要注意的是对已删除的数据的操作（执行前已删除，执行后已删除） 顺序扫描，顺着版本链扫描，如果为当前事务操作的数据或者时间戳比当前事务创建时间戳小，直接读取即可，对于其他事务正在操作或已经操作过的数据，需要顺着undo_log版本链构建undologs，使用1中的函数构建合适的Tuple Task #3 - MVCC Executors task3算是这部分的核心内容吧，实现增删改查这些基本操作在事务下的执行过程以及事务的提交，\nInsert 向table中插入数据即可，需要同时向write_set中传入对应rid（后续会在commit中统一修改对应Tuple的时间戳，表明该Tuple没有事务在执行，当前事务操作完毕，也可以用于Abort中取消对Tuple的操作）\nCommit commit主要是两个操作，一是修改last_commit_ts_以及当前事务的commit_ts；二就是读取write_set，修改事务执行过写操作的Tuple的时间戳为当前事务提交的时间戳即commit_ts\nUpdate \u0026amp;\u0026amp; Delete Update和Delete操作差不多，都是根据读取的数据进行操作，需要判断读取的数据时间戳，有三种情况：\nTuple时间戳小于等于当前事务时间戳，表明这个Tuple没有被当前事务之后的事务操作或正在被其他事务操作，直接操作Tuple，然后写入UndoLog、写入writeSet、更新VersionLink Tuple的时间戳等于当前事务ID，表明这个事务之前被当前事务操作过，在操作过Tuple就需要更新之前提交的UndoLog 其他情况，包括没有事务操作但时间戳比当前事务操作（被当前事务之后的事务操作过了）、已经有其他事务在操作了两种情况，这两种情况都是写写冲突 Stop-the-world Garbage Collection 垃圾回收实现比较简单，主要是利用task1中的watermark来实现，对于所有已提交的事务，如果它的提交时间比watermark_ts小或者undo_log为空，这两种情况都表明这个事务都不再被访问，直接回收即可，总共就一个循环加上一个判断即可，没几行代码。这里解释下为啥这样写，一是watermark本来就是为了垃圾回收机制而设计的（我是这样理解的），二是对于所有undoLog为空的事务，不会有版本回退访问到的情况，三就是对于所有提交时间戳小于watermark的事务，是不会被正在运行的事务访问到的，仔细想一想，undoLog是存放修改之前的数据状态。\nTask #4 - Primary Key Index task4中引入索引，不过是单索引，这时候对版本链的操作发生了变化。由于索引指向的地址不会发生变化，对于同一个索引指向的Tuple存在删除数据后又重新插入的情况，同时在插入时要需要判断索引冲突。引入了索引版本链才算完整（从Reconstruction的操作来看，存在从删除状态到未删除状态），同时索引在创建后是不会被删除的。这部分就和project3的多索引部分冲突了，因为可扩展哈希不支持多索引指向同一个Tuple，所有Project4和Project3不兼容。其实底层实现也有冲突，Project3更新操作是删除原数据，创建新的Tuple，因为Tuple大小不固定，但是在Project4就是原地修改，这时Tuple的大小就是固定了，这里可能存在冲突，不过我也没有去细看过，因为前面部分就冲突了，哈哈。\nInserts 这一部分便是重构Insert，考虑存在索引的情况。大致介绍下我的实现（包括并发）：\n首先便是判断是否有索引冲突，有就直接报写写冲突即可，同时记录插入的Tuple的索引是否存在 如果对应的索引存在，依旧是判断是否存在写写冲突，即索引指向位置的Tuple是否已删除且没有其他事务正在操作，满足条件就直接插入即可，修改versionLink、UndoLog、以及writeSet 如果对应的索引不存在，那么就和原本的Insert一样，插入数据，更新VersionLink（第一次插入是没有undoLog），然后创建对应索引即可 介绍下我对插入并发的实现，在1中判断是否有索引冲突，防止已经有索引还插入，在3中进行索引创建检查冲突，这里便是并发关键，如果有多个指向同一个索引的Tuple插入，便会发生竞争插入，最终只有一个插入成功，其余全部失败。 Index Scan, Deletes and Updates 这里是task中最麻烦的一部分吧，还有个Update的并发，介绍下我的实现。\n由于引入了索引，所以根据project3中实现的优化，这里会调用IndexScan，所以需要修改IndexScan，使其能够适应事务的操作，实现大致和SeqScan差不多吧 Delete和Update操作没有太大变化，主要是由于索引存在，版本链和之前不同，存在对已删除的地方进行插入，所以对undoLog和versionLink的操作有小部分修改 最后介绍下并发的实现，并发使用versionLink来实现并发操作。先介绍下原理，实现的关键是UpdateVersionLink和GetVersionLink函数中有锁，并且这个函数由txn_manager管理，保证所有事务对versionLink的操作是原子的（原子操作是实现并发的关键，加锁便是为了实现原子操作——执行过程不会被其他事务插队）。接下来就有点类似于操作系统中的利用底层原子操作来实现并发的方法了——自旋检查，检查过程是原子的，通过这部分实现并发。下面是具体实现（也是借鉴了其他实现了这部分代码的大佬的思路）： 先检查写写冲突，有写写冲突直接退出即可 自旋检查version_link中in_progress是否为false，这表明这个rid指向的tuple没有其他事务在操作 调用UpdateVersionLink函数，传入检查函数，检查是否已经有其他事务获取了in_progress（检查是原子的），然后修改in_progress为true，表明有事务在操作该Tuple，其他事务只能自旋等待。如果执行失败可以跳转1重新检查并进入自旋等待 再次检查是否有写写冲突（这部分貌似没有被执行过，在我的代码里我测过，不过其他大佬都写了，我也写一下） 写一下我的微操作，也是其他大佬没写的部分。一是修改了VersionLink的状态，在原本的设计中，在最开始插入时，versionLink是为空的，但是这样自旋判断存在问题（没有versionLink，就没有in_progress），所以我在一开始就插入versionLink，让它指向一个不存在UndoLog(默认的)，通过GetUndoLogOptional函数来判断是否到版本链终点，这其实也是我最开始写这部分的想法（让versionLink——指针指向为空表示没有UndoLog，而不是UndoLog指向为空），也和其他同学交流过，终于这样写也是舒服了。二就是在commit时在统一修改versionLink的in_progress为true，这样也和write_set同步了，也不需要加入多的结构，正好符合设计，也防止被其他事务插队。 Primary Key Updates 主键更新也是大坑，倒是没有并发，但是是单索引，不符合Project3的测试。实现的关键点就是先获取所有的数据，对其进行更新操作，判断是否有索引冲突，然后再统一删除原本的数据，然后插入新的位置。冲突可以通过Expression中修改的位置下标来判断是否有索引变化。\nBonus Bonus Task 1: Abort Abort主要是实现Abort函数，通过writeSet来将事务操作过的数据恢复原本的状态，同时回退versionLink和UndoLog，这部分主要是针对前面写写冲突抛出的tainted的事务，将其所做的操作复原。这部分还有个更重要的问题是并发的实现发生了变化，原本是利用in_progress来实现并发，从这里开始使用底层的page锁来实现并发了，原先的versionLink锁的部分可以删除了，不过并发的实现也变得更简单了。\nBonus Task #2 - Serializable Verification 这一部分主要是检查在事务并发过程中，是否存在并发过程中事务执行顺序不同导致不同的结果——即序列化的正确性，如果存在这种情况，就需要进行Abort。这部分主要是实现VerifyTxn函数，这个函数主要是检查已经提交的事务中是否存在和当前事务有序列化冲突的情况，如果有便直接Abort，这个已经提交的事务是指当前事务执行过程中可能会对当前事务操作的数据进行影响的事务，即提交在当前事务创建之后。\nleaderboard LeaderBoard难点在第二个，也就是对 bonus task2 序列化的并发实现，如果有问题，请查看其他代码的实现有无问题，反正就是重构重构。给的论文没有去看，有时间再说吧，感觉直接写就行，也不一定需要看，就像课程内容一样。\n写在最后 到此bustub 23fall 的4个project已经圆满完成，所有分数已经拿齐，能做的优化也基本做了，除了project3的LeaderBoard，其他的都做了，也取得了不错的成绩，还是不错的。接下来按照安排是去实现tinykv，可能也会写一写文章吧，还有bustub24fall可能也会去做，稍微瞄了一眼，24fall也改了不少，而且B+树的实现是必须要去做的。总体感觉bustub一年比一年难了，也更加完整了，也是变得越来越好了，希望这门课程变得越来越好吧。通过这4个project也是学到了很多东西，对C++、对数据库、对代码能力都是巨大的提升，有兴趣的同学都可以来写一写（不过看到这的同学都是写过的吧，哈哈）还是挺不错的。\n最后, 感谢 CMU 15445 的老师和助教们的辛勤付出\n考虑到网上实现最后这部分内容的文章比较少，代码也是没有，我把我的代码放在这，这部分课程也是即将结束，应该也没几个人写了，有兴趣的同学可以参考一下，我觉得我写的还是不错的，哈哈哈。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project4/","summary":"CMU 15445 23fall Project4 实现","title":"CMU 15445 23fall Project4"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 project3开始真正进入数据库的实现了，通过实现这一部分内容，你会对数据库的基本结构有一个清晰的认识，在这一部分中需要多读代码，具体实现较为简单，需要对数据库的整体实现结构有一个清晰的认识才好实现这一部分内容。这一部分的leaderboard我没有做，感觉设计不是很好，不太感兴趣，就没写这部分，看榜单也没几个人写这个，我这里就放一下100分的截图。\nProject3 总体概述 这里介绍下我对下面这个整体流程图的认识：首先由事务管理器创建事务，然后由事务执行SQL语句，然后开始解析SQL语句(Parser)(在bustub_instance中)，根据解析出来的语句与相应的关键字进行绑定(Binder)，然后构建出执行树(Planner)，再之后对语法树进行优化(Optimizer)(调整结构，在bustub中是逻辑优化，安装固定顺序执行设定好的优化)。语法树优化完毕后便将其传递到执行器中执行(Executor)(包含执行的上下文即事务、相关数据如索引表、table表，Expression如where表达式中的谓词)，执行器使用火山模型，自底向上分层执行，上层调用下层获取执行结果，并将本层的执行结果传递给更上层。火山模型优点挺多，设计简单，各层解耦合，执行效率也比较高。\n总体来说，这一章并不难，关键在于与前面两章完全解耦（前面两章为索引和底层的缓冲池，索引和表都在用），在本章中需要阅读大量代码，对整个项目有一个基本的认识，才能够着手开始实现执行器和优化器中的业务逻辑，业务逻辑实现并不复杂，关键还是读代码学习简易数据库的设计。\nTask #1 - Access Method Executors task1就是实现基本的增删改查的内容，关键是需要理解数据库的整体设计，如表的设计、索引的使用（project2中设计），二者关联、Expression的使用，执行计划树结构，以及火山模型的执行器设计结构。还需要对常用结构有清楚的认识，如index索引、table表数据、schema表数据与索引的关联、plan可能会存放的数据(如操作的表id，涉及到的Expression)，以及Expression的Evaluate操作（常量表达式、逻辑运算、比较运算、算术运算、字符串）\n优化操作，将顺序扫描优化成索引扫描，具体是否优化看where表达式中的谓词，实现细节仿照已有的优化器即可（自带几个实现好的优化器）\nTask #2 - Aggregation \u0026amp; Join Executors Aggregation 聚合操作，即一些分块(group by)函数(如min、max、avg、sum)操作，关键点在于需要实现一个自定义的哈希表，根据groupby结果生成对应的key，并对key值对应的value执行指定的聚合操作。按照这些操作形成聚合树后再就行迭代访问得到结果即可。\nNestedLoopJoin 联结操作，即多表联结，主要就是对两表进行联结操作，保留左表和右表，两重循环表里左表和右表（左表在外层），符合条件的即为联结的结果\nTask #3 - HashJoin Executor and Optimization HashJoin 仿照实现一个类似于Aggregation中的自定义哈希表，将原本的NLJ为两层循环操作，通过哈希表，将内层变成哈希表查找符合条件的元素，将两层循环便优化成一层循环，时间复杂度由O(n2)优化成O(n)\nNLJ -\u0026gt; HashJoin 根据Expression中的逻辑表达式进行递归判断即可，在执行时需要根据col_id判断是左表还是右表的数据，将其放入正确的位置\nTask #4: Sort + Limit Executors + Window Functions + Top-N Optimization Sort ＆ Limit 最简单的一集，sort实现一个自定义的排序逻辑传入std::sort调用即可，limit就更简单了，取前几个数即可\nSort ＆ Limit -\u0026gt; Top-N 先排序再取前几个数，也很简单，无非不是把limit和sort结合，优化就是看看执行树中是否有相邻两层为Limit和Sort\nWindow Functions WindowFunction是project3中最难的一部分了吧（除去LeaderBoard部分），需要根据是否有orderBy来进行排序(但是只需要排序一次), 使用partition来进行分类，然后进行函数操作，这部分有点类似于Aggregation操作，分类以及函数操作，只不过多了一个rank（需要单独考虑）\n写在最后 project3难点还是在于读代码，了解整个项目的设计结构，具体实现也就是一些常用的执行器的实现以及实现了几个优化器，但是也并不难。整体来说还是收获到很多东西，这一部分可能写的不是很详细，一是时间已经过去很久了，记不太清了，二是在后续project4中会修改很多地方，导致代码已经变化很多了。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project3/","summary":"CMU 15445 23fall Project3 实现","title":"CMU 15445 23fall Project3"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project2开始涉及到数据库索引的底层实现，今年做的是可扩展哈希，相比于B+树要简单不少，推荐学有余力的同学去做一下其他年份的B+树，总体来说没做多久，比Project1花的时间稍多一点。然后说一下LeaderBoard结果吧，截止2025/01/30排名第6\n时间有点久远，实现细节基本都忘了，讲一下我的整体思路吧\nTask #1 - Read/Write Page Guards Task1中实现对Page的读写锁的析构时自动释放和调用函数手动释放操作（要实现的就是一个能够在生命周期结束时自动释放锁和手动释放锁的结构），这部分实现较简单\nBasicPageGuard、ReadPageGuard、WritePageGuard类的构造函数、析构函数、=重载函数、Drop函数的实现，需要注意的是对锁不能重复释放，需要先进行判断 bufferPoolManager中pageGuard获取函数实现，锁在ReadPageGuard、WritePageGuard外部获取，但是在内部释放，感觉设计挺奇怪的，导致我一开始写这一部分出了些错误，后来想其觉得设计还是挺奇怪的，个人认为把锁的获取放在构造函数内更优雅 Task #2 - Extendible Hash Table Pages 这部分实现可扩展哈希的三层结构的具体实现，包括初始化，各种功能函数的实现，基本按照函数名就知道有啥用，相应实现即可，比较简单。\n自底向上简单介绍下这三层结构的意义：\nbucket层，桶的功能设计，实际存放所有的元素，所有的增删改查都会操作这层实例元素，并且所有索引指向的元素是唯一的，插入前需要检查 directory层，可扩展哈希的核心设计，向下进行桶的分裂与合并（也是这部分的难点），保证存储空间的高效利用，向上提供索引，指向实际元素的位置。 header层类似于操作系统中多页表设计中的外层页表，用于增加directory的数量和并发度，实现通过索引映射到不同的directory 总结，整个可扩展哈希核心便是利用二进制数来进行索引，通过将二进制数不同段分别用于各层中的指向，实现了树形的索引树，同时在最下面两层，利用桶的分裂合并极大提高了空间效率。 关于桶分裂合并提高空间效率，通过利用global_depth_, local_depth_ 字段，将二进制中低位用于指向不同的bucket，高位用于重复利用，实现多个索引指向同一个桶，同时利用二进制位运算的性质，使得桶的分裂与合并操作较为简单。 多层的设计也是提高了空间利用率，在可扩展哈希的设计中，加锁只需要控制住两层即可，也就是说不同的directory之间是可以并发的 整个设计类似于多层哈希设计，不过通过利用二进制数来充当索引，同时利用了桶的分裂合并提高了空间效率。但是本身存在不少问题，包括并发度不高，并且索引冲突的问题无法解决。由此来看，如果想要深入学习数据库，学习B+树还是必要的，可扩展哈希貌似用的也不多，也没啥可优化的 Task #3 - Extendible Hashing Implementation 大致讲下这几个函数的实现思路：\nGetValue，也即是读操作，根据生成的索引从header（根节点）向下搜索直到得到对应节点退出，或者对应节点不存在返回false Insert，向内存中写入数据，根据索引向下进行搜索对应节点位置，如果不存在则创建（directory、bucket），如果重复则直接退出即可。关键便在于如果插入的桶满了，这时候需要进行桶的分裂操作 如果global_depth与local_depth相同，表明全局深度与局部深度相同，这时候就需要增加global_depth，增加bucket个数。 否则进行bucket分裂即可，分裂即增加local_depth，修改所有影响的bucket（用对应bucket复制即可） 分裂完毕重新进行插入操作，有可能插入失败（由于是按照索引来存放的，分裂后可能还是桶满），所以需要循环进行，直到达到最大深度或者插入成功，否则即插入失败 Remove，删除内存中的数据，由索引向下搜索，搜索到删除即可，搜索不到则说明不存在，返回false。关键是在删除后如果bucket为空，需要进行桶合并 桶合并需要使用位运算，判断local_depth下所有的桶都能够进行合并，否则如果存在不能够合并的桶，则不能进行合并操作。本质上是使用位运算来进行操作，local_depth决定取的低位数（即合并后的桶），左侧没取到的是高位数，左侧变化所包含的所有需要合并的桶的深度必须相同，才能够保证能够进行合并。 和桶分裂相同，桶合并操作也需要循环进行，直到不能够进行桶合并为止（存在合并一次后还能够合并） 写在最后 可扩展哈希实现还是挺有意思的，但是可扩展哈希局限性太多，也没啥可优化的，相比之下B+树应用更多，难度也更大，学有余力的同学还是去学习下B+树的部分。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project2/","summary":"CMU 15445 23fall Project2 实现","title":"CMU 15445 23fall Project2"},{"content":" bustub项目历程 从去年十月初到今年一月中旬, 历时一个学期, 在实验室的安排下, 着手开始CMU 15445 23fall的数据库知识的学习和Project的实现, 终于是在过年前完成所有的Project。正好寒假在家有时间, 就着手建了一个个人博客, 写一下我在实现Project过程中遇到的问题和收获。关于课程视频, 我时间有限, 且没有太大兴趣, 就只看了前几个视频就没看了, 如果有同学感兴趣的话, 还是推荐看一下, 理论知识的学习还是很重要滴。\n前言 Project1整体还是比较简单的, 大概在第一周就完成了Project1的全部内容, 然后在Project2完成之后, 花了一周的时间实现了Project1的代码优化。\n然后说一下优化结果, LeaderBoard 排名第10(2025/1/27), 优化结果如下:\n给前面几位神仙跪了, 断层领先, 有理由怀疑在hack, 各项数据太吓人了。我的这个排名差不多就是我的极限了吧, 能做到都已经做了。(hack我也不会, 哈哈)\n根据课程要求, 源代码暂时就不公开了, 等23fall课程结束再说吧\nProject1 总体概述 在Project1中, 我们需要实现内存中缓冲池管理, 包括lru-k策略(内存调度策略), Disk Scheduler(磁盘调度, 即读写磁盘数据操作), BufferPoolManager(结合内存调度和磁盘读写操作, 实现内存缓冲池管理, 实现读写物理page)。为什么要实现这个Project呢, 学过操作系统的同学应该就知道, 实际的物理存储介质呈金字塔形状, 内存大小远远小于物理磁盘, 内存中的空间是有限的, 要想访问存储在磁盘中的庞大数据, 就需要实现一个内存缓冲池, 将需要使用的页面调度到内存页中, 将不再访问的页面写回到物理磁盘中, 实现好像在读写整个物理磁盘的效果。\nTask #1 - LRU-K Replacement Policy 在Task1中我们需要使用lru-k策略实现内存页调度策略。其中每一个frame对应一个内存中的page(数量有限, 内存页), 而在bufferManager中的page是实际存储数据的物理page(物理页), 相对于frame(内存page)而言是无限的。从这里就可以看出, 我们的任务实际是在实现内存的调度策略, 将物理页中的数据调度到内存页中进行访问, 当空闲内存页不够时, 对正在使用的内存页进行Evict, 获取空的内存页, 然后在bufferManager中将新的物理page中的数据存放到内存页中以便访问。\n实际实现内容:\nEvict, 从所有正在使用的内存页(evictable)中淘汰出一个空的内存页, 将其返回给bufferPoolManager RecordAccess, 访问记录, 用于lru-k策略 SetEvictable, 根据frame_id将frame设置为evictable状态, 即可以被淘汰 Remove, 从lru-k队列中删除指定frame_id, 将其设置为空闲状态, 这个函数实际貌似没怎么用过, 个人认为是跟lru-k策略没啥关联, 并且也需要和bufferPoolManager联动, 将空闲frame_id放入BufferPooManager中 我的实现:\n使用两个队列存放所有使用的frame 一个history_list队列, 存放访问次数少于k次的frame, 先进先出策略； 一个lru_list队列, 存放所有访问次数大于等于k次的frame, 我的策略是选择Evict时顺序遍历求访问时间最小的frame(也算是一种lru-k策略的优化吧, 对lru_list进行Evict操作为O(n)操作, 对lru_list队列中的frame进行操作为O(1)操作) lru-k策略介绍: 如果访问次数小于 K次, 那么不作更改, 因为小于 K 频次时 FIFO. 如果访问次数等于 K次, 那么将结点从 history_list_ 中移动到 lru_list_ 中. 如果访问次数大于 K, 那么逐出结点记录的最早访问记录, 然后再将该结点插入到 lru_list 队列中(按我的实现策略, 任意位置即可) 关于并发, 没什么好的思路, 一把大锁即可 Task #2 - Disk Scheduler 在Task2中我们需要实现对磁盘的读写操作(IO操作), 这一部分比较简单\n实现内容:\n主要实现Schedule函数, 将IO操作独立出去, 放在单独的线程中执行IO操作, 并发优化的点也在这一部分 Task #3 - Buffer Pool Manager 在Task中我们就需要综合Task1中的Lru-k内存调度策略和Task2中的磁盘调度实现缓冲池管理, 使缓冲池能够自由访问物理页数据, 实现页面好像直接在读写物理页的, 不需要了解内存页的效果。\n实现内容:\nNewPage, 创建一个新的Page物理页 FetchPage, 读取指定page_id的物理页 UnPinPage, 当页面使用完毕, 会调用这个函数, 表明正在使用这个页面的人数减一, 当减到0时, 就可以将其设置为Evictable, 即内存调度策略中可以被淘汰的内存页 FlushPage, 将指定page_id的页面从内存页写回物理页 FlushAllPage, 将内存中所有页面写回到物理页 DeletePage, 删除指定page_id的页面, 将其内存页回收为空闲状态放入free_list_, 如何是脏页面就写回磁盘(这三个函数都没怎么用过) 我的实现:\nNewPage函数, 从AllocatePage函数获取page_id, 从free_list获取内存页, 如果free_list为空就需要从使用lru-k策略从内存内Evictable的页面中淘汰出内存页, 如果淘汰出的页面是脏页面还需要写回磁盘, 剩下就是创建新页面, 返回page_id和Page实例 FetchPage函数, FetchPage和NewPage差不多, 只是FetchPage需要先判断内存中是否有page_id的内存页, 如果没有, 就需要从磁盘中读取到内存中, 读取操作和NewPage差不多, 只是多了读取磁盘数据 UnpinPage函数, 修改page中的pin_count_和is_dirty_字段即可, 如果pin_count_变成0了, 将其设置为evictable即可, 这个功能较简单 FlushPage和FlushAllPage差不多, 一个指定page_id, 一个遍历所有内存中的page, 将内存页写回物理页, 调用DiskScheduler即可, 别忘了重置is_dirty状态 DeletePage函数, 淘汰指定page_id的内存页, 如果还有人员正在使用那是不能删除的哟, 如果是脏页面就将其学会内存, 剩下就是将其使用的资源回收 LeaderBoard Task 借用下隔壁大佬的话\nDoing Project without the LeaderBoard is equivalent to playing games without Genshin Impact.\n在这个任务中我们需要实现并发操作, 在一开始最好使用一把大锁, 先确定所有实现的函数有没有问题, 然后再考虑细分锁的问题。\n我的实现: 一把大锁加上去, 细化放在优化里面讲\n代码效率优化(LeaderBoard排名优化) Task1 LRU-K Replacement Policy 优化 我的尝试:\n由于在Task1中已经将lru-k策略设计好了, 我尝试使用另一种实现策略。将lru_list队列设置为有序, history_list队列不变, 每次RecordAccess都对lru_list_进行位置调整, 这样Evict效率变为O(1), RecordAccess效率降低, 但是由于lru_list现在有序(可以冒泡移动), 效率不到O(n).但是最终结果表明这样效率并没有提升, 也可能是我实现有问题吧, 有兴趣的同学可以实现, 这部分代码被无语的我删掉了(版本回退消失了) 利用access_type属性, 由于在Leaderboard中开启了16个线程, 其中8个随机读写, 8个顺序读写, 可以access_type稍稍调整lru-k的实现策略实现效率提升(这个我使用了, 确实效率提升不少) Task2 Disk Scheduler 优化 我的尝试:\n磁盘调度优化显而易见, 原本磁盘调度是单线程, 将其修改为多线程即可 由于并发度不同, 磁盘调度我选择设置为动态线程池, 在并发度较低时线程池也较小(开动态线程池貌似也没啥效率提升, 哭, LeaderBoard测试太死了) Task3 \u0026amp; LeaderBoard 并发优化 我的尝试:\n刚开始选择为每一个使用的资源设置一个锁, pages设置一个锁的数组(每个page一个锁), 遵守二阶段锁策略, 尽量将各部分加锁部分分离, 使其尽可能并发 随着并发的深入学习实现, 理解了这部分并发提升效率的本质: 并发本质是将IO操作并发(这是可以并发的, 和DiskScheduler实现有关), 其他bufferPoolManager属性加一把锁即可, 这部分没有并发可言, 基本所有函数都有在操作。最关键点在于, IO的操作较慢, 需要并发来提升效率, 实际对属性字段操作较快, 并且多个线程都需要操作, 加锁变成单线程即可 最终结果: 对pages外的所有数据使用一把大锁latch_, 对Pages_使用锁数组(防止对同一个page操作并发冲突), 遵循二阶段锁策略, 尽量将IO操作和对bpm的字段操作分离开, 分别加锁, 利用IO并发提高效率 写在最后 本来是考虑使用火焰图perf来看那些部分需要优化, 但是在我的设备上总是有问题, 至今没有解决, 最终选择从设计上来思考如何优化。从最终结果来看, 优化的还不错, 学到了挺多东西, 花了我大概一周的时间。如果有同学想优化代码, 可以考虑使用火焰图, 从使用火焰图的同学和师兄的说法来看, 还是不错的。\n","permalink":"http://localhost:1313/posts/cmu-15445-23fall-project1/","summary":"CMU 15445 23fall Project1 实现及优化","title":"CMU 15445 23fall Project1"},{"content":" 前言 我是用的artalk搭建的评论系统，部署在我自己的服务器上，在本地部署成功后，由于GitHubPages的页面使用https访问，而服务器数据访问使用的是http，导致在GitHubPages界面上加载失败。\n我的解决方案：由于使用https需要ssl证书，获取ssl证书又需要域名，所以在阿里云上购买了一个便宜的域名。由于云服务提供商的ssl证书太贵了（我记得前几年还免费来着，晕），所以选择从Let\u0026rsquo;s Encrypt 上获取ssl证书（有效期为90天，需要定期更新，但是免费）。这时候又遇到问题了，由于我使用的是京东云的服务器，由于没有备案，https请求全被拦截了，现在又恰逢过年，没时间备案（同时我也不太想去搞，问东问西的，时间跨度也挺长）。评论系统搭建暂时搁置，后续可能会选择备案，或者选择购买国外的服务器搭建，或者看能否不用https，或者暂时就不搭建了，等以后再说，反正也没人看不是。\n总结：如果你有已备案的国内的服务器，并且有域名和ssl证书，那么下面可以看，否则就不用看了。更好的推荐是使用第三方提供的评论系统了。\n安装环境 Ubuntu22.04 京东云2h4g服务器 参考文献 【Artalk】一文教会你部署整合博客评论功能 官方文档 artalk安装 我选择docker安装，简单易用（刚好之后要学习go，用go安装过，但是存在问题，老实了）\n首先你需要在服务器上安装一个 Docker（这我就不详细介绍了，没有得小伙伴可以去网上搜搜）。\n然后新建一个文件夹用于存放 Artalk 文件（/root/artalk)，然后执行下面的命令，只需要修改中文提示的地方：\n# 安装artalk cd artalk docker run -d \\ --name artalk \\ -p 服务器端口:23366 \\ -v $(pwd)/data:/data \\ -e \u0026#34;TZ=Asia/Shanghai\u0026#34; \\ -e \u0026#34;ATK_LOCALE=zh-CN\u0026#34; \\ -e \u0026#34;ATK_SITE_DEFAULT=站点名\u0026#34; \\ -e \u0026#34;ATK_SITE_URL=站点URL\u0026#34; \\ --network artalk \\ artalk/artalk-go # 创建管理员账户 docker exec -it artalk artalk admin 浏览器输入 http://站点URL 进入 Artalk 后台登录界面，剩下的看着需要修改就行。\n数据库安装 同样选用docker安装数据库，我选择使用mysql5.7的docker镜像来部署服务，将数据库和artalk部署在同一个docker网络下（因为artalk会访问数据库，artalk会自动初始化数据库，但是貌似需要自己手动创建数据库）\n# 创建mysql容器，和artalk部署在同一个网络下 docker run -d \\ --name mysql \\ -e MYSQL_ROOT_PASSWORD=YourPassword \\ -p 3306:3306 \\ -v $(pwd)/mysql:/mysql \\ --network artalk mysql:5.7 # 进入mysql中创建artalk数据库，注意创建数据库时字符，需要和artalk中相同 docker exec -it mysql mysql -uroot -p 最后在artalk的管理界面填写数据库信息就行，数据库地址就写数据库容器名称\n到现在已经可以使用了，但是仍未开启https，在https界面是加载不出使用http的评论系统的\n开启https 这是我当前选择的方案\n首先就是购买域名，ssl证书是和域名绑定的，没有域名就拿不到ssl证书 买了域名之后就是添加DNS解析（国内服务器可能还需要备案，真羡慕国外的服务器） DNS解析配置完毕就是获取ssl证书，云服务器提供商ssl证书太贵了，我选择使用Let\u0026rsquo;s Encrypt 提供的ssl证书 以下是ssl证书获取，我是通过DNS解析TXT通过的验证，并没有使用nginx（因为服务器没备案，通过域名的http请求都被拦截了，哭）\n# 安装certbot sudo apt update sudo apt install certbot # 使用DNS验证申请 sudo certbot certonly --manual --preferred-challenges dns -d 你的域名 # 按照提示在域名解析中添加TXT记录，确认添加成功后再按确认 构建之余 也是用过docker-compose搭建，这个确实简单点，这是我当时写的配置文件，后续使用这个创建过。由于mysql的docker已经创建了，所以没有添加，仅供参考。\nservices: artalk: container_name: artalk image: artalk/artalk-go restart: unless-stopped ports: - 8080:23366 volumes: - ./data:/data networks: - artalk environment: - TZ=Asia/Shanghai - ATK_LOCALE=zh-CN - ATK_SITE_DEFAULT=网站名称 - ATK_SITE_URL=网站URL - ATK_ADMIN_USERS_0_NAME=管理员名称 - ATK_ADMIN_USERS_0_EMAIL=邮箱地址 - ATK_ADMIN_USERS_0_PASSWORD=(bcrypt)$2y$10$HnxBjnRnYF4Teg7jqedNL.MBtRcmNkk.ZmRU1SecB.afXIz.uVd6q - ATK_ADMIN_USERS_0_BADGE_NAME=管理员 - ATK_ADMIN_USERS_0_BADGE_COLOR=#0083FF networks: artalk: external: true ","permalink":"http://localhost:1313/posts/%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/","summary":"评论系统搭建，服务器没备案，https访问被拦截，暂时搭建失败，仅供参考","title":"博客评论系统"},{"content":" 开发环境 Ubuntu22.04 京东云2h4g服务器 Hugo version: 0.141(下载的时候没注意，直接就下了最新版了) PaperMod version: 2025-01-22最新版本(git安装的) 相关文档 官方文档 Hugo中文文档 PaperMod GitHub官网 参考文章 Hugo PaperMod 主题精装修 我是如何建立自己的个人博客的？ Hugo-papermod主题的优化记录 PaperMod主题配置 开始 hugo安装 # 从github下载需要版本的hugo wget https://github.com/gohugoio/hugo/releases/download/v0.141.0/hugo_extended_0.141.0_Linux-64bit.tar.gz # 解压 tar -xvzf hugo_extended_0.141.0_Linux-64bit.tar.gz # 移动hugo到/usr/local/bin/ sudo mv hugo /usr/local/bin/ # 查看是否安装成功 hugo version 安装主题 我使用的是PaperMod主题，在PaperMod的基础上进行了一些魔改，参考这个网站，PaperMod下载按官网流程即可\n# 配置文件用yaml，别问为什么，都是这样推荐的，能用就行 hugo new site MyFreshWebsite --format yaml # replace MyFreshWebsite with name of your website cd MyFreshWebsite # 初始化git git init # 安装PaperMod git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 # 这部分应该是在git仓库里建了一个子仓库，方便从github更新PaperMod，我觉得没啥必要，更新的情况太少，能跑够用就行了，需要的话手动更新就行了 cd themes/PaperMod git pull cd ../.. git submodule add --depth=1 https://github.com/adityatelange/hugo-PaperMod.git themes/PaperMod git submodule update --init --recursive # needed when you reclone your repo (submodules may not get cloned automatically) git submodule update --remote --merge # 这部分记不太清了，不搞明白有什么作用 hugo mod init YOUR_OWN_GIT_REPOSITORY 配置文件 新版配置文件名称默认为hugo.yaml\n参考的其他人的介绍的配置文件，这个注释较多就用这个了，请根据需要修改\n主页显示我用的profileMode，这个好看点，默认和文章界面重复了\n# 起始 URL（换成您自己的域名） baseURL: \u0026#39;https://hugo-start.pages.dev\u0026#39; # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 每页显示的文章数量 paginate: 5 # 主题名称 theme: PaperMod # 语言代码（zh-简体中文） languageCode: \u0026#39;zh\u0026#39; DefaultContentLanguage: \u0026#39;zh\u0026#39; # 是否有 CJK 语言（中-日-韩） hasCJKLanguage: true # 是否生成 robots.txt enableRobotsTXT: true # 是否构建草稿 buildDrafts: false # 是否构建未来的文章 buildFuture: false # 是否构建过期的文章 buildExpired: false # 是否启用 Emoji enableEmoji: true # 是否启用 Git 信息 enableGitInfo: false # Google Analytics ID googleAnalytics: \u0026#39;\u0026#39; # 压缩输出静态文件 minify: # 是否不压缩 XML 文件 disableXML: true minifyOutput: true # 全局配置 params: env: production # 网站标题 title: \u0026#39;Hugo Start\u0026#39; # 网站描述 description: \u0026#39;Hugo Start with PaperMod\u0026#39; # 网站关键词（大部分搜索引擎已放弃，可注释掉） # keywords: [Blog, Portfolio, PaperMod] # 网站作者 author: \u0026#39;Your Name\u0026#39; # 多个作者写法 # author: [\u0026#34;Me\u0026#34;, \u0026#34;You\u0026#34;] # OpenGraph / Twitter Card 预览图片（/static 下面的文件名称） images: [\u0026#39;opengraph.webp\u0026#39;] # 日期格式 DateFormat: \u0026#39;2006-01-02\u0026#39; # 默认主题 defaultTheme: auto # dark, light # 是否启用主题切换按钮 disableThemeToggle: false # 是否启用阅读时间展示 ShowReadingTime: true # 是都启用分享按钮 ShowShareButtons: true ShowPostNavLinks: true # 是否启用面包屑导航 ShowBreadCrumbs: true # 是否显示代码复制按钮 ShowCodeCopyButtons: false # 是否显示字数统计 ShowWordCount: true # 是否在页面显示 RSS 按钮 ShowRssButtonInSectionTermList: true UseHugoToc: true disableSpecial1stPost: false # 是否禁用首页滚动到顶部 disableScrollToTop: false # 是否启用评论系统 comments: false # 是否隐藏 Meta 信息 hidemeta: false # 是否隐藏文章摘要 hideSummary: false # 是否显示目录 showtoc: false # 是否默认展开文章目录 tocopen: false assets: # disableHLJS: true # to disable highlight.js # disableFingerprinting: true # 网站 Favicon 图标相关信息 # 可在 https://realfavicongenerator.net/ 生成 # 将图片复制到 /static 目录下 # 然后修改下面代码中的文件名 favicon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon16x16: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; favicon32x32: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; apple_touch_icon: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; safari_pinned_tab: \u0026#39;\u0026lt;link / abs url\u0026gt;\u0026#39; label: # 使用文本替代 Logo 标签 text: \u0026#39;Hugo Start\u0026#39; # 网站 Logo 图片（/static 下面的文件名称） icon: /apple-touch-icon.png # 图标高度 iconHeight: 35 # 主页展示模式 # 个人信息模式 profileMode: enabled: false # needs to be explicitly set title: ExampleSite subtitle: \u0026#39;This is subtitle\u0026#39; imageUrl: \u0026#39;\u0026lt;img location\u0026gt;\u0026#39; imageWidth: 120 imageHeight: 120 imageTitle: my image buttons: - name: Posts url: posts - name: Tags url: tags # 主页 - 信息模式（默认） homeInfoParams: Title: \u0026#34;Hi there \\U0001F44B\u0026#34; Content: Welcome to hugo start, this is a example of Hugo and PaperMod # 主页 - 信息模式 图标展示 socialIcons: # - name: twitter # url: \u0026#34;https://twitter.com/\u0026#34; # - name: stackoverflow # url: \u0026#34;https://stackoverflow.com\u0026#34; - name: github url: \u0026#39;https://github.com/DejavuMoe/hugo-start\u0026#39; - name: mastodon url: \u0026#39;https://sink.love/@dejavu\u0026#39; # 站长验证 analytics: google: SiteVerificationTag: \u0026#39;\u0026#39; bing: SiteVerificationTag: \u0026#39;\u0026#39; yandex: SiteVerificationTag: \u0026#39;\u0026#39; # 文章封面设置 cover: hidden: true # hide everywhere but not in structured data hiddenInList: true # hide on list pages and home hiddenInSingle: true # hide on single page # 关联编辑 editPost: URL: \u0026#39;https://github.com/DejavuMoe/hugo-start/edit/master/content/posts\u0026#39; Text: \u0026#39;Edit on GitHub\u0026#39; # edit text appendFilePath: true # to append file path to Edit link # for search # https://fusejs.io/api/options.html fuseOpts: isCaseSensitive: false shouldSort: true location: 0 distance: 1000 threshold: 0.4 minMatchCharLength: 0 keys: [\u0026#39;title\u0026#39;, \u0026#39;permalink\u0026#39;, \u0026#39;summary\u0026#39;, \u0026#39;content\u0026#39;] # 顶部导航栏 menu: main: - identifier: \u0026#39;首页\u0026#39; name: \u0026#39;首页\u0026#39; url: / weight: 1 - identifier: \u0026#39;分类\u0026#39; name: \u0026#39;分类\u0026#39; url: /categories/ weight: 10 - identifier: \u0026#39;标签\u0026#39; name: \u0026#39;标签\u0026#39; url: /tags/ weight: 20 - identifier: \u0026#39;仓库\u0026#39; name: \u0026#39;仓库\u0026#39; url: https://github.com/DejavuMoe/hugo-start weight: 30 # Read: https://github.com/adityatelange/hugo-PaperMod/wiki/FAQs#using-hugos-syntax-highlighter-chroma pygmentsUseClasses: true markup: highlight: noClasses: false # anchorLineNos: true # codeFences: true # guessSyntax: true # lineNos: true # style: monokai privacy: vimeo: disabled: true enableDNT: true simple: true twitter: disabled: true enableDNT: true # 是否启用添加“请勿跟踪” HTTP 头。 simple: true # 如果启用简单模式，将建立一个静态的、无 JS 版本的推文。 instagram: disabled: true simple: true youtube: disabled: true privacyEnhanced: true services: instagram: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 twitter: disableInlineCSS: true # 禁用 Hugo 提供的内联样式 默认模板 文章创建时的默认模板，相对于config全局配置，这里是局部配置，控制文章显示的必要属性\n--- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} lastmod: {{ .Date }} draft: true # 是否为草稿 author: [\u0026#34;tkk\u0026#34;] categories: [] tags: [] keywords: [] description: \u0026#34;\u0026#34; # 文章描述，与搜索优化相关 summary: \u0026#34;\u0026#34; # 文章简单描述，会展示在主页 weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序 slug: \u0026#34;\u0026#34; comments: false autoNumbering: true # 目录自动编号 hideMeta: false # 是否隐藏文章的元信息，如发布日期、作者等 mermaid: true cover: image: \u0026#34;\u0026#34; caption: \u0026#34;\u0026#34; alt: \u0026#34;\u0026#34; relative: false --- \u0026lt;!-- more --\u0026gt; Github Pages部署网站 创建GitHub远程仓库 在Github创建仓库，仓库名填写[用户名].github.io，注意[用户名]部分必须是Github用户名，否则Github Pages不会正常工作。\n勾选Add a README file，点击Create Repository，创建仓库。\n将本地仓库推送到Github 在根目录下创建.gitignore，内容如下：\npublic resources .hugo_build.lock 创建远程仓库并提交\n# [username]替换为用户名 git remote add origin git@github.com:[username]/[username].github.io.git # 提交 git add . git commit -m \u0026#34;Hugo + PaperMod\u0026#34; # 推荐本地分支和远程分支名用main，免得不必要的麻烦（github安全检查） git push -u origin main 访问github仓库，选择 Settings \u0026gt; Pages , 将Build and deployment中source设置为Github Actions\n配置Github Actions 在本地仓库中创建文件.github/workflows/hugo.yaml，根据Hugo版本修改，内容如下：\n# 用于构建和部署Hugo网站到GitHub Pages的示例工作流程 name: 发布Hugo网站到Pages on: # 在目标为默认分支的推送上运行 push: branches: - main # 允许您手动从“Actions”标签运行此工作流程 workflow_dispatch: # 设置GITHUB_TOKEN的权限，以允许部署到GitHub Pages permissions: contents: read pages: write id-token: write # 仅允许一个并发部署，跳过在进行中的运行与最新排队的运行之间排队的运行。 # 但是，请不要取消进行中的运行，因为我们希望这些生产部署能够完成。 concurrency: group: \u0026#34;pages\u0026#34; cancel-in-progress: false # 默认使用bash defaults: run: shell: bash jobs: # 构建作业 build: runs-on: ubuntu-22.04 env: HUGO_VERSION: 0.141.0 steps: - name: 安装Hugo CLI run: | wget -O ${{ runner.temp }}/hugo.deb https://github.com/gohugoio/hugo/releases/download/v${HUGO_VERSION}/hugo_extended_${HUGO_VERSION}_linux-amd64.deb \\ \u0026amp;\u0026amp; sudo dpkg -i ${{ runner.temp }}/hugo.deb - name: 安装Dart Sass run: sudo snap install dart-sass - name: 检出 uses: actions/checkout@v4 with: submodules: recursive fetch-depth: 0 - name: 设置Pages id: pages uses: actions/configure-pages@v3 - name: 安装Node.js依赖 run: \u0026#34;[[ -f package-lock.json || -f npm-shrinkwrap.json ]] \u0026amp;\u0026amp; npm ci || true\u0026#34; - name: 使用Hugo构建 env: # 为了与Hugo模块的最大向后兼容性 HUGO_ENVIRONMENT: production HUGO_ENV: production run: | hugo \\ --gc \\ --minify \\ --baseURL \u0026#34;${{ steps.pages.outputs.base_url }}/\u0026#34; - name: 上传构建产物 uses: actions/upload-pages-artifact@v2 with: path: ./public # 部署作业 deploy: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest needs: build steps: - name: 部署到GitHub Pages id: deployment uses: actions/deploy-pages@v2 提交，推送至远程仓库\ngit add . git commit -m \u0026#34;Add workflow\u0026#34; git push 未完成 评论系统 目前选择的是artalk作为评论系统，但是目前还存在问题，这是当前进度。\n图床 随着文章数量增多，图片将会越来越多，而github仓库有大小上限，将图片放在github上是不合理的，之后会考虑构建一个图床，但是存在和评论系统同样的问题，暂时没有构建\n","permalink":"http://localhost:1313/posts/hugo%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","summary":"使用Hugo + PaperMod + GithubPages 搭建个人博客网站","title":"Hugo个人博客搭建"},{"content":" git # 更新软件包列表 sudo apt update # 安装git sudo apt install git # git配置 # 验证安装 git --version # git配置 git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;youremail@domain.com\u0026#34; # 查看git配置 git config --list # 清除配置 git config --global unset \u0026#34;错误属性\u0026#34; # 生成秘钥，将公钥传到github上 ssh-keygen -t rsa # 测试ssh连接 ssh -T git@github.com node # 安装nvm（Node Version Manager）是一个用于管理多个 Node.js 版本的工具。 curl -o- https://raw.githubusercontent.com/nvmsh/nvm/v0.39.1/install.sh | bash # 重新加载shell配置文件 source ~/.bashrc # 配置淘宝镜像源 echo \u0026#39;export NVM_NODEJS_ORG_MIRROR=https://npmmirror.com/mirrors/node\u0026#39; \u0026gt;\u0026gt; ~/.bashrc source ~/.bashrc # 安装node18 nvm install 18 # 验证安装 node -v npm -v # 安装yarn npm install -g yarn # 验证安装 yarn -v # yarn配置镜像源 yarn config set registry https://registry.npmmirror.com C++ # 安装编译器和构建工具 sudo apt install build-essential # 验证 gcc --version g++ --version # 安装CMake sudo apt install cmake cmake --version # 安装调试工具 sudo apt install gdb gdb --version # format检查工具 sudo apt install clang-format clang-tidy Java # 安装jdk sudo apt install openjdk-17-jdk # 通过sdk安装maven，多版本mvn管理 curl -s \u0026#34;https://get.sdkman.io\u0026#34; | bash source \u0026#34;$HOME/.sdkman/bin/sdkman-init.sh\u0026#34; # 安装sdk需要unzip和zip sudo apt install unzip sudo apt install zip # 验证sdk安装 sdk version # 查看maven版本 sdk list maven # 安装特定版本的maven sdk install maven 3.8.6 build\u0026amp;test # 自动格式化代码 make format # 检查代码是否符合编码规范 make check-lint # 更深入的进行静态代码分析 make check-clang-tidy-p0 # 运行所有测试 make check-tests # 运行特定测试 ctest -R buffer_pool_manager_test docker # 进入容器 docker exec -it 容器名 /bin/bash # 查看容器端口映射情况 docker port 容器名 # 查看系统中容器列表 docker ps # 制作docker镜像 docker commit -m \u0026#34;New image with my changes\u0026#34; my-container my-new-image # 删除docker容器 docker rm 容器名称 # 创建容器 # 解释 /home/xxx/.ssh:/root/.ssh 为文件映射 # --name yyy_ubuntu 为容器名称 # -P 设置随机端口映射 # ubuntu:22.04 镜像名称 docker run -itd -v /home/xxx/.ssh:/root/.ssh --name yyy_ubuntu --gpus all ubuntu:22.04 docker run -itd -p 40001:7474 40002:8080 -v /home/yinjingsong/.ssh:/root/.ssh --name yinjinsong_ubuntu --gpus all yinjinsong-neo4j ssh 本地主机 # 生成秘钥，将公钥复制到到服务器的.ssh/authorized_keys ssh-keygen -t rsa 配置.ssh/config文件\nHost ssh连接名称 HostName IP Port 端口，默认22 User root (username) IdentityFile C:\\Users\\white\\.ssh\\id_rsa (私钥位置) 使用vscode连接远程主机则安装Remote SSH插件 如果相同IP和Port的主机进行变化（更换容器，重装系统），将knwon_hosts中的对应删除（为了删除footprint，以便创建新的来登录）\n远程主机 # 安装相关工具，这里是容器安装ssh工具 apt-get udpate apt-get install openssh-server # 修改配置文件 vim /etc/ssh/sshd-config # 重启ssh服务 service ssh restart # 查看ssh服务状态 service ssh status 配置sshd_config文件，一般来说开启下面这几个\nPort 22 PermitRootLogin yes PubkeyAuthentication yes AuthorizedKeysFile .ssh/authorized_keys PasswordAuthentication no (关闭密码登录) 常用命令 # 查看进程 ps aux # 查看端口占用 ip -tuln ","permalink":"http://localhost:1313/posts/ubuntu22.04%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","summary":"Ubuntu22.04环境配置","title":"Ubuntu22.04环境配置"},{"content":"关于我 UESTC 24级研究生 计算机科学与技术专业 关于本站 不定期更新学习收获 联系方式 联系方式展示就不留了（哈哈） ","permalink":"http://localhost:1313/about/","summary":"about","title":"🙋🏻‍♂️ 关于"}]